{"pages":[{"title":"","text":"","link":"/404.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"about","text":"姓名： Hu 邮箱： me(at)hoooo(dot)org","link":"/about/index.html"},{"title":"tags","text":"","link":"/tags/index.html"},{"title":"search","text":"","link":"/search/index.html"}],"posts":[{"title":"DSL 思考","text":"一、什么是DSL DSL，即Domain Specific Language，是为在某些特定领域内解决特定问题而设计的专用语言，其基本思想是“求专不求全”。DSL主要目的是消除代码复杂度和间接性，并且应该注重专业领域。此外，也需要合理恰当的语法形式来实现DSL。 DSL 的类型： 非计算 HTML、CSS 计算能力有限 SQL、 CPP templates 、正则表达式 异构 GLSL 特殊应用 Matlab 二、 Embedded DSL Embedded domain-specific language（eDSL）是嵌入式DSL，其优势是利用宿主语言实现。嵌入式DSL可以看做是库，API can usefully be thought of as a language。 Embedding DSL 利用宿主语言的现有api实现，不再需要编写解析器。 实现 eDSL 的方式有如下几种： 字符串 是最简单的实现方式，因为不需要编写解析器。最好的例子是在JQuery中检索CSS 1const myTable = $(&quot;#foo div.tabular-data table); CSS选择器是只是指定一组HTML document 元素的DSL。 同样，还有正则表达式。 1const matches = input.match(&quot;.*/.+\\\\.png$&quot;); 宏定义、准引用(Quasiquotation) 宏定义（Macros）能够在编译时期执行代码。宏常常与准引用一起使用，比如在Lisp和 Haskell 中可以自定义语法。 在Yesod 网络框架中，Haskell 有 Shakespearean Templates 的例子，允许HTML/CSS/JS代码在Haskell 代码中插值。 123456789101112131415data Person = Person { name :: String , age :: Int }main :: IO ()main = putStrLn $ renderHtml [shamlet|&lt;p&gt;Hello, my name is #{name person} and I am #{show $ age person}.&lt;p&gt; Let's do some funny stuff with my name: # &lt;b&gt;#{sort $ map toLower (name person)}&lt;p&gt;Oh, and in 5 years I'll be #{show ((+) 5 (age person))} years old.|] where person = Person &quot;Michael&quot; 26 组合Combinators Combinators 是利用小函数或者对象进行构建，因为没有自定义语法，所以很像 API。 例如，Ruby的Rake构建系统对.md文件运行pandoc生成.html文件。 123456task :default =&gt; :htmltask :html =&gt; %W[ch1.html ch2.html ch3.html]rule &quot;.html&quot; =&gt; &quot;.md&quot; do |t| sh &quot;pandoc -o #{http://t.name} #{t.source}&quot;end Monads 在Haskell 中可以利用 Monad 来实现 eDSL。 12345result = do a &lt;- [1..10] b &lt;- [1..10] guard (a /= b) guard (a + b == 7) return (a, b) eDSL 因为能够用于处理专用领域中的问题，所以用处极大。但是在DSL设计和使用中，应该注重在实现上使用恰当的语法。同时，对于DSL解决的问题可能是“动态逻辑加载”，可以使用现有语言动态调用解析器来完成。 库（library）和 eDSL 很相似，有时候最简单的库就能够解决问题。 Embedded DSLs are useful because they let us apply everything we know about programming languages to specific domains. 参考 What is an embedded domain-specific language? 王垠——DSL Embedded Domain Specific Language 领域专用语言迷思 DSL在实际工作中的应用","link":"/2018/07/17/DSL/"},{"title":"Image processing using Graph_1","text":"Lecture1 Graph-based methods in Image Processing for: Segmentation 图像分割 Filtering 过滤 Classification and clustering 聚类/分类 We will sometimes regard a picture as being a real-valued, non-negative function of two real variables; the value of this function at a point will be called the gray-level of the picture at the point. —— Rosenfeld Storing the image in a computer requires digitization, 图片存储： Sampling(recoding image values at a finite set of samples points) Quantization(discretizing the continuous functions values) Typically, sampling points are located on a Cartesian grid. Basic model Generalized image modalities( multispectral images) Generalized image domains(video, volume images MRI) Generalized sampling point distributions( non-Cartesian girds) 形态、样式、采用方法 Benefit for image processing Discrete and mathematically simple representation that lends itself well to the development of efficient and provably correct methods. A minimalistic image representation – flexibility in representing different types of images. re-use existing algorithms and theorems for image analysis! Image as Graphs Graph based image processing methods typically operate on pixel adjacency graphs graphs whose vertex set is the set of image elements, whose edge set is given by an adjacency relation on the image elements Graph segmentation To segment an image represented as a graph, we want to partition the graph into a number of separate connected components. The partitioning can be described either as a vertex labeling or as a graph cut. Graph partitioning vertex labeling Vertex labeling associates each node of the graph with an element in some set of labels. Each element in this set represents an object category. graph cuts A cut is a set of edges that, if they are removed from a graph, separates the graph into two or more connected components. References Space-Variant Machine Vision — A Graph Theoretic Approach. A graph-based framework for sub-pixel image segmentation.","link":"/2017/12/21/Graph_1/"},{"title":"Image processing using Graph_2","text":"L2 体素或立体像素(voxel) 是体积像素(volume pixel) 的简称，是数字数据位于三维空间分区的最小单位，应用于三维成像、科学数据与医疗视频等领域。 CPP —— Boost Graph libraries Matlab —— Graph Analysis toolbox 适定问题 well-posted problem 不适定问题 ill-posted problem Image segmentation 是不适定问题，除非我们限定分割对象。 image segmentation: 在医学领域中，图像分割是病变区域提取、特定组织测量以及实现三维重建的基础。 Recognition （识别） the task of roughly determining where in the image an object is located， 即确定目标物体的大概位置并区别于图像中的其他物体。 Delineation （描绘） the task of determining the exact extent of the object，即在于精确定义和刻画图像中目标物体的区域或者边缘的空间范围。 ​","link":"/2017/12/27/Graph_2/"},{"title":"Huge Page","text":"Ⅰ. Check Huge Page Linux 内核支持多种 page size。 架构 HugePage Size arm64 4K, 2M and 1G (or 64K and 512M if one builds their own kernel with CONFIG_ARM64_64K_PAGES=y) x86 4K and 4M (2M in PAE mode，1GB if architecturally supported) amd64 2MB, 1GB ia64 4K, 8K, 64K, 256K, 1M, 4M, 16M, 256M ppc64 4K, 16M Huge Page 支持 mmap 和 shmget、shmat 调用。 当前系统 Huge Page 设置信息 123456789$ grep Huge /proc/meminfo AnonHugePages: 0 kBShmemHugePages: 0 kBHugePages_Total: 0HugePages_Free: 0HugePages_Rsvd: 0HugePages_Surp: 0Hugepagesize: 2048 kBHugetlb: 0 kB HugePages_Total Huge Page 池的页面数量。 HugePages_Free Huge Page 池中未分配的页面数量。 HugePages_Rsvd 已承诺从池中分配但尚未进行分配的 Huge Page 的数量。 HugePages_Surp /proc/sys/vm/nr_hugepages中 表示 Huge Page 池中页面数量。 /proc/sys/vm/nr_overcommit_hugepages 表示最大值。 Hugepagesize 默认 hugepage 尺寸（Kb）。 Hugetlb 内存总量（kB） HugePages_Total * Hugepagesize /proc/filesystems 可以查看 hugetlbfs 配置信息 /proc/sys/vm/nr_hugepages 表示当前内核大页面池中“持久”大页面的数量。 检查 NUMA 系统中大型页面的每个节点分布情况，使用： 1cat /sys/devices/system/node/node*/meminfo | fgrep Huge Shirink： Shrinking the persistent huge page pool via nr_hugepages such that it becomes less than the number of huge pages in use will convert the balance of the in-use huge pages to surplus huge pages. This will occur even if the number of surplus pages it would exceed the overcommit value. As long as this condition holds–that is, until nr_hugepages+nr_overcommit_hugepages is increased sufficiently, or the surplus huge pages go out of use and are freed – no more surplus huge pages will be allowed to be allocated. 运行时 huge page 接口 /proc/sys/vm /sys/kernel/mm/hugepages 中 hugepages-${size}kB Ⅱ、Huge Page 分配/释放与 NUMA 内存策略 分配或释放 huge page 可以使用： 1numactl -m &lt;node-list&gt; echo 20 &gt;/proc/sys/vm/nr_hugepages_mempolicy 这个操作将会释放或分配 abs(20 - nr_hugepages) 到 &lt;node-list&gt; 。 Ⅲ、使用 Huge Page 需要使用 mmap ，应该先挂载 hugetlbfs： 123 mount -t hugetlbfs \\-o uid=&lt;value&gt;,gid=&lt;value&gt;,mode=&lt;value&gt;,pagesize=&lt;value&gt;,size=&lt;value&gt;,\\min_size=&lt;value&gt;,nr_inodes=&lt;value&gt; none /mnt/huge 在内核 2.6 之后，可以使用 MAP_HUGETLB 的方式操作内存。 map_hugetlb hugepage-shm hugepage-mmaphttps://man7.org/linux/man-pages/man2/mmap.2.html libhugetlbfs 测试 设置 huge page 1234567891011sysctl vm.nr_hugepages=192AnonHugePages: 0 kBShmemHugePages: 0 kBHugePages_Total: 192HugePages_Free: 192HugePages_Rsvd: 0HugePages_Surp: 0Hugepagesize: 2048 kBHugetlb: 393216 kB huge.c 测试 123456789101112131415161718192021222324#include &lt;sys/mman.h&gt;#include &lt;stdio.h&gt;#include &lt;memory.h&gt;int main(int argc, char *argv[]) { char *m; size_t s = (8UL * 1024 * 1024); m = mmap(NULL, s, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS | 0x40000 /*MAP_HUGETLB*/, -1, 0); if (m == MAP_FAILED) { perror(&quot;map mem&quot;); m = NULL; return 1; } memset(m, 0, s); printf(&quot;map_hugetlb ok, press ENTER to quit!\\n&quot;); getchar(); munmap(m, s); return 0;} 查看 huge page 信息 123456789101112131415$ gcc huge.c$ ./a.out map_hugetlb ok, press ENTER to quit!$ cat /proc/meminfo |grep -i hugeAnonHugePages: 0 kBShmemHugePages: 0 kBHugePages_Total: 192HugePages_Free: 188HugePages_Rsvd: 0HugePages_Surp: 0Hugepagesize: 2048 kBHugetlb: 393216 kB Reference https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt http://blog.chinaunix.net/uid-28541347-id-5783934.html https://wiki.debian.org/Hugepages Linux下试验大页面映射（MAP_HUGETLB）_cncnlg的专栏-CSDN博客_map_hugetlb https://www.kernel.org/doc/Documentation/vm/transhuge.txt mmap(2) - Linux manual page","link":"/2020/08/11/HugePage/"},{"title":"Pin学习1","text":"什么是插桩（Instrumentation）? 向程序注入额外的代码来收集程序运行时的状态。 插桩（Instrumentation）的方法： 源代码插桩（source instrumentation） ——对源码进行操作 二进制插桩（Binary instrumentation） ——运行时直接注入 为何使用动态指令注入？ 不需要重新编译或重新链接 在运行时检测代码 处理动态生成的代码 附加到运行的进程中 Pin工具的有点 简单易用 使用动态指令插入方式 —— 不需要修改源代码、重新编译、重新连接 多平台支持 支持X86、X86_64、Itanium、Xscale 支持Linux、Windows、MacOS 鲁棒性 支持现实常见应用： 数据库、浏览器 支持多线程程序 支持信号(signals) 高效 适用编辑器优化(Applies compiler optimizations on instrumentation code) Pin使用方式 1234567// 加载和注入一个程序$ pin -t pintool -- application// Pin —— 注入引擎，在kit中已经提供//Pintool —— 注入工具，自己编写或者适用kit中提供的// 注入到一个程序中（进程号）$ pin -t pintool -pid 1234 Pin注入的API 架构无关的基础API： 提供确定的基础功能的API Control-flow changes Memory accesses 基于特定架构的API： 如基于IA32的段寄存器信息 基于调用（call-based）的API： 桩程序（Instrumentation routines） 分析程序（Analysis routines） 桩程序和分析程序的区别 桩和分析都是从ATOM工具发展来的概念。（搜索关键字 ATOM analysis Instrumentation ） ATOM，即Analysis Tools with OM， http://atominstrument.com/products-services-overview/ http://www.hpl.hp.com/techreports/Compaq-DEC/WRL-TN-44.pdf 桩程序(instrumentation routines）定义了在哪里插桩； 如在指令前 ： 在指令第一次执行时插桩 分析程序（analysis routines）定义当桩启动时执行哪些操作。 如 增量计数器： 在每一次指令执行时发生 Pintool举例1——指令计数 12345678910sub $0xff, %edx counter++;cmp %esi, %edx counter++;jle &lt;L1&gt; counter++;mov $0x1, %edi counter++;add $0x10, %eax counter++; 输出指令数 1234567$ /bin/lsMakefile imageload.out itrace proccountimageload inscount0 atrace itrace.out$ pin -t inscount0 -- /bin/lsMakefile imageload.out itrace proccountimageload inscount0 atrace itrace.outCount 422838 Pintool举例2——指令跟踪 123456789101112// 传递ip参数到分析程序中Print(ip); sub $0xff, %edx Print(ip); sub $0xff, %edx Print(ip); jle &lt;L1&gt;Print(ip); mov $0x1, %ediPrint(ip); add $0x10, %eaxPrint(ip); 输出轨迹 12345678910$ pin -t itrace -- /bin/lsMakefile imageload.out itrace proccountimageload inscount0 atrace itrace.out$ head -6 itrace.out0x7f20e459b2d00x7f20e459b2d30x7f20e459ea400x7f20e459ea410x7f20e459ea440x7f20e459ea46 ManualExamples/itrace.cpp 12345678910111213141516#include &lt;stdio.h&gt;#include &quot;pin.H&quot;FILE * trace;void printip(void *ip) { fprintf(trace, &quot;%p\\n&quot;, ip); } // 分析程序void Instruction(INS ins, void *v) {INS_InsertCall(ins, IPOINT_BEFORE, (AFUNPTR)printip, IARG_INST_PTR, IARG_END);} // 插桩程序void Fini(INT32 code, void *v) { fclose(trace); }int main(int argc, char * argv[]) {trace = fopen(&quot;itrace.out&quot;, &quot;w&quot;);PIN_Init(argc, argv);INS_AddInstrumentFunction(Instruction, 0);PIN_AddFiniFunction(Fini, 0);PIN_StartProgram();return 0;} 分析程序的参数举例： IARG_INST_PTR 指令指针值（program counter） IARG_UINT32 整型值 IARG_REG_VALUE 指定寄存器的值 IARG_BRANCH_TARGET_ADDR 分支桩的目标地址 IARG_MEMORY_READ_EA 内存读取的有效地址 一个指令的桩的位置 前置（IPOINT_BEFORE） 后置 Fall-through edge（IPOINT_AFTER） Taken edge （IPOINT_TAKEN_BRANCH） 注： 红色代表 IPOINT_BEFORE， 绿色代表 IPOINT_AFTER，黑色代表 IPOINT_TAKEN_BRANCH。 来源 http://www.cs.du.edu/~dconnors/courses/comp3361/notes/PinTutorial 参考 http://terenceli.github.io/技术/2014/01/02/intro-to-pin http://huirong.github.io/2015/12/30/Intel-Pin-introduction/#参考文献","link":"/2016/11/16/Pin_1/"},{"title":"SystemTap学习记录","text":"SystemTap 工具 SystemTap 允许用户在不重新编译代码的情况下利用静态追踪、动态追踪工具，比如在任何地方动态插入printk，或者改变内核的关键数据结构（guru模式）。所有的操作都要以root用户模式下进行。 安装 1$ sudo apt install systemtap systemtap-runtime 安装 kernel debug symbol 1234567891011121314# 16.04 或更高$ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys C8CAB6595FDFF622 # 旧版本$ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys ECDCAD72428D7C01 $ codename=$(lsb_release -c | awk '{print $2}')$ sudo tee /etc/apt/sources.list.d/ddebs.list &lt;&lt; EOFdeb http://ddebs.ubuntu.com/ ${codename} main restricted universe multiversedeb http://ddebs.ubuntu.com/ ${codename}-security main restricted universe multiversedeb http://ddebs.ubuntu.com/ ${codename}-updates main restricted universe multiversedeb http://ddebs.ubuntu.com/ ${codename}-proposed main restricted universe multiverseEOF$ sudo apt-get update$ sudo apt-get install linux-image-$(uname -r)-dbgsym 基础 类 Awk/C 语言 可以嵌入到C语言中（guru 模式） SystemTap Language Reference 指令 限制 SystemTap 可以在内核空间进行追踪，但在用户空间追踪事件取决于内核的支持（Utrace机制） 没有内置于内核中，所以性能比eBPF稍差。 示例 ¶ apps/gmalloc_watch.stp - Tracing glib2 memory allocations The gmalloc_watch.stp script from Colin Walters’ blog traces the allocation of glib2 memory using the markers in glib2. 1# stap gmalloc_watch.stp -T 1 ¶ memory/glibc-malloc.stp - Overview glibc malloc internal operations This script reports on internal statistics of the glibc malloc implementation, as used by a process restricted by stap -x/-c 1# stap glibc-malloc.stp -c 'stap --dump-functions' ¶ memory/numa_faults.stp - Summarize Process Misses across NUMA Nodes The numa_faults.stp script tracks the read and write pages faults for each process. When the script exits it prints out the total read and write pages faults for each process. The script also provide a break down of page faults per node for each process. This script is useful for determining whether the program has good locality (page faults limited to a single node) on a NUMA computer. sample usage in memory/numa_faults.txt …… 火焰图 http://www.brendangregg.com/FlameGraphs/memoryflamegraphs.html 参考 Ubuntu - Systemtap SystemTap man SystemTap Tutorial SystemTap Beginners Guide SystemTap Example FlameGraph","link":"/2020/06/13/SystemTap%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"title":"Python的LRU Cache","text":"functools.lru_cache 在 Python 中的 functools 模块是应用高阶函数，即参数或（和）返回值为其他函数的函数。通常来说，此模块的功能适用于所有可调用对象。 12345678910@functools.cachedef factorial(n): return n * factorial(n-1) if n else 1&gt;&gt;&gt; factorial(10) # no previously cached result, makes 11 recursive calls3628800&gt;&gt;&gt; factorial(5) # just looks up cached value result120&gt;&gt;&gt; factorial(12) # makes two new recursive calls, the other 10 are cached479001600 functools.cache(user_function) 是简单轻量级未绑定函数缓存。 有时称为 “memoize”。返回值与 lru_cache(maxsize=None) 相同，创建一个查找函数参数的字典的简单包装器。 因为它不需要移出旧值，所以比带有大小限制的 lru_cache() 更小更快。` LRU函数的API是@functools.lru_cache(user_function) 和 @functools.lru_cache(maxsize=128, typed=False)，一个为函数提供缓存功能的装饰器，缓存maxsize组传入参数，在下次以相同参数调用时直接返回上一次的结果。用以节约高开销或I/O函数的调用时间。 由于使用了字典存储缓存，所以该函数的固定参数和关键字参数必须是可哈希的。不同模式的参数可能被视为不同从而产生多个缓存项，例如, f(a=1, b=2) 和 f(b=2, a=1) 因其参数顺序不同，可能会被缓存两次。 如果指定了user_function，它必须是一个可调用对象。 这允许 lru_cache 装饰器被直接应用于一个用户自定义函数，让 maxsize 保持其默认值 128: 1234@lru_cachedef count_vowels(sentence): sentence = sentence.casefold() return sum(sentence.count(vowel) for vowel in 'aeiou') 如果maxsize设为None，LRU 特性将被禁用且缓存可无限增长。 如果typed设置为true，不同类型的函数参数将被分别缓存。例如， f(3) 和 f(3.0) 将被视为不同而分别缓存。 被包装的函数配有一个cache_parameters()函数，该函数返回一个新的dict用来显示maxsize和typed的值。 这只是出于显示信息的目的。 改变值没有任何效果。 为了衡量缓存的有效性以便调整maxsize形参，被装饰的函数带有一个cache_info()函数。当调用cache_info()函数时，返回一个具名元组，包含命中次数 hits，未命中次数 misses ，最大缓存数量 maxsize 和 当前缓存大小 currsize。在多线程环境中，命中数与未命中数是不完全准确的。 该装饰器也提供了一个用于清理/使缓存失效的函数cache_clear() 。 原始的未经装饰的函数可以通过 __wrapped__ 属性访问。它可以用于检查、绕过缓存，或使用不同的缓存再次装饰原始函数。 LRU（最久未使用算法）缓存 在最近的调用是即将到来的调用的最佳预测值时性能最好（例如，新闻服务器上最热门文章倾向于每天更改）。 缓存的大小限制可确保缓存不会在长期运行进程如网站服务器上无限制地增长。 一般来说，LRU缓存只在当你想要重用之前计算的结果时使用。因此，用它缓存具有副作用的函数、需要在每次调用时创建不同、易变的对象的函数或者诸如time（）或random（）之类的不纯函数是没有意义的。 静态 Web 内容的 LRU 缓存示例： 12345678910111213141516@lru_cache(maxsize=32)def get_pep(num): 'Retrieve text of a Python Enhancement Proposal' resource = 'http://www.python.org/dev/peps/pep-%04d/' % num try: with urllib.request.urlopen(resource) as s: return s.read() except urllib.error.HTTPError: return 'Not Found'&gt;&gt;&gt; for n in 8, 290, 308, 320, 8, 218, 320, 279, 289, 320, 9991:... pep = get_pep(n)... print(n, len(pep))&gt;&gt;&gt; get_pep.cache_info()CacheInfo(hits=3, misses=8, maxsize=32, currsize=8) 以下是使用缓存通过 动态规划 计算 斐波那契数列 的例子。 1234567891011@lru_cache(maxsize=None)def fib(n): if n &lt; 2: return n return fib(n-1) + fib(n-2)&gt;&gt;&gt; [fib(n) for n in range(16)][0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610]&gt;&gt;&gt; fib.cache_info()CacheInfo(hits=28, misses=16, maxsize=None, currsize=16) Python中的实现 在 CPython 中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209################################################################################### LRU Cache function decorator################################################################################_CacheInfo = namedtuple(&quot;CacheInfo&quot;, [&quot;hits&quot;, &quot;misses&quot;, &quot;maxsize&quot;, &quot;currsize&quot;])class _HashedSeq(list): &quot;&quot;&quot; This class guarantees that hash() will be called no more than once per element. This is important because the lru_cache() will hash the key multiple times on a cache miss. &quot;&quot;&quot; __slots__ = 'hashvalue' def __init__(self, tup, hash=hash): self[:] = tup self.hashvalue = hash(tup) def __hash__(self): return self.hashvaluedef _make_key(args, kwds, typed, kwd_mark = (object(),), fasttypes = {int, str}, tuple=tuple, type=type, len=len): &quot;&quot;&quot;Make a cache key from optionally typed positional and keyword arguments The key is constructed in a way that is flat as possible rather than as a nested structure that would take more memory. If there is only a single argument and its data type is known to cache its hash value, then that argument is returned without a wrapper. This saves space and improves lookup speed. &quot;&quot;&quot; # All of code below relies on kwds preserving the order input by the user. # Formerly, we sorted() the kwds before looping. The new way is *much* # faster; however, it means that f(x=1, y=2) will now be treated as a # distinct call from f(y=2, x=1) which will be cached separately. key = args if kwds: key += kwd_mark for item in kwds.items(): key += item if typed: key += tuple(type(v) for v in args) if kwds: key += tuple(type(v) for v in kwds.values()) elif len(key) == 1 and type(key[0]) in fasttypes: return key[0] return _HashedSeq(key)def lru_cache(maxsize=128, typed=False): &quot;&quot;&quot;Least-recently-used cache decorator. If *maxsize* is set to None, the LRU features are disabled and the cache can grow without bound. If *typed* is True, arguments of different types will be cached separately. For example, f(3.0) and f(3) will be treated as distinct calls with distinct results. Arguments to the cached function must be hashable. View the cache statistics named tuple (hits, misses, maxsize, currsize) with f.cache_info(). Clear the cache and statistics with f.cache_clear(). Access the underlying function with f.__wrapped__. See: http://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU) &quot;&quot;&quot; # Users should only access the lru_cache through its public API: # cache_info, cache_clear, and f.__wrapped__ # The internals of the lru_cache are encapsulated for thread safety and # to allow the implementation to change (including a possible C version). if isinstance(maxsize, int): # Negative maxsize is treated as 0 if maxsize &lt; 0: maxsize = 0 elif callable(maxsize) and isinstance(typed, bool): # The user_function was passed in directly via the maxsize argument user_function, maxsize = maxsize, 128 wrapper = _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo) wrapper.cache_parameters = lambda : {'maxsize': maxsize, 'typed': typed} return update_wrapper(wrapper, user_function) elif maxsize is not None: raise TypeError( 'Expected first argument to be an integer, a callable, or None') def decorating_function(user_function): wrapper = _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo) wrapper.cache_parameters = lambda : {'maxsize': maxsize, 'typed': typed} return update_wrapper(wrapper, user_function) return decorating_functiondef _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo): # Constants shared by all lru cache instances: sentinel = object() # unique object used to signal cache misses make_key = _make_key # build a key from the function arguments PREV, NEXT, KEY, RESULT = 0, 1, 2, 3 # names for the link fields cache = {} hits = misses = 0 full = False cache_get = cache.get # bound method to lookup a key or return None cache_len = cache.__len__ # get cache size without calling len() lock = RLock() # because linkedlist updates aren't threadsafe root = [] # root of the circular doubly linked list root[:] = [root, root, None, None] # initialize by pointing to self if maxsize == 0: def wrapper(*args, **kwds): # No caching -- just a statistics update nonlocal misses misses += 1 result = user_function(*args, **kwds) return result elif maxsize is None: def wrapper(*args, **kwds): # Simple caching without ordering or size limit nonlocal hits, misses key = make_key(args, kwds, typed) result = cache_get(key, sentinel) if result is not sentinel: hits += 1 return result misses += 1 result = user_function(*args, **kwds) cache[key] = result return result else: def wrapper(*args, **kwds): # Size limited caching that tracks accesses by recency nonlocal root, hits, misses, full key = make_key(args, kwds, typed) with lock: link = cache_get(key) if link is not None: # Move the link to the front of the circular queue link_prev, link_next, _key, result = link link_prev[NEXT] = link_next link_next[PREV] = link_prev last = root[PREV] last[NEXT] = root[PREV] = link link[PREV] = last link[NEXT] = root hits += 1 return result misses += 1 result = user_function(*args, **kwds) with lock: if key in cache: # Getting here means that this same key was added to the # cache while the lock was released. Since the link # update is already done, we need only return the # computed result and update the count of misses. pass elif full: # Use the old root to store the new key and result. oldroot = root oldroot[KEY] = key oldroot[RESULT] = result # Empty the oldest link and make it the new root. # Keep a reference to the old key and old result to # prevent their ref counts from going to zero during the # update. That will prevent potentially arbitrary object # clean-up code (i.e. __del__) from running while we're # still adjusting the links. root = oldroot[NEXT] oldkey = root[KEY] oldresult = root[RESULT] root[KEY] = root[RESULT] = None # Now update the cache dictionary. del cache[oldkey] # Save the potentially reentrant cache[key] assignment # for last, after the root and links have been put in # a consistent state. cache[key] = oldroot else: # Put result in a new link at the front of the queue. last = root[PREV] link = [last, root, key, result] last[NEXT] = root[PREV] = cache[key] = link # Use the cache_len bound method instead of the len() function # which could potentially be wrapped in an lru_cache itself. full = (cache_len() &gt;= maxsize) return result def cache_info(): &quot;&quot;&quot;Report cache statistics&quot;&quot;&quot; with lock: return _CacheInfo(hits, misses, maxsize, cache_len()) def cache_clear(): &quot;&quot;&quot;Clear the cache and cache statistics&quot;&quot;&quot; nonlocal hits, misses, full with lock: cache.clear() root[:] = [root, root, None, None] hits = misses = 0 full = False wrapper.cache_info = cache_info wrapper.cache_clear = cache_clear return wrappertry: from _functools import _lru_cache_wrapperexcept ImportError: pass 此外，@cache 函数就是@lru_cache参数memoize设置为None。 1234567################################################################################### cache -- simplified access to the infinity cache################################################################################def cache(user_function, /): 'Simple lightweight unbounded cache. Sometimes called &quot;memoize&quot;.' return lru_cache(maxsize=None)(user_function) methodtools中对lru_cache的修饰 methodtools 对 lru_cache进行了扩展。 123456789101112131415161718192021222324252627282930313233343536373839404142import functoolsfrom wirerope import Wire, WireRope__version__ = '0.4.2'__all__ = 'lru_cache',if hasattr(functools, 'lru_cache'): _functools_lru_cache = functools.lru_cacheelse: try: import functools32 except ImportError: # raise AttributeError about fallback failure functools.lru_cache # install `functools32` to run on py2 else: _functools_lru_cache = functools32.lru_cacheclass _LruCacheWire(Wire): def __init__(self, rope, *args, **kwargs): super(_LruCacheWire, self).__init__(rope, *args, **kwargs) lru_args, lru_kwargs = rope._args wrapper = _functools_lru_cache( *lru_args, **lru_kwargs)(self.__func__) self.__call__ = wrapper self.cache_clear = wrapper.cache_clear self.cache_info = wrapper.cache_info def __call__(self, *args, **kwargs): # descriptor detection support - never called return self.__call__(*args, **kwargs) def _on_property(self): return self.__call__()@functools.wraps(_functools_lru_cache)def lru_cache(*args, **kwargs): return WireRope(_LruCacheWire, wraps=True, rope_args=(args, kwargs)) 参考 https://github.com/youknowone/methodtools https://github.com/python/cpython/tree/3.9 https://realpython.com/lru-cache-python/ [Wirerope](https://github.com/youknowone/wirerope）","link":"/2020/12/30/Python_LRU_Cache/"},{"title":"字典树Trie2","text":"接着上一篇字典树结构的讲解，我们接着使用C++和Python来实现字典树。 一、LeetCode的字典树 在LeetCode 208 要求实现字典树。 Implement a trie with insert, search, and startsWith methods. Note: You may assume that all inputs are consist of lowercase letters a-z. 二、Python实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101# coding:utf-8&quot;&quot;&quot;Implement a trie with insert, search, and startsWith methods.Note:You may assume that all inputs are consist of lowercase letters a-z.Subscribe to see which companies asked this question&quot;&quot;&quot;class TrieNode(object): def __init__(self): &quot;&quot;&quot; Initialize your data structure here. &quot;&quot;&quot; self.data = {} self.is_word = Falseclass Trie(object): def __init__(self): self.root = TrieNode() def insert(self, word): &quot;&quot;&quot; Inserts a word into the trie. :type word: str :rtype: void &quot;&quot;&quot; node = self.root for letter in word: child = node.data.get(letter) if not child: node.data[letter] = TrieNode() node = node.data[letter] node.is_word = True def search(self, word): &quot;&quot;&quot; Returns if the word is in the trie. :type word: str :rtype: bool &quot;&quot;&quot; node = self.root for letter in word: node = node.data.get(letter) if not node: return False return node.is_word # 判断单词是否是完整的存在在trie树中 def starts_with(self, prefix): &quot;&quot;&quot; Returns if there is any word in the trie that starts with the given prefix. :type prefix: str :rtype: bool &quot;&quot;&quot; node = self.root for letter in prefix: node = node.data.get(letter) if not node: return False return True def get_start(self, prefix): &quot;&quot;&quot; Returns words started with prefix :param prefix: :return: words (list) &quot;&quot;&quot; def _get_key(pre, pre_node): words_list = [] if pre_node.is_word: words_list.append(pre) for x in pre_node.data.keys(): words_list.extend(_get_key(pre + str(x), pre_node.data.get(x))) return words_list words = [] if not self.starts_with(prefix): return words if self.search(prefix): words.append(prefix) return words node = self.root for letter in prefix: node = node.data.get(letter) return _get_key(prefix, node)# Your Trie object will be instantiated and called as such:trie = Trie()trie.insert(&quot;somestring&quot;)trie.insert(&quot;somebody&quot;)trie.insert(&quot;somebody1&quot;)trie.insert(&quot;somebody3&quot;)print trie.search(&quot;key&quot;)print trie.search(&quot;somebody3&quot;)print trie.get_start('some') 输出 123456# print trie.search(&quot;key&quot;)False# print trie.search(&quot;somebody3&quot;)True# print trie.get_start('some')['somestring', 'somebody', 'somebody1', 'somebody3'] 采用Class来实现字典树：https://github.com/bdimmick/python-trie/blob/master/trie.py 三、C++实现","link":"/2016/04/26/Trie_2/"},{"title":"Trie字典树","text":"一、字典树 字典树——Trie树，又称为前缀树（Prefix Tree）、单词查找树或键树，是一种多叉树结构。 上图是一棵__Trie__树，表示了关键字集合{“a”, “to”, “tea”, “ted”, “ten”, “i”, “in”, “inn”} 。从上图可以归纳出Trie树的基本性质： 根节点不包含字符，除根节点外的每一个子节点都包含一个字符。 从根节点到某一个节点，路径上经过的字符连接起来，为该节点对应的字符串。 每个节点的所有子节点包含的字符互不相同。 通常在实现的时候，会在结点结构中设置一个标志，用来标记该节点处是否构成一个单词（关键字）。 可以看出，Trie树的关键字一般都是字符串，而且Trie树把每个关键字保存在一条路径上，而不是一个节点中。另外，有两个公共前缀的关键字，在Trie树种前缀部分的路径相同。所以Trie又称为前缀树。 二、字典树的优缺点 优点 插入和查询的效率很高，均是O（m），其中m是待插入/查询的字符串长度。 关于查询，有人会说hash表时间复杂度是O（1）不是更快？但是哈希搜索的效率取决于哈希函数的好坏，若一个坏的hash函数导致了很多冲突，效率不一定比Trie树高 Trie树中不同的关键字不会产生冲突。 Trie树中只有在允许一个关键字关联多个值的情况下才有类似hash碰撞发生。 Trie树不用求hash值，对短字符串有更快的速度。通常，求hash值也是需要遍历字符串的。 Trie树可以对关键字按照字典序排序。 字典排序（lexicographical order）是一种对于随机变量形成序列的排序方法。其方法是，按照字母顺序，或者数字小大顺序，由小到大的形成序列。 每一颗Trie树都可以被看做一个简单版的确定有限状态的自动机（DFA，deterministic finite automation），也就是说，对于一个任意给定属于该自动机的状态（①）和一个属于该自动机字母表的字符（②），都可以根据给定的转移函数（③）转到下一个状态。其中： ① 对于Trie树的每一个节点都确定一个自动机的状态。 ② 给定一个属于该自动机字母表的字符，在图中可以看到根据不同字符形成的分支； ③ 从当前节点进入下一层次节点的过程进过状态转移函数得出。 核心思想是：空间换时间，利用字符串的公共前缀来减少无谓的字符串比较以达到提高查询效率的目的。 缺点 当hash函数很好时，Trie树的查找效率低于哈希搜索。 空间消耗大。 三、Trie树的应用 字符串检索 检索、查询功能是Trie树最原始功能，思路就是从根节点开始一个一个字符进行比较。 如果沿路比较，发现不同的字符，则表示该字符串在集合中不存在。 如果所有的字符全部比较并且完全相同，还需要判断最后一个节点标识位（标记该节点是否为一个关键字）。 词频统计 Trie树常被搜索引擎用于文本词频统计。 思路：为了实现词频统计，我们修改了节点结构，用一个整型变量count来计数。对每一个关键字执行插入操作，若已存在，计数加1，若不存在，插入后count置 1。 、 (1. 2. 都可以用hash table做) 字符串排序 Trie树可以对大量字符串按字典序进行排序，思路也很简单：遍历一次所有关键字，将它们全部插入trie树，树的每个结点的所有儿子很显然地按照字母表排序，然后先序遍历输出Trie树中所有关键字即可。 前缀匹配 例如：找出一个字符串集合中所有以ab开头的字符串。我们只需要用所有字符串构造一个trie树，然后输出以a-&gt;b-&gt;开头的路径上的关键字即可。 trie树前缀匹配常用于搜索提示。如当输入一个网址，可以自动搜索出可能的选择。当没有完全匹配的搜索结果，可以返回前缀最相似的可能。 作为辅助结构 如后缀树，AC自动机 有穷自动机参考这里 与哈希表相比 优点： trie数据查找与不完美哈希表（链表实现）在最坏情况下更快；对于trie树，最差为O（m），m为查找字符串的长度；对于不完美哈希表，会有键值冲突（不同键哈希相同），最坏为O（N），N为全部字符产生的个数。典型情况是O（m）用于哈希计算，O（1）用于数据查找。 trie中不同键没有冲突 trie的桶与哈希表用于存储键冲突的桶类似，仅在单个键与多个值关联时需要 当更多的键加入到trie中，无需提供hash方法或改变hash方法 trie通过键为条目提供字母顺序 缺点： trie数据查找在某些情况下（磁盘或随机访问时间远远高于主存）比哈希表慢 当键值为某些类型（如浮点型），前缀链很长且前缀不是特别有意义。 一些trie会比hash表更消耗内存。对于trie，每个字符串的每个字符都要分配内存；对于大多数hash，只需要为整个条目分配一块内存。 与二叉搜索树相比 二叉搜索树，又称二叉排序树，它满足： 任意节点如果左子树不为空，左子树所有节点的值都小于根节点的值； 任意节点如果右子树不为空，右子树所有节点的值都大于根节点的值； 左右子树也都是二叉搜索树； 所有节点的值都不相同。 其实二叉搜索树的优势已经在与查找、插入的时间复杂度上了，通常只有O(log n)，很多集合都是通过它来实现的。在进行插入的时候，实质上是给树添加新的叶子节点，避免了节点移动，搜索、插入和删除的复杂度等于树的高度，属于O(log n)，最坏情况下整棵树所有的节点都只有一个子节点，完全变成一个线性表，复杂度是O(n)。 Trie树在最坏情况下查找要快过二叉搜索树，如果搜索字符串长度用m来表示的话，它只有O(m)，通常情况（树的节点个数要远大于搜索字符串的长度）下要远小于O(n)。 四、实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;#define ALPHABET_SIZE 26typedef struct trie_node{ int count; // 记录该节点代表的单词的个数 trie_node *children[ALPHABET_SIZE]; // 各个子节点 }*trie;trie_node* create_trie_node(){ trie_node* pNode = new trie_node(); pNode-&gt;count = 0; for(int i=0; i&lt;ALPHABET_SIZE; ++i) pNode-&gt;children[i] = NULL; return pNode;}void trie_insert(trie root, char* key){ trie_node* node = root; char* p = key; while(*p) { if(node-&gt;children[*p-'a'] == NULL) { node-&gt;children[*p-'a'] = create_trie_node(); } node = node-&gt;children[*p-'a']; ++p; } node-&gt;count += 1;}/** * 查询：不存在返回0，存在返回出现的次数 */int trie_search(trie root, char* key){ trie_node* node = root; char* p = key; while(*p &amp;&amp; node!=NULL) { node = node-&gt;children[*p-'a']; ++p; } if(node == NULL) return 0; else return node-&gt;count;}int main(){ // 关键字集合 char keys[][8] = {&quot;the&quot;, &quot;a&quot;, &quot;there&quot;, &quot;answer&quot;, &quot;any&quot;, &quot;by&quot;, &quot;bye&quot;, &quot;their&quot;}; trie root = create_trie_node(); // 创建trie树 for(int i = 0; i &lt; 8; i++) trie_insert(root, keys[i]); // 检索字符串 char s[][32] = {&quot;Present in trie&quot;, &quot;Not present in trie&quot;}; printf(&quot;%s --- %s\\n&quot;, &quot;the&quot;, trie_search(root, &quot;the&quot;)&gt;0?s[0]:s[1]); printf(&quot;%s --- %s\\n&quot;, &quot;these&quot;, trie_search(root, &quot;these&quot;)&gt;0?s[0]:s[1]); printf(&quot;%s --- %s\\n&quot;, &quot;their&quot;, trie_search(root, &quot;their&quot;)&gt;0?s[0]:s[1]); printf(&quot;%s --- %s\\n&quot;, &quot;thaw&quot;, trie_search(root, &quot;thaw&quot;)&gt;0?s[0]:s[1]); return 0;} 对于Trie树，我们一般只实现插入和搜索操作。这段代码可以用来检索单词和统计词频。 五、Trie树改进 按位树（Btiwise Trie）：原理上和普通Trie树差不多，只不过普通Trie树存储的最小单位是字符，但是Bitwise Trie存放的是位而已。位数据的存取由CPU指令一次直接实现，对于二进制数据，它理论上要比普通Trie树快。 节点压缩 ①分支压缩： 对于稳定的Trie树，基本上都是查找和读取的操作，完全可以把一些分支进行压缩。例如，下图中最右侧分支inn可以直接压缩成一个节点“inn”，而不需要作为一个常规子树存在。Radix树就是根据这个原理来解决Trie树过深的问题。 ②节点映射表：这种方式也是Trie树节点可能几乎完全确定下采用的，针对Trie树节点的每一个状态，如果状态总数重复很多的话，通过一个元素为数字的多维数组（比如Triple Array Trie）来表示，这样存储Trie树本身的空间开销会小一些，虽然引入了额外的映射表。 双数组TRIE树（Double Array Trie） 它在保证Trie树检索速度的前提下，提高空间利用率而提出的一种数据结构，本质上还是一个确定有限自动机。（所谓DFA就是一个能够实现状态专一的自动机，对于一个给定的属于该自动机的状态和一个数据该自动机字符表Σ的字符，它能够根据预先给定的状态转移函数转移到下一个状态。） 对于DAT来说，每个节点代表自动机的一个状态， 根据变量的不同，进行状态转移，当达到结束状态或者无法转移时，完成查询。 参考资料：http://blog.csdn.net/zzran/article/details/8462002 六、Trie树的其他形式 上图主要说明下这些算法数据结构之间的关系。图中黄色部分主要写明了这些算法和数据结构的一些关键点。 图中可以看到这样一些关系：extend-kmp 是kmp的扩展；ac自动机是kmp的多串形式；它是一个有限自动机；而trie图实际上是一个确定性有限自动机；ac自动机，trie图，后缀树实际上都是一种trie；后缀数组和后缀树都是与字符串的后缀集合有关的数据结构；trie图中的后缀指针和后缀树中的后缀链接这两个概念及其一致。 七、Trie树的性能比较 参考博客 http://www.hankcs.com/nlp/performance-comparison-of-several-trie-tree.html 参考资料 Trie树 http://www.raychase.net/1783?replytocom=264917 Trie树 http://blog.csdn.net/v_july_v/article/details/6897097 BitWise Trie http://blog.csdn.net/breeze_gao/article/details/8461856 AC自动机 http://www.cppblog.com/menjitianya/archive/2014/07/10/207604.html","link":"/2016/04/25/Trie_1/"},{"title":"分治策略-基础.md","text":"基础思想 分治策略(Divide and Conquer)基本思想： 将原始问题划分或者归结为规模较小的子问题； 递归或迭代求解每个子问题； 将子问题的解综合得到原问题的解。 注意： 子问题和原始问题性质完全一样；（递归基础） 子问题之间可彼此独立地求解； 递归停止时子问题可直接求解。 问题 二分搜索 算法 Binary Search(T, l, r, x) 输入：数组TTT，下标从lll到rrr；数xxx 输出：jjj // 若xxx在TTT中，jjj为下标；否则为000 伪代码： 1234567l ← 1; r ← nwhile l &lt;= r do m ← ⌊(l+r)/2⌋ // m为中间位置 if T[m]=x then return m // x是中位数 else if T[m] &gt; x then r ← m-1 else l ← m+1return 0 思想： 通过xxx与中位数的比较，将原问题归结为规模减半的子问题，如果xxx小于中位数，则子问题由小于xxx的数构成，否则子问题由大于xxx的数构成。 对子问题进行二分检索。 当子问题规模为1时，直接比较x与T[m]，若相等则返回m，否则返回0。 复杂度分析： 二分检索问题最坏情况下的时间复杂度： W(n)=W(⌊n/2⌋)+2W(1)=1解出W(n)=⌊log⁡n⌋+1W(n)=W(\\lfloor n/2 \\rfloor )+2 \\newline W(1)=1 \\newline 解出 \\quad W(n)=\\lfloor\\log{n} \\rfloor + 1 W(n)=W(⌊n/2⌋)+2W(1)=1解出W(n)=⌊logn⌋+1 二分归并排序 算法：Merge Sort(A, p, r) 输入：数组A[p..r] 输出：元素按照从小到大的排序数组A 伪代码： 12345if p &lt; rthen q ← ⌊(p+r)/2⌋ // 对半划分 Merge Sort (A, p, q) // 子问题1 Merge Sort (A, q+1, r) // 子问题2 Merge (A, p, q, r) // 综合解 设计思想： 将原问题化为分规模为n/2的2个子问题； 继续划分，将原问题归结为规模为n/4的4个子问题，继续…，当子问题规模为1时，划分结束。 从规模1到n/2，陆续归并排好序的两个子数组。每归并一次，数组规模扩大一倍，直到原始数组的规模。 时间复杂度的分析： 假设n为2的幂，二分归并排序最坏的情况下时间复杂度： W(n)=2W(n/2)+n−1W(1)=0解出W(n)=nlog⁡n−n+1W(n)=2W(n/2)+n-1 \\\\ W(1)=0 \\\\ 解出 \\quad W(n) = n\\log{n} - n + 1 W(n)=2W(n/2)+n−1W(1)=0解出W(n)=nlogn−n+1 Hanoi塔的递归算法 算法 Hanoi(A, C, n) // n个盘子从A到C 1234if n = 1 then move(A, C) // 1个盘子从A到Celse Hanoi(A, B, n - 1) move(A, C) Hanoi(B, C, n - 1) 设n个盘子的移动次数为T(n) T(n)=2T(n−1)+1T(1)=1T(n)=2n−1T(n) = 2T(n-1)+1 \\\\ T(1) = 1 T(n) = 2^n - 1 T(n)=2T(n−1)+1T(1)=1T(n)=2n−1 算法设计思想 将原问题归结为规模为n-1的2个子问题； 继续归约，将原问题归结为规模为n-2的4个子问题。继续…，当子问题规模为1时，归约过程截止。 从规模1到n-1，陆续组合两个子问题的解。直到规模为n。 分析方法：递推方程。 一般性描述 分治算法 Divide-and-Conquer(P) 12345if |P|&lt;=c then S(P)divide P into P1,P2,...,Pkfor i ← 1 to k yi ← Divide-and-Conquer(Pi)Return Merge(y1, y2, ..., yk) 设计要点 原问题可以划分或者归约为规模较小的子问题 子问题与原问题具有相同的性质 子问题的求解彼此独立 划分时子问题的规模尽可能均衡 子问题规模足够小时可以直接求解 子问题的解综合可以得到原来的解 算法实现：递归或者迭代 分治算法时间分析","link":"/2021/09/17/divide_conquer_1/"},{"title":"何为并发","text":"计算机领域的并发指的是在单个系统里同时执行多个独立的任务，而非顺序的进行一些活动。 使用并发 使用并发的第一种方法，是将应用程序分为多个独立的进程，它们在同一时刻运行，就像同时进行网页浏览和文字处理一样。 优点是进程间通信不复杂，但速度慢、开销大（多个进程有固定的开销：进程的启动、管理进程等）。 在单个进程中运行多个线程。 进程中的所有线程都共享地址空间，并且所有线程访问到大部分数据———全局变量仍然是全局的，指针、对象的引用或数据可以在线程之间传递。 地址空间共享，以及缺少线程间数据的保护，使得操作系统的记录工作量减小，所以使用多线程相关的开销远远小于使用多个进程。不过，共享内存的灵活性是有代价的：如何保证数据的一致性。 为何使用并发？ 分离关注点 —— 基于概念设计 提升性能 利用并发提升性能的方式： 任务并行（task parallelism） 数据并行（data parallelism） 并行化的缺点 使用并发容易造成代码难理解，编写和维护多线程的代码成本提升，同时额外的复杂性可能引起跟多的错误。 使用多线程，系统需要分配内核资源和堆栈空间，开销会对性能产生影响。 同时，线程是有限的资源。过多的线程会使性能整体缓慢。运行越多的线程，操作系统就需要做越多的上下文切换。 使用并发的策略 它拥有大幅度提高应用性能的潜力，但它也可能使代码复杂化，使其更难理解，并更容易出错。因此，只有应用中具有显著增益潜力的性能关键部分，才值得并发化。当然，如果性能收益的潜力仅次于设计清晰或关注点分离，可能也值得使用多线程设计。","link":"/2021/08/16/concurrency/"},{"title":"决策论笔记","text":"决策论概述 决策的内涵 决策是在人们的政治、经济、技术和日常生活中，为了达到预期目的，从所有可供选择的多个方案中，找出最满意方案的一种活动。 狭义决策认为决策就是做决定，单纯强调最终结果。 广义决策认为将管理过程的行为都纳入决策范畴，决策贯穿于整个管理过程中。 决策目标： 决策者希望达到的状态，工作努力的目的。一般而言，在管理决策中决策者追求的当然是利益最大化。 决策准则： 决策判断的标准，备选方案的有效性度量。 决策属性： 决策方案的性能、质量参数、特征和约束，如技术指标、重量、年龄、声誉等，用于评价它达到目标的程度和水平。 科学决策过程：任何科学决策的形成都必须执行科学的决策程序。 决策的基本要素 决策者：决策的主体，一个人或团体。 两个以上可供选择的行动方案，记为djd_jdj​。 状态（事件）：决策实施后可能遇到的自然状况，记为θi\\theta_iθi​。 状态概率：对各状态发生可能性大小进行主观估计，记为P(θi)P(\\theta_i)P(θi​)。 结局（损益）：当决策djd_jdj​实施后遇到的状态θi\\theta_iθi​所产生的的效益（利润）或损失（成本），记为μij\\mu_{ij}μij​，用损益表表示。 损益表 决策的分类 按决策影响范围分类： 战略决策 战术决策 按决策的状态空间分类： 确定型决策： 状态只有一种； 不确定型决策：状态不止一种，且决策者对状态发生的概率未知； 风险型决策：状态不止一种，但决策者对状态发生的概率已知。 按决策的时间分类： 程序决策 非程序决策 半程序决策 按描述方法分类： 定性决策 定量决策 定性与定量相结合 按目标数量分类： 单目标决策 多目标决策 按决策过程的连续性分类： 单级决策 序贯决策 按决策者数量分类： 个人决策 群决策 按问题大小分类： 宏观决策 微观决策 决策的过程 确定目标 收集信息 提出方案 预决策过程 方案优选 决策 决策的模型 决策者 决策方案（属性、目的、目标） 状态 准则 收益 价值观 不确定型决策 不确定型决策：决策者对状态发生的概率一无所知。 A=(aij)A=(a_{ij})A=(aij​)表示iii策略在jjj状态下的收益值，不确定决策方法就是在给定决策矩阵AAA，决策者对状态发生的情况一无所知的情况下如何确定最优决策？ 由于在不确定决策中，各种决策环境是不确定的，所以对于同一个决策问题，用不同的方法求值，将会得到不同的结论，在现实生活中，同一决策问题，决策者偏好不同，也会使得处理相同问题的原则方法不同。 不确定型决策方法 悲观主义准则（maxmin准则） Si∗=max⁡i(min⁡j(aij))S^*_i = \\displaystyle\\max_i(\\min_j(a_{ij}))Si∗​=imax​(jmin​(aij​))，先每行求最小，后各列求最大得最优策略。 乐观主义准则(maxmax准则) Si∗=max⁡i(max⁡j(a∗ij))S^*_i = \\displaystyle\\max_i(\\max_j(a*{ij}))Si∗​=imax​(jmax​(a∗ij))，先每行求最大，后各列求最大得最优策略。 等可能准则 Si∗=max⁡i(∑j=1naijn)S_i^* = \\displaystyle\\max_i(\\sum_{j=1}^n\\frac{a_{ij}}{n})Si∗​=imax​(j=1∑n​naij​​) 先每行求平均值，后各列求最大得最优决策。 最小机会损失准则 先用每列的最大值减去各列元素得到损失矩阵A′A'A′， Si∗=min⁡i(max⁡jaij′)S_i^*=\\displaystyle\\min_i(\\max_ja_{ij}^{'})Si∗​=imin​(jmax​aij′​) 折衷主义准则 先每行分别求最小值、最大值，然后乘上一个乐观系数，以此为标准进行选择。 si∗=max⁡i(αmax⁡j(aij)+(1−α)min⁡j(aij))s_i^*=\\displaystyle\\max_i(\\alpha\\max_j(a_{ij})+(1-\\alpha)\\min_j(a_{ij}))si∗​=imax​(αjmax​(aij​)+(1−α)jmin​(aij​)) 风险型决策 风险型决策：决策者对状态发生概率是已知的。 数学期望方法 Si∗=max⁡i(∑j=1npjaij)S_i^*=\\displaystyle\\max_i(\\sum_{j=1}^n p_j a_{ij})Si∗​=imax​(j=1∑n​pj​aij​) 决策树的组成： 决策节点 状态节点 结果节点（收益） 决策树 □ 表示决策节点。节点中的数字为决策后最优方案的益损期望值。从它引出的分支是方案分支。 ⬭ 表示方案节点。节点中数字为节点号，节点上的数据是该方案的损益期望值。从它引出的分支叫状态分支。在分支上表明状态和出现的概率。 △ 表示结果节点。节点中数字为每一个方案在相应状态下的益损值。 利用决策树进行决策时的两个步骤： 画决策树——从根部到枝部。问题的益损矩阵就是决策树的框图。 决策过程——从枝部到根部。先计算每个行动的益损期望值，再比较各行动方案的值，将最大的期望值保留，同时截去其他方案的分枝。 修正概率方法 贝叶斯决策：开始人们对原来的参数提出了某一个概率分布。后来通过调查又获得许多信息，只要原来的信息不是错误的，则应该用后来的补充信息修正原来的认识。用补充情报改进原来的概率分布。 主观概率：将依据过去的信息或经验由决策者估计的概率称之为主观概率。 先验概率：未收到新信息时根据已有的信息和经验，估计出概率分布称为先验概率。 客观概率：用随机试验确定出的概率称为客观概率。 后验概率：收到新信息，修正后的概率分布称为后验概率。 条件概率：事件B已经发生的条件下，事件A发生的概率，称为事件A在给定B下的条件概率。 P(B∣A)=P(AB)P(A),P(A∣B)=P(AB)P(B)P(B|A)=\\frac{P(AB)}{P(A)}, P(A|B)=\\frac{P(AB)}{P(B)}P(B∣A)=P(A)P(AB)​,P(A∣B)=P(B)P(AB)​ 贝叶斯公式：若A1,A2,…,AnA_1,A_2,\\dots,A_nA1​,A2​,…,An​构成一个完备事件，P(Am)&gt;0P(A_m)&gt;0P(Am​)&gt;0，则对任何概率不为零的时间B，有 P(Am∣B)=P(Am)P(B∣Am)∑iP(Ai)P(B∣Ai),m=1,2,…,nP(A_m|B)=\\frac{P(A_m)P(B|A_m)}{\\displaystyle\\sum_iP(A_i)P(B|A_i)}, \\quad m=1,2,\\dots,nP(Am​∣B)=i∑​P(Ai​)P(B∣Ai​)P(Am​)P(B∣Am​)​,m=1,2,…,n 此公式为后验概率。 效用理论 贝努利（D. Berneulli）首次提出效用概念，他用下图表示出人们对钱财的真实价值的考虑与其钱财拥有量之间的关系，这就是贝努利货币效用函数。 效用是一种相对的指标值，它的大小表示决策者对于风险的态度，对某事物的倾向、偏差等主观因素的强弱程度。 如果每个方案的期望值相等，即用最大期望值决策不合适，可以用最大效用值期望准则。 确定效用曲线的基本方法有两种： 直接提问法，需要决策者回答提问，主观衡量，应用较少； 对比提问法，此方法使用较多。 对比提问法： 设现有A0,A1A_0,A_1A0​,A1​两种方案供选择。A0A_0 A0​表示决策者不需要花费任何风险可获收益x0x_0x0​；而A1A_1A1​有两种自然状态，可以概率PPP获得收益x1x_1x1​，以概率(1−P)(1-P)(1−P)获得收益x2x_2x2​；且x1&gt;x0&gt;x2x_1&gt;x_0&gt;x_2x1​&gt;x0​&gt;x2​； 令yiy_iyi​表示效益xix_ixi​的效用值，则x0,x1,x2x_0,x_1,x_2x0​,x1​,x2​的效用值分别用y0,y1,y2y_0,y_1,y_2y0​,y1​,y2​。若在某条件下，决策者认为A0,A1A_0,A_1A0​,A1​两方案等价，则有： Py1+(1−P)y2=y0Py_1+(1-P)y_2=y_0 Py1​+(1−P)y2​=y0​ 4个数p,x0,x1,x2p,x_0,x_1,x_2p,x0​,x1​,x2​中给定3个，提问第4个变量有决策者决定，求出效用值。 一般采用改进V-M（Von Neumann-Morgenstern）方法，固定P=0.5,x1,x2P=0.5,x_1,x_2P=0.5,x1​,x2​改变x0x_0x0​三次，得出相应的yyy值，确定三点，作出效用曲线。 0.5y(x1)+0.5y(x2)=y(x0)0.5y(x_1)+0.5y(x_2)=y(x_0) 0.5y(x1​)+0.5y(x2​)=y(x0​) 不同决策者对待风险态度不同，因而会得到不同形状的效用曲线。一般可分为保守型I、中间型II、风险型III，如下图 图中I为保守型，其特点为：当收益指较小时，效用值增加较快；随收益值增大时，效用值增加速度变慢，表明决策者不求大利，谨慎小心、保守。 图中II为中间型，其特点为：收益指与效用值成正比，表明决策者完全按机遇办事，心平气和。 图中III为风险型，其特点与I保守型恰好相反，当收益较小时，效用值增加较慢；随收益值增大时，效用值增加速度变快，表明决策者对增加收益反应敏感，愿冒较大风险，谋求大利，不怕冒险。","link":"/2020/05/14/decision_theory/"},{"title":"分治策略-快速排序.md","text":"基础思想 用首元素xxx作划分标准，将输入数组AAA划分成不超过xxx的元素构成的数组ALA_LAL​，大于xxx的元素构成的数组ARA_RAR​。其中，AL,ARA_L,A_RAL​,AR​从左到右存放数组AAA的位置。 递归地堆子问题ALA_LAL​和ARA_RAR​进行排序，直到子问题规模为111时停止。 伪代码 算法：Quicksort(A,p,r) 输入：数组A[p..r] 输出：排好序的数组A 12345if p &lt; r then q &lt;- Partition(A, p, r) A[p]&lt;-&gt;A[q] Quicksort(A, p, q-1) Quicksort(A, q+1, r) 初始置p=1, r=n，然后调用上述算法。 1234567891011x &lt;- A[p]i &lt;- pj &lt;- r + 1while true do repeat j &lt;- j - 1 until A[j] &lt;= x // 不超过首元素的 repeat i &lt;- i + 1 until A[i] &gt; x // 比首元素大的 if i &lt; j then A[i] &lt;-&gt; A[j] else return j 划分时间复杂度 最坏情况： W(n)=W(n−1)+n−1W(1)=0W(n)=n(n−1)/2 W(n)=W(n-1)+n-1 \\\\ W(1)=0 \\\\ W(n)=n(n-1)/2 W(n)=W(n−1)+n−1W(1)=0W(n)=n(n−1)/2 最好情况： T(n)=2T(n/2)+n−1T(1)=0T(n)=Θ(nlog⁡n) T(n) = 2T(n/2)+n-1 \\\\ T(1) = 0 \\\\ T(n) = \\varTheta(n \\log {n}) T(n)=2T(n/2)+n−1T(1)=0T(n)=Θ(nlogn) 利用生成递归树计算复杂度也是O(nlog⁡n)O(n\\log {n})O(nlogn)。 平均时间复杂度 首元素排好序后处在1,2,...,n1,2,...,n1,2,...,n，各种情况概率为1/n1/n1/n。 首元素出现在位置111： T(0),T(n−1)T(0), T(n-1)T(0),T(n−1) 首元素出现在位置222： T(1),T(n−2)T(1), T(n-2)T(1),T(n−2) … 首元素出现在位置n−1n-1n−1: T(n),T(1)T(n), T(1)T(n),T(1) 首元素出现在位置nnn： T(n−1),T(0)T(n-1), T(0)T(n−1),T(0) 子问题工作来量为2[T(1)+T(2)+...+T(n−1)]2[T(1)+T(2)+...+T(n-1)]2[T(1)+T(2)+...+T(n−1)]， 划分工作两为n−1n-1n−1， 即 T(n)=1n∑k=1n−1(T(k)+T(n−k))+n−1T(n)=2n∑k=1n−1T(k)+n−1T(1)=0T(n)=Θ(nlog⁡n) T(n) = \\frac{1}{n}\\sum_{k=1}^{n-1}(T(k)+T(n-k))+n-1 \\\\ T(n) = \\frac{2}{n}\\sum_{k=1}^{n-1}T(k)+n-1 \\\\ T(1) = 0 \\\\ T(n) = \\varTheta(n \\log {n}) T(n)=n1​k=1∑n−1​(T(k)+T(n−k))+n−1T(n)=n2​k=1∑n−1​T(k)+n−1T(1)=0T(n)=Θ(nlogn) 首元素划分后每个位置概率相等。 算法实现 小结 分支策略 子问题划分由首元素决定 最坏情况时间：O(n2)O(n^2)O(n2) 平均情况时间：O(nlog⁡n)O(n\\log{n})O(nlogn)","link":"/2021/09/17/divide_conquer_3/"},{"title":"分治策略-算法设计思想.md","text":"算法设计思想 将原问题归结为规模为n-1的2个子问题； 继续归约，将原问题归结为规模为n-2的4个子问题。继续…，当子问题规模为1时，归约过程截止。 从规模1到n-1，陆续组合两个子问题的解。直到规模为n。 分析方法：递推方程。 一般性描述 分治算法 Divide-and-Conquer(P) 12345if |P|&lt;=c then S(P)divide P into P1,P2,...,Pkfor i ← 1 to k yi ← Divide-and-Conquer(Pi)Return Merge(y1, y2, ..., yk) 设计要点 原问题可以划分或者归约为规模较小的子问题 子问题与原问题具有相同的性质 子问题的求解彼此独立 划分时子问题的规模尽可能均衡 子问题规模足够小时可以直接求解 子问题的解综合可以得到原来的解 算法实现：递归或者迭代 分治算法时间分析 时间复杂度函数的递推方程： W(n)=W(∣P1∣)+W(∣P1∣)+...+W(∣P1∣)+f(n)W(c)=CW(n)=W(|P_1|)+W(|P_1|)+...+W(|P_1|)+f(n) \\\\ W(c)=C W(n)=W(∣P1​∣)+W(∣P1​∣)+...+W(∣P1​∣)+f(n)W(c)=C P1,P2,...,PkP_1, P_2, ..., P_kP1​,P2​,...,Pk​为划分后产生的子问题 f(n)f(n)f(n)为划分子问题以及将子问题的解综合得到原问题解的总工作量 规模为ccc的最小子问题的工作量为CCC 两种常见的递推方程 f(n)=∑i=1kaif(n−i)+g(n)f(n)=af(nb)+d(n)f(n)=\\sum_{i=1}^{k}a_if(n-i)+g(n) \\newline f(n)=af(\\frac{n}{b})+d(n) f(n)=i=1∑k​ai​f(n−i)+g(n)f(n)=af(bn​)+d(n) Hanoi塔，W(n)=2W(n−1)+1W(n)=2W(n-1)+1W(n)=2W(n−1)+1 二分检索，W(n)=W(n/2)+1W(n)=W(n/2)+1W(n)=W(n/2)+1 归并排序，W(n)=2W(n/2)+n−1W(n)=2W(n/2)+n-1W(n)=2W(n/2)+n−1 对于方程1f(n)=∑i=1kaif(n−i)+g(n)f(n)=\\sum_{i=1}^{k}a_if(n-i)+g(n)f(n)=∑i=1k​ai​f(n−i)+g(n)求解方法有迭代法、递归树；对于方程2f(n)=af(nb)+d(n)f(n)=af(\\frac{n}{b})+d(n)f(n)=af(bn​)+d(n)有迭代法、换元法、递归树、主定理。 方程2 方程 T(n)=aT(n/b)+d(n)T(n)=aT(n/b)+d(n)T(n)=aT(n/b)+d(n) d(n)d(n)d(n)为常数时， T(n)={O(nlog⁡ba)a≠1O(log⁡n)a=1T(n) = \\begin{cases} \\Omicron(n^{\\log_ba}) &amp;{a \\neq 1} \\\\ \\Omicron(\\log {n}) &amp;{a = 1} \\end{cases} T(n)={O(nlogb​a)O(logn)​a​=1a=1​ d(n)=cnd(n)=cnd(n)=cn时， T(n)={O(n)a&lt;bO(nlog⁡n)a=bO(nlog⁡ba)a&gt;bT(n) = \\begin{cases} \\Omicron(n) &amp;{a &lt; b} \\\\ \\Omicron(n \\log {n}) &amp;{a = b} \\\\ \\Omicron(n^{\\log_ba}) &amp;{a &gt; b} \\end{cases} T(n)=⎩⎪⎨⎪⎧​O(n)O(nlogn)O(nlogb​a)​a&lt;ba=ba&gt;b​","link":"/2021/09/17/divide_conquer_2/"},{"title":"分治策略-改进.md","text":"减少子问题数 依据 分治算法的时间复杂度方程 W(n)=aW(n/b)+d(n)W(n) = aW(n/b) + d(n) W(n)=aW(n/b)+d(n) aaa：子问题数，n/bn/bn/b：子问题规模，d(n)d(n)d(n)：划分与综合工作量。 当aaa比较大，bbb较小，d(n)d(n)d(n)不大时，方程的解：W(n)=Θ(nlog⁡ba)W(n)=\\varTheta(n^{\\log_b a})W(n)=Θ(nlogb​a)。 减少aaa是降低函数W(n)W(n)W(n)的阶的途径。 利用子问题的依赖关系，使某些子问题的解通过组合其他子问题的解而得到。 例1. 整数位乘问题 输入：X,YX,YX,Y是nnn位二进制数，n=2kn=2^kn=2k 输出：XYXYXY 普通乘法：需要O(n2)O(n^2)O(n2)次乘运算 简单划分，令 X=A2n/2+B,Y=C2n/2+D. X=A2^{n/2}+B, \\quad Y=C2^{n/2}+D.X=A2n/2+B,Y=C2n/2+D. XY=AC2n+(AD+BC)2n/2+BDXY=AC \\quad 2^n + (AD + BC) \\quad 2^{n/2} + BD XY=AC2n+(AD+BC)2n/2+BD 可以得到： W(n)=4W(n/2)+O(n)→W(n)=O(n2)W(n)=4W(n/2)+O(n) \\to W(n)=O(n^2)W(n)=4W(n/2)+O(n)→W(n)=O(n2) 这种划分并没有改善效率，子问题数目为4。 子问题间的依赖关系：代数变换 AD+BC=(A−B)(D−C)+AC+BDAD+BC = (A-B)(D-C) + AC + BDAD+BC=(A−B)(D−C)+AC+BD AC,BDAC,BDAC,BD可以利用之前的解，所以优化后为三个子问题。 算法复杂度： W(n)=3W(n/2)+cnW(1)=1W(n) = 3W(n/2)+cn \\\\ W(1)=1W(n)=3W(n/2)+cnW(1)=1 方程的解： W(n)=O(nlog⁡3)=O(n1.59)W(n) = O(n^{\\log 3}) = O(n^{1.59})W(n)=O(nlog3)=O(n1.59) 例2. 矩阵相乘的问题 输入： 输出： 小结 适用于：子问题个数多，划分和综合工作量不太大，时间复杂度函数为W(n)=Θ(nlog⁡ba)W(n) = \\varTheta(n^{\\log_b a})W(n)=Θ(nlogb​a) 利用子问题之间的依赖关系，用某些子问题解的代数表达式表示另一些子问题的解，减少独立计算子问题的个数。 综合解的工作量可能会增加，但增加的工作量不会影响W(n)W(n)W(n)的阶。 增加预处理 例子：平面点对的问题 输入： 平面点集PPP中有nnn个点，n&gt;1n&gt;1n&gt;1 输出：PPP中的两个点，其距离最小 蛮力算法：C(n,2)C(n,2)C(n,2)个点对，计算最小距离，O(n2)O(n^2)O(n2) 分治策略：PPP划分为大小相等的PLP_LPL​和PRP_RPR​ 分别计算PL,PRP_L, P_RPL​,PR​中最近点对 计算PLP_LPL​与PRP_RPR​中各一个点的最近点对 上述情况下的最近点是解。 总结 依据 W(n)=aW(n/b)+f(n)W(n)=aW(n/b)+f(n)W(n)=aW(n/b)+f(n) 提高算法效率的方法 减少子问题个数aaa W(n)=O(nlog⁡ba)W(n)=O(n^{\\log_b a})W(n)=O(nlogb​a) 增加与处理，减少f(n)f(n)f(n)","link":"/2021/09/17/divide_conquer_5/"},{"title":"分治策略-幂乘问题.md","text":"幂乘问题 输入：aaa为给定实数，nnn为自然数 输出：ana^nan 传统算法思想 顺序相乘 an=(...(((aa)a)a)...)aa^n=(...(((a\\quad a)a)a)...)aan=(...(((aa)a)a)...)a 乘法次数：Θ(n)\\varTheta (n)Θ(n) 分治算法——划分 nnn为偶数：a......a⏟n/2个∣a......a⏟n/2个\\underbrace{a......a}_{\\text{n/2个}}|\\underbrace{a......a}_{\\text{n/2个}}n/2个a......a​​∣n/2个a......a​​ nnn为奇数：a......a⏟(n-1)/2个∣a......a⏟(n-1)/2个∣a\\underbrace{a......a}_{\\text{(n-1)/2个}}|\\underbrace{a......a}_{\\text{(n-1)/2个}}|a(n-1)/2个a......a​​∣(n-1)/2个a......a​​∣a 解： an={an/2×an/2n为偶数a(n−1)/2×a(n−1)/2n为奇数a^n = \\begin{cases} a^{n/2} \\times a^{n/2} &amp;{n为偶数} \\\\ a^{(n-1)/2} \\times a^{(n-1)/2} &amp;{n为奇数} \\end{cases} an={an/2×an/2a(n−1)/2×a(n−1)/2​n为偶数n为奇数​ 分治算法分析 以乘法作为基本运算： 子问题规模：不超过n/2n/2n/2 两个规模近似n/2n/2n/2的子问题完全一样，只要计算1次 W(n)=W(n/2)+Θ(1)W(n)=Θ(log⁡n)W(n)=W(n/2) + \\varTheta (1) \\\\ W(n)=\\varTheta (\\log {n}) W(n)=W(n/2)+Θ(1)W(n)=Θ(logn) 幂乘算法的应用 Fibonacci数列：1,1,2,3,5,8,13,21,...1,1,2,3,5,8,13,21,...1,1,2,3,5,8,13,21,... 增加F0=0F_0=0F0​=0，得到数列0,1,1,2,3,5,8,13,21,...0,1,1,2,3,5,8,13,21,...0,1,1,2,3,5,8,13,21,... 问题：已知F0=0,F1=1F_0=0,F_1=1F0​=0,F1​=1，给定nnn，计算FnF_nFn​ 通常算法：从F0,F1,...F_0,F_1,...F0​,F1​,...开始，根据递推公式 Fn=Fn−1+Fn−2F_n=F_{n-1}+F_{n-2} Fn​=Fn−1​+Fn−2​ 持续相加可以得到FnF_nFn​，时间复杂度为Θ(n)\\varTheta (n)Θ(n)。 Fibonacci数的性质 定理1 设Fn{F_n}Fn​为Fibonacci数构成的数列，那么 [Fn+1FnFnFn−1]=[1110]n\\begin{bmatrix} F_{n+1} &amp; F_{n} \\\\ F_n &amp; F_{n-1} \\end{bmatrix} = {\\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix}}^{n} [Fn+1​Fn​​Fn​Fn−1​​]=[11​10​]n 归纳证明， n=1n=1n=1时, 左边=[F2F1F1F0]=[1110]n=右边左边 = \\begin{bmatrix} F_{2} &amp; F_{1} \\\\ F_1 &amp; F_{0} \\end{bmatrix} = {\\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix}}^{n} = 右边左边=[F2​F1​​F1​F0​​]=[11​10​]n=右边, 假设对任意正整数nnn，命题成立，即 [Fn+1FnFnFn−1]=[1110]n\\begin{bmatrix} F_{n+1} &amp; F_{n} \\\\ F_n &amp; F_{n-1} \\end{bmatrix} = {\\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix}}^{n} [Fn+1​Fn​​Fn​Fn−1​​]=[11​10​]n 那么， [Fn+2Fn+1Fn+1Fn]=[Fn+1FnFnFn−1][1110]=[1110]n[1110]=[1110]n+1\\begin{bmatrix} F_{n+2} &amp; F_{n+1} \\\\ F_{n+1} &amp; F_{n} \\end{bmatrix} = \\begin{bmatrix} F_{n+1} &amp; F_{n} \\\\ F_n &amp; F_{n-1} \\end{bmatrix} \\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix} = {\\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix}}^{n} \\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix} = {\\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix}}^{n+1} [Fn+2​Fn+1​​Fn+1​Fn​​]=[Fn+1​Fn​​Fn​Fn−1​​][11​10​]=[11​10​]n[11​10​]=[11​10​]n+1 算法 令矩阵M=[1110]M=\\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix}M=[11​10​]，用幂乘算法计算MnM^nMn时间复杂度： 矩阵乘法次数 T(n)=Θ(log⁡n)T(n)=\\varTheta (\\log {n})T(n)=Θ(logn) 每次矩阵乘法需要做8次元素相乘 总计元素相乘次数为Θ(log⁡n)\\varTheta (\\log {n})Θ(logn) 使用Python实现的算法: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159import mathimport decimalfrom timeit import default_timer as timerfrom typing import Callable, OrderedDict, Tuple, Listfrom functools import lru_cacheclass Fibonacci: num: int times: OrderedDict memory: List[int] MAXSIZE: int def _get_time(self, fn: Callable) -&gt; Tuple[float, int]: start = timer() result = fn() end = timer() return end - start, result def __init__(self, num: int) -&gt; None: self.num = num self.times = {} self.MAXSIZE = 10000 def print_results(self): print(&quot;-------------------------------------&quot;) print(&quot;n = {}&quot;.format(self.num)) for k, v in self.times.items(): print(&quot;{0}： \\t时间为\\t{1}微秒，\\t结果为{2}。&quot;.format(k, round(decimal.Decimal(v[0] * math.pow(10, 6)), 1), v[1])) def _fib_1(self, n: int) -&gt; int: if n == 0: return 0 if n == 1: return 1 return self._fib_1(n-1) + self._fib_1(n-2) @lru_cache(maxsize=20) def _fib_2(self, n: int) -&gt; int: if n == 0: return 0 if n == 1: return 1 return self._fib_2(n-1) + self._fib_2(n-2) def _fib_3(self, n: int) -&gt; int: pre = 0 next = 1 result = 0 if n == 0: return pre if n == 1: return next while (n := n - 1) &gt;= 1: # 注意n的值 result = pre + next pre = next next = result return result def _fib_4(self, n: int) -&gt; int: t = math.sqrt(5.0) # result = (int) ((math.pow(((1 + math.sqrt(5.0)) / 2), n) - math.pow(((1 - math.sqrt(5.0)) / 2), n)) / math.sqrt(5.0)) result = (int) ((math.pow(((1 + t) / 2), n) - math.pow(((1 - t) / 2), n)) / t) # 速度快 return result def _fib_5(self, n: int) -&gt; int: if n == 0 or n == 1: return n em = [[1, 1], [1, 0]] return self._matrixPow(em, n + 1)[1][1] def _fib_6(self, n: int) -&gt; int: if n == 0 or n == 1: return n em = [[0, 1], [0, 0]] # 系数 rhm = [[0, 1], [1, 1]] return self._matrixMultiply(em, self._matrixPow(rhm, n - 1))[0][1] def _matrixMultiply(self, x: List[List[int]], y: List[List[int]]) -&gt; List[List[int]]: # https://stackoverflow.com/a/10508239 # zip_rhm = list(zip(*rhm)) # return [[sum(map(lambda x, y: x * y, row_lhm, col_rhm)) for col_rhm in zip_rhm] for row_lhm in lhm] return [[x[0][0] * y[0][0] + x[0][1] * y[0][1], x[0][0] * y[0][1] + x[0][1] * y[1][1]], [x[1][0] * y[0][0] + x[1][1] * y[0][1], x[1][0] * y[1][0] + x[1][1] * y[1][1]]] def _matrixPow(self, m: List[List[int]], n: int) -&gt; List[List[int]]: r = m res = [[1, 0], [0, 1]] # while n != 0: # if n &amp; 1 == 1: # res = self._matrixMultiply(res, r) # r = self._matrixMultiply(r, r) # n &gt;&gt;= 1 n &lt;&lt;= 1 while (n := n &gt;&gt; 1) != 0: if n &amp; 1 == 1: res = self._matrixMultiply(res, r) r = self._matrixMultiply(r, r) return res def _fib_7(self, n: int) -&gt; int: if n == 0 or n == 1: return n if n == 2: return 1 self.memory = [-1 for x in range(n+1)] self.memory[0] = 0 self.memory[1] = 1 self.memory[2] = 1 for i in range(3, n + 1): self.memory[i] = self.memory[i-1] + self.memory[i-2] return self.memory[n] def _fib_8(self, n: int) -&gt; int: if n == 0 or n == 1: return n if n == 2: return 1 self.memory = [0, 1, 1] for i in range(3, n+1): self.memory[i%3] = self.memory[(i-2)%3] + self.memory[(i-1)%3] return self.memory[n%3] def _memory_reset(self): self.memory = [-1 for i in range(self.num + 1)] def _fib_9(self, n: int) -&gt; int: if n == 0: return 0 if n == 1: return 1 if self.memory[n] == -1: self.memory[n] = self._fib_9(n-1) + self._fib_9(n-2) return self.memory[n] def run(self): # self.times[&quot;递归法&quot;] = self._get_time(lambda: self._fib_1(self.num)) self.times[&quot;递归cache法&quot;] = self._get_time(lambda: self._fib_2(self.num)) self.times[&quot;迭代法&quot;] = self._get_time(lambda: self._fib_3(self.num)) self.times[&quot;公式法&quot;] = self._get_time(lambda: self._fib_4(self.num)) self.times[&quot;矩阵法1&quot;] = self._get_time(lambda: self._fib_5(self.num)) self.times[&quot;矩阵法2&quot;] = self._get_time(lambda: self._fib_6(self.num)) self.times[&quot;动态规划&quot;] = self._get_time(lambda: self._fib_7(self.num)) self.times[&quot;动态规划压缩&quot;] = self._get_time(lambda: self._fib_8(self.num)) self._memory_reset() self.times[&quot;记忆法&quot;] = self._get_time(lambda: self._fib_9(self.num)) if __name__ == '__main__': f_1 = Fibonacci(25) f_1.run() f_1.print_results() f_2 = Fibonacci(44) f_2.run() f_2.print_results() 输出结果： 12345678910111213141516171819202122-------------------------------------n = 25递归法： 时间为 17734.4微秒， 结果为75025。递归cache法： 时间为 14.9微秒， 结果为75025。迭代法： 时间为 3.3微秒， 结果为75025。公式法： 时间为 12.2微秒， 结果为75025。矩阵法1： 时间为 9.5微秒， 结果为75025。矩阵法2： 时间为 6.7微秒， 结果为75025。动态规划： 时间为 8.5微秒， 结果为75025。动态规划压缩： 时间为 7.9微秒， 结果为75025。记忆法： 时间为 14.7微秒， 结果为75025。-------------------------------------n = 44递归法： 时间为 212522669.9微秒，结果为701408733。递归cache法： 时间为 32.4微秒， 结果为701408733。迭代法： 时间为 16.9微秒， 结果为701408733。公式法： 时间为 2.0微秒， 结果为701408733。矩阵法1： 时间为 13.6微秒， 结果为701408733。矩阵法2： 时间为 14.7微秒， 结果为701408733。动态规划： 时间为 12.2微秒， 结果为701408733。动态规划压缩： 时间为 16.8微秒， 结果为701408733。记忆法： 时间为 53.0微秒， 结果为701408733。 本文中介绍的矩阵是矩阵法2。","link":"/2021/09/17/divide_conquer_4/"},{"title":"分治策略-典型算法.md","text":"选择问题 选最大和最小 输入：集合LLL（含nnn个不等的实数） 输出：LLL中的第iii小的元素 i=1i=1i=1，称为最小元素 i=ni=ni=n，称为最大元素 位置处在中间爱你位置的元素，成为中位元素。 nnn为奇数，中位数唯一，i=(n+1)/2i=(n+1)/2i=(n+1)/2。 nnn为偶数，可指定为i=n/2+1i=n/2+1i=n/2+1。 选最大算法：顺序比较，在最坏情况下的时间为W(n)=n−1W(n)=n-1W(n)=n−1。 代码为： 123456789101112def max_value(numbers: List[int]) -&gt; Tuple[int, int]: if not numbers: return (-1, -1) if len(numbers) == 1: return (0, numbers[0]) m = numbers[0], k = 0 for i in range(1, len(numbers)): if m &lt; numbers[i]: m = numbers[i] k = i return (k, m) 选最大最小通常算法： 比较算法，先选最大max 顺序比较，在剩余数组中选最小min，类似于选最大算法，但比较时保留最小值。 时间复杂度：W(n)=n−1+n−2=2n−3W(n)=n-1 + n-2 = 2n -3W(n)=n−1+n−2=2n−3 分组算法解决最大最小值： 输入：n个数的数组L 输出：max，min 将n个元素两两一组分成⌊n/2⌋\\lfloor n/2 \\rfloor⌊n/2⌋组。 每组比较，得到⌊n/2⌋\\lfloor n/2 \\rfloor⌊n/2⌋个较小和⌊n/2⌋\\lfloor n/2 \\rfloor⌊n/2⌋个较大的。 在⌈n/2⌉\\lceil n/2 \\rceil⌈n/2⌉个较大（含轮空元素）找最大max 在⌈n/2⌉\\lceil n/2 \\rceil⌈n/2⌉个比较（含轮空元素）中找最小min 时间复杂度： 在上述代码2中，组内比较⌊n/2⌋\\lfloor n/2 \\rfloor⌊n/2⌋次。 在3-4行内求max和min比较，最多2×(⌈n/2⌉−1)2 \\times (\\lceil n/2 \\rceil - 1)2×(⌈n/2⌉−1)次。 即W(n)=⌊n/2⌋+2×⌈n/2⌉−2=n+⌈n/2⌉−2=⌈3n/2⌉−2W(n)=\\lfloor n/2 \\rfloor + 2 \\times \\lceil n/2 \\rceil - 2 \\\\ = n + \\lceil n/2 \\rceil - 2 \\\\ = \\lceil 3n/2 \\rceil -2W(n)=⌊n/2⌋+2×⌈n/2⌉−2=n+⌈n/2⌉−2=⌈3n/2⌉−2 分治算法： 将数组LLL从中间划分为2个子数组L1,L2L_1, L_2L1​,L2​ 递归地在L1L_1L1​中求最大的max1max_1max1​和min1min_1min1​ 递归地在L2L_2L2​中求最大的max2max_2max2​和min2min_2min2​ max←max⁡{max1,max2}max \\gets \\max{\\{max_1, max_2\\}}max←max{max1​,max2​} min←min⁡{min1,min2}min \\gets \\min {\\{min_1, min_2\\}}min←min{min1​,min2​} 代码： 1234567891011121314151617181920import mathfrom typing import List, Tupledef max_min(arr: List[int]) -&gt; Tuple[int, int]: i, j = 0, len(arr) - 1 if i == j: return [arr[i], arr[i]] elif i == j - 1: return [arr[i], arr[j]] if arr[i] &gt; arr[j] else [arr[j], arr[i]] else: mid = math.floor(j/2) max1, min1 = max_min(arr[i : mid]) max2, min2 = max_min(arr[mid : j + 1]) return [max(max1, max2), min(min1, min2)]if __name__ == &quot;__main__&quot;: arr = [6, 10, 32, 8, 19, 20, 222, 14, 53, 1] max_value, min_value = max_min(arr) print(max_value, min_value) # 222, 1 最坏情况复杂度： 假设n=2k,W(n)=2W(n/2)+2W(2)=1\\quad n=2^k, \\\\ \\quad\\quad W(n) = 2W(n/2) + 2 \\\\ \\quad\\quad W(2)=1n=2k,W(n)=2W(n/2)+2W(2)=1 解 W(2k)=2W(2k−1)+2=2[2W(2k−2)+2]+2=22W(2k−2)+22+2=...2k−1+2k−1+...+22+2=3×2k−1−2=3n/2−2W(2^k) = 2W(2^{k-1}) + 2 \\\\ = 2 [ 2W(2^{k-2}) + 2] +2 \\\\ = 2^2W(2^{k-2})+2^2+2=... \\\\ 2^{k-1} + 2^{k-1} + ... + 2^2 + 2 \\\\ = 3 \\times 2^{k-1} -2 =3n/2-2 W(2k)=2W(2k−1)+2=2[2W(2k−2)+2]+2=22W(2k−2)+22+2=...2k−1+2k−1+...+22+2=3×2k−1−2=3n/2−2 选择算法小结： 选最大：顺序比较，比较次数n−1n-1n−1 选最大最小： 选择最大+最小，比较次数2n−32n-32n−3 分组：比较次数⌈3n/2⌉−2\\lceil 3n/2 \\rceil -2⌈3n/2⌉−2 分治：n=2kn=2^kn=2k，比较次数3n/2−23n/2-23n/2−2 选第二大问题 输入：nnn个数的数组LLL 输出：第二大的数SecondSecondSecond 通常算法：顺序比较 顺序比较找到最大的maxmaxmax 从剩下n−1n-1n−1个数中找最大，就是第二大的secondsecondsecond 时间复杂度：W(n)=n−1+n−2=2n−3W(n)=n-1+n-2=2n-3W(n)=n−1+n−2=2n−3 (比较次数) 提高效率的途径 成为第二大数的条件：仅在与最大数的比较中被淘汰 要确定第二大数，必须知道最大数 在确定最大数的过程中被记录下的最大数直接淘汰的元素 在上述范围内（被最大数直接淘汰的数）内最大数就是第二大数 (使用空间换时间) 锦标赛算法 两两分组比较，大的进入下一轮，直到剩下1个元素maxmaxmax为止； 在每次比较中淘汰较小的元素，将被淘汰元素记录在淘汰他的元素的链表上。 检查maxmaxmax的链表，从中找到最大元素，即secodesecodesecode。 伪代码： k &lt;- n // 参与淘汰的元素数字 将k个元素两两1组，分成⌊k/2⌋\\lfloor k/2 \\rfloor⌊k/2⌋组 每组的2个数比较，找到较大数 将被淘汰数记入较大数的链表 如果 k 为奇数，那么 k←⌊k/2⌋+1k \\gets \\lfloor k/2 \\rfloor + 1k←⌊k/2⌋+1 否则 k←⌊k/2⌋k\\gets \\lfloor k/2\\rfloork←⌊k/2⌋ 如果k&gt;1k&gt;1k&gt;1，那么转到步骤2 max ←\\gets← 最大数 second ←\\gets← max的链表中最大 其中，1-4是一轮淘汰，7为继续分组淘汰 时间复杂度分析： 命题1 设参与比较的元素有ttt个元素，经过iii轮淘汰后元素至多为⌈t/2i⌉\\lceil t/2^i \\rceil⌈t/2i⌉。 证 对iii归纳。i=1i=1i=1，分⌊t/2⌋\\lfloor t/2 \\rfloor⌊t/2⌋，淘汰⌊t/2⌋\\lfloor t/2 \\rfloor⌊t/2⌋个元素，进入下一轮的元素是t−⌊t/2⌋=⌈t/2⌉t - \\lfloor t/2 \\rfloor = \\lceil t/2 \\rceilt−⌊t/2⌋=⌈t/2⌉。 假设iii轮分组淘汰后元素数至多为⌈t/2i⌉\\lceil t/2^i \\rceil⌈t/2i⌉，那么i+1i+1i+1轮分组淘汰后元素为： ⌈⌈t/2i⌉/2⌉=⌈t/2i+1⌉\\lceil \\lceil t / 2 ^ i\\rceil / 2 \\rceil = \\lceil t/2^{i+1}\\rceil⌈⌈t/2i⌉/2⌉=⌈t/2i+1⌉ 命题2 maxmaxmax在第一阶段分组比较中总计进行了⌈log⁡n⌉\\lceil \\log n \\rceil⌈logn⌉次比较。 证 假设到产生maxmaxmax时总计进行kkk轮淘汰，根据 命题1 有⌈n/2k⌉=1\\lceil n/2^k \\rceil = 1⌈n/2k⌉=1。 若n=2dn=2^dn=2d，那么有k=d=log⁡n=⌈log⁡n⌉k=d=\\log {n}=\\lceil \\log n \\rceilk=d=logn=⌈logn⌉； 若 2d&lt;n&lt;2d+12^d&lt;n&lt;2^{d+1}2d&lt;n&lt;2d+1 ，那么有k=d+1=⌈log⁡n⌉k=d+1=\\lceil \\log n \\rceilk=d+1=⌈logn⌉。 综上， 第一阶段元素数：nnn 比较次数：n−1n-1n−1 淘汰了n−1n-1n−1个元素 第二阶段：元素数⌈log⁡n⌉\\lceil \\log n \\rceil⌈logn⌉ 比较次数：⌈log⁡n⌉−1\\lceil \\log n \\rceil - 1⌈logn⌉−1 淘汰元素数为⌈log⁡n⌉−1\\lceil \\log n \\rceil - 1⌈logn⌉−1 时间复杂度W(n)=n+⌈log⁡n⌉−2W(n)=n + \\lceil \\log {n} \\rceil -2W(n)=n+⌈logn⌉−2 第二大小结 求第二大算法： 调用2次找最大：2n−32n-32n−3 锦标赛算法：用空间换取时间。 一般选择算法的设计 问题：选第k小 输入：数组SSS，SSS的长度nnn，正整数k，1≤k≤nk，1\\le k\\le nk，1≤k≤n 输出：第k小的数 例子 S={3,4,8,2,5,9,18},k=4S=\\{3, 4, 8, 2, 5, 9, 18\\}, k=4S={3,4,8,2,5,9,18},k=4，解：5 统计数据的集合S，∣S∣=nS，|S|=nS，∣S∣=n，选中位数，k=⌈n/2⌉k=\\lceil n/2\\rceilk=⌈n/2⌉ 选择算法的分析 伪码 算法 Select(S, k) 将S分成5个一组，共nM=⌈n/5⌉n_M=\\lceil n/5 \\rceilnM​=⌈n/5⌉组 每组排序，中位数防盗集合M m∗←Select(M,⌈M/2⌉)m^* \\gets Select(M,\\lceil M/2 \\rceil)m∗←Select(M,⌈M/2⌉) // S分A，B，C，D A,D元素小于 m∗m^*m∗ 放 S1S_1S1​，大于 m∗m^*m∗ 放 S2S_2S2​。 S1←S1∪C;S2←S2∪BS_1 \\gets S_1 \\cup C; \\quad S_2 \\gets S_2 \\cup BS1​←S1​∪C;S2​←S2​∪B if k=∣S1∣+1k=|S_1| + 1k=∣S1​∣+1 then 输出 m∗m^*m∗ else if k≤∣S1∣k \\le |S_1|k≤∣S1​∣ then Select(S1S_1S1​,k) then Select(S2S_2S2​,k-∣S1∣|S_1|∣S1​∣-1) 用m*划分 n=5(2r+1),∣A∣=∣D∣=2r\\large n=5(2r+1),|A|=|D|=2rn=5(2r+1),∣A∣=∣D∣=2r 子问题规模至多：2r+2r+3r+2=7r+2\\large 2r+2r+3r+2=7r+22r+2r+3r+2=7r+2 子问题规模估计 不妨设n=5(2r+1)\\large n=5(2r+1)n=5(2r+1)，∣A∣=∣D∣=2r\\large |A|=|D|=2r∣A∣=∣D∣=2r， r=n/5−12=n10−12\\large r=\\frac{n/5-1}{2}=\\frac{n}{10}-\\frac{1}{2}r=2n/5−1​=10n​−21​ 划分后子问题规模至多为: 7r+2=7(n10−12+2)=7n10−32&lt;7n10\\large 7r+2=7(\\frac{n}{10}-\\frac{1}{2}+2) \\\\ =\\frac{7n}{10} - \\frac{3}{2} &lt; \\frac{7n}{10}7r+2=7(10n​−21​+2)=107n​−23​&lt;107n​ 时间复杂度递推方程 算法工作量W(n)W(n)W(n) 行2：O(n)O(n)O(n) // 每5个数找中位数，构成M 行3：W(n/5)W(n/5)W(n/5) // M中找中位数m∗m^*m∗ 行4：O(n)O(n)O(n) // 用m∗m^*m∗划分集合S 行8-9：W(7n/10)W(7n/10)W(7n/10) // 递归 W(n)≤W(n/5)+W(7n/10)+O(n)\\large W(n) \\le W(n/5) + W(7n/10) + O(n)W(n)≤W(n/5)+W(7n/10)+O(n) 递归树 W(n)≤W(n/5)+W(7n/10)+O(n)\\large W(n) \\le W(n/5) + W(7n/10) + O(n)W(n)≤W(n/5)+W(7n/10)+O(n) W(n)≤cn(1+0.9+0.92+...)=O(n)\\large W(n) \\le cn(1+0.9+{0.9}^2+...)=O(n)W(n)≤cn(1+0.9+0.92+...)=O(n) 讨论 为什么使用5个一组，而不是3个一组或者7个一组？ 分析：递归调用 求m∗m^*m∗的工作量与∣M∣=n/t|M|=n/t∣M∣=n/t相关，ttt为每组元素数，ttt大，∣M∣|M|∣M∣小。 归约后子问题大小与分组元素数ttt有关，ttt大，子问题的规模大。 3分组时的子问题规模 假设t=3t=3t=3，3个一组： n=3(2r+1)r=(n/3−1)/2=n/6−1/2n=3(2r+1) \\\\ r=(n/3-1)/2=n/6-1/2n=3(2r+1)r=(n/3−1)/2=n/6−1/2 子问题规模最多为4r+1=4n/6−14r+1=4n/6-14r+1=4n/6−1 算法时间复杂度 算法时间复杂度满足方程： W(n)=W(n/3)+W(4n/6)+cnW(n)=W(n/3)+W(4n/6)+cnW(n)=W(n/3)+W(4n/6)+cn 由递归树得到W(n)=Θ(nlog⁡n)W(n)=\\varTheta (n \\log n)W(n)=Θ(nlogn) 关键点： ∣M∣|M|∣M∣与归月后子问题规模值和小于nnn 递归树每行的工作量构成公比小于1的等比级数，算法的复杂度才是O(n)O(n)O(n)。","link":"/2021/09/23/divide_conquer_6/"},{"title":"分治策略-卷积","text":"卷积及其应用 向量计算 给定向量： a=(a0,a1,...,an−1)a=(a_0, a_1, ..., a_{n-1})a=(a0​,a1​,...,an−1​) b=(b0,b1,...,an−1)b=(b_0, b_1, ..., a_{n-1})b=(b0​,b1​,...,an−1​) 向量和： a+b=(a0+b0,a1+b1,...,an−1+bn−1a+b=(a_0+b_0,a_1+b_1,...,a_{n-1}+b_{n-1}a+b=(a0​+b0​,a1​+b1​,...,an−1​+bn−1​ 内积： a⋅b=a0b0+a1b1+...+an−1bn−1a \\cdot b=a_0b_0+a_1b_1+...+a_{n-1}b_{n-1}a⋅b=a0​b0​+a1​b1​+...+an−1​bn−1​ 卷积： a∗b=(c0,c1,...,c2n−2)a*b=(c_0,c_1,...,c_{2n-2})a∗b=(c0​,c1​,...,c2n−2​)，其中ck=∑i+j=ki,j&lt;naibj,k=0,1,2,...,2n−2\\large c_k=\\sum\\limits_{i+j=k \\atop i,j&lt;n}a_ib_j, \\\\ \\quad k=0,1,2,...,2n-2ck​=i,j&lt;ni+j=k​∑​ai​bj​,k=0,1,2,...,2n−2 卷积的意义：在下述矩阵中，每个斜线的项之和恰好是卷积中的各个分量。 ab0ab1...abn−2abn−1a0ba0b0a0b1...a0bn−2a0bn−1a1ba1b0a1b1...a1bn−2a1bn−1⋮⋮⋮⋮⋮an−2ban−2b0an−2b1...an−2bn−2an−2bn−1an−1ban−1b0an−1b1...an−1bn−2an−1bn−1\\Large {\\begin{array}{cc} &amp; \\color{blue}{ab_0} &amp; \\color{blue}{ab_1} &amp; \\color{blue}{...} &amp; \\color{blue}{ab_{n-2}} &amp; \\color{blue}{ab_{n-1}} \\\\ \\color{blue}{a_0b} &amp; a_0b_0 &amp; a_0b_1 &amp; ... &amp; a_0b_{n-2} &amp; a_0b_{n-1} \\\\ \\color{blue}{a_1b} &amp; a_1b_0 &amp; a_1b_1 &amp; ... &amp; a_1b_{n-2} &amp; a_1b_{n-1} \\\\ \\color{blue}{\\vdots} &amp; \\vdots &amp; \\vdots &amp; &amp; \\vdots &amp; \\vdots \\\\ \\color{blue}{a_{n-2}b} &amp; a_{n-2}b_0 &amp; a_{n-2}b_1 &amp; ... &amp; a_{n-2}b_{n-2} &amp; a_{n-2}b_{n-1} \\\\ \\color{blue}{a_{n-1}b} &amp; a_{n-1}b_0 &amp; a_{n-1}b_1 &amp; ... &amp; a_{n-1}b_{n-2} &amp; a_{n-1}b_{n-1} \\\\ \\end{array}} a0​ba1​b⋮an−2​ban−1​b​ab0​a0​b0​a1​b0​⋮an−2​b0​an−1​b0​​ab1​a0​b1​a1​b1​⋮an−2​b1​an−1​b1​​...............​abn−2​a0​bn−2​a1​bn−2​⋮an−2​bn−2​an−1​bn−2​​abn−1​a0​bn−1​a1​bn−1​⋮an−2​bn−1​an−1​bn−1​​ 计算实例： 向量：a=(1,2,4,3),b=(4,2,8,0)a=(1,2,4,3),\\quad b=(4,2,8,0)a=(1,2,4,3),b=(4,2,8,0), 则： a+b=(5,3,12,3)a+b=(5,3,12,3)a+b=(5,3,12,3) a⋅b=1×4+2×2+4×8+3×0=40a\\cdot b=1\\times 4+2\\times 2+4\\times 8+3\\times 0=40a⋅b=1×4+2×2+4×8+3×0=40 a∗b=(4,10,28,36,38,24,0)a*b=(4, 10,{\\color{red}{28}},36,38,24,0)a∗b=(4,10,28,36,38,24,0) 其中，282828是这么计算出来的： ab0ab1ab2ab3a0b1×41×21×81×0a1b2×42×22×82×0a2b4×44×24×84×0a3b3×43×23×83×0\\large \\begin{array}{cc} &amp; ab_0 &amp; ab_1 &amp; ab_2 &amp; ab_3 \\\\ a_0b &amp; 1\\times 4 &amp; 1\\times 2 &amp; \\color{red}{1\\times 8} &amp; 1 \\times 0 \\\\ a_1b &amp; 2\\times 4 &amp; \\color{red}{2\\times 2} &amp; 2 \\times 8 &amp; 2\\times 0 \\\\ a_2b &amp; \\color{red}{4\\times 4} &amp; 4 \\times 2 &amp; 4 \\times 8 &amp; 4 \\times 0 \\\\ a_3b &amp; 3 \\times 4 &amp; 3 \\times 2 &amp; 3 \\times 8 &amp; 3 \\times 0 \\\\ \\end{array} a0​ba1​ba2​ba3​b​ab0​1×42×44×43×4​ab1​1×22×24×23×2​ab2​1×82×84×83×8​ab3​1×02×04×03×0​ 卷积与多项式乘法的关系 多项式乘法：C(x)=A(x)B(x)C(x)=A(x)B(x)C(x)=A(x)B(x) A(x)=a0+a1x+a2x2+⋯+am−1xm−1A(x)=a_0+a_1x+a_2x^2+\\dots+a_{m-1}x^{m-1}A(x)=a0​+a1​x+a2​x2+⋯+am−1​xm−1 B(x)=b0+b1x+b2x2+⋯+bn−1xn−1B(x)=b_0+b_1x+b_2x^2+\\dots+b_{n-1}x^{n-1}B(x)=b0​+b1​x+b2​x2+⋯+bn−1​xn−1 C(x)=a0b0+(a0b1+a1b0)x+⋯+am−1bn−1xm+n−2C(x)=a_0b_0+(a_0b_1+a_1b_0)x+\\dots+a_{m-1}b_{n-1}x^{m+n-2}C(x)=a0​b0​+(a0​b1​+a1​b0​)x+⋯+am−1​bn−1​xm+n−2 其中xkx^kxk的系数 ck=∑i+j=ki∈{0,1,,...,m−1},j∈{0,1,...,n−1}aibj,k=0,1,…,m+n−2c_k=\\sum\\limits_{i+j=k \\atop i \\in \\{0,1,,...,m-1\\}, j\\in \\{0,1,...,n-1\\}} a_ib_j,\\quad k=0,1,\\dots,m+n-2ck​=i∈{0,1,,...,m−1},j∈{0,1,...,n−1}i+j=k​∑​ai​bj​,k=0,1,…,m+n−2 平滑处理 信号向量：a=(a0,a1,…,am−1)a=(a_0,a_1,\\dots,a_{m-1})a=(a0​,a1​,…,am−1​) b=(b2k,b2k−1,...,b0)=(w−k,...,wk)b=(b_{2k},b_{2k-1},...,b_0)=(w_{-k},...,w_k)b=(b2k​,b2k−1​,...,b0​)=(w−k​,...,wk​) ai′=∑s=−kkai+sbk−s=∑s=−kkai+swsa_i'=\\sum_{s=-k}^{k}a_{i+s}b{k-s}=\\sum_{s=-k}^{k}a_{i+s}w_sai′​=∑s=−kk​ai+s​bk−s=∑s=−kk​ai+s​ws​ 把向量bbb看作2k+12k+12k+1长度窗口在aaa上移动计算a∗ba*ba∗b，得到(a0′,a1′,...,am−1′)(a_0',a_1',...,a_{m-1}')(a0′​,a1′​,...,am−1′​)。有少数向有误差。 实例： 信号向量：a=(a0,a1,...,a8)a=(a_0, a_1,...,a_8)a=(a0​,a1​,...,a8​) 步长：k=2k=2k=2 权值：w=(w−2,w−1,w0,w1,w2)=(b4,b3,b2,b2,b1,b0)w=(w_{-2},w_{-1},w_0,w_1,w_2) \\\\ =(b_4,b_3,b_2,b_2,b_1,b_0)w=(w−2​,w−1​,w0​,w1​,w2​)=(b4​,b3​,b2​,b2​,b1​,b0​) ai′=ai−2b4+ai−1b3+aib2+ai+1b1+ai+2b0{a_i}'=a_{i-2}b_4+a_{i-1}b_3+a_ib_2+a_{i+1}b_1+a_{i+2}b_0ai​′=ai−2​b4​+ai−1​b3​+ai​b2​+ai+1​b1​+ai+2​b0​ 下标之和为i+ki+ki+k 卷积计算 蛮力算法 向量a=(a0,a1,....,an−1)a=(a_0,a_1,....,a_{n-1})a=(a0​,a1​,....,an−1​)和b=(b0,b1,...,bn−1)b=(b_0,b_1,...,b_{n-1})b=(b0​,b1​,...,bn−1​) A(x)=a0+a1x+a2x2+...+an−1xn−1A(x)=a_0+a_1x+a_2x^2+...+a_{n-1}x^{n-1}A(x)=a0​+a1​x+a2​x2+...+an−1​xn−1 B(x)=b0+b1x+b2x2+...+bn−1xn−1B(x)=b_0+b_1x+b_2x^2+...+b_{n-1}x^{n-1}B(x)=b0​+b1​x+b2​x2+...+bn−1​xn−1 C(x)=A(x)B(x)=a0b0+(a0b1+a1b0)x+...+an−1bn−1x2n−2C(x)=A(x)B(x) \\\\ = a_0b_0+(a_0b_1+a_1b_0)x+...+a_{n-1}b_{n-1}x^{2n-2}C(x)=A(x)B(x)=a0​b0​+(a0​b1​+a1​b0​)x+...+an−1​bn−1​x2n−2 C(x)C(x)C(x)的系数向量就是a∗ba*ba∗b，即卷积a∗ba*ba∗b计算等价于多项式相乘。 蛮力算法时间为O(n2)O(n^2)O(n2) 计算2n-1次多项式C(x)C(x)C(x): 选择值x0,x1,...,x2n−1x_0,x_1,...,x_{2n-1}x0​,x1​,...,x2n−1​，求出A(xj)A(x_j)A(xj​)和B(xj)B(x_j)B(xj​)，j=0,1,...,2n−1j=0,1,...,2n-1j=0,1,...,2n−1 对每个jjj，计算C(xj)=A(xj)B(xj)C(x_j)=A(x_j)B(x_j)C(xj​)=A(xj​)B(xj​) 利用多项式插值的方法，由C(x)C(x)C(x)在x=x0,x1,...,x2n−1x=x_0,x_1,...,x_{2n-1}x=x0​,x1​,...,x2n−1​的值求出多项式C(x)C(x)C(x)的系数 主要步骤是多项式求值。如何选择x0,x1,x2,...x_0,x_1,x_2,...x0​,x1​,x2​,...的值就是高效求取多项式关键问题。 高斯滤波的权值函数为： ws=1ze−s2,s=0,±1,...,±kw_s = \\frac{1}{z}e^{-s^2},\\quad s=0,\\pm 1,...,\\pm kws​=z1​e−s2,s=0,±1,...,±k w=(w−k,...,w−1,w0,w1,...,wk)w=(w_{-k},...,w_{-1},w_0,w_1,...,w_k)w=(w−k​,...,w−1​,w0​,w1​,...,wk​) 其中z用于归一化处理，使所有的权值之和为1,处理结果： ai′=∑s=−kkai+sws{a_i}'=\\sum\\limits_{s=-k}^{k}a_{i+s}w_sai​′=s=−k∑k​ai+s​ws​ 2n个数的选择：1的2n次根 ωj=e2πj2ni=eπjnicos⁡πjn+isin⁡πjn\\Large {\\omega}_j=e^{\\frac{2\\pi j}{2n}i}=e^{\\frac{\\pi j}{n}i} \\\\ \\cos {\\frac{\\pi j}{n}} + i\\sin \\frac{\\pi j}{n}ωj​=e2n2πj​i=enπj​icosnπj​+isinnπj​ j=0,1,...,2n−1,i=−1j=0,1,...,2n-1,\\quad i=\\sqrt{-1}j=0,1,...,2n−1,i=−1​ 当n=4n=4n=4时， ω0=1,ω1=eπ4i=2/2+2/2⋅i\\Large{\\omega}_0=1,\\quad {\\omega}_1=e^{\\frac{\\pi}{4}i}={\\sqrt{2}}/2+{\\sqrt{2}}/2\\cdot iω0​=1,ω1​=e4π​i=2​/2+2​/2⋅i ω2=eπ2i=i,ω3=e3π4i=−2/2+2/2⋅i\\Large{\\omega}_2=e^{\\frac{\\pi}{2}i}=i,\\quad {\\omega}_3=e^{\\frac{3\\pi}{4}i}=-{\\sqrt{2}}/2+{\\sqrt{2}}/2\\cdot iω2​=e2π​i=i,ω3​=e43π​i=−2​/2+2​/2⋅i ω4=eπi=−1,ω5=e5π4i=−2/2−2/2⋅i\\Large{\\omega}_4=e^{\\pi i}=-1,\\quad {\\omega}_5=e^{\\frac{5\\pi}{4}i}=-{\\sqrt{2}}/2-{\\sqrt{2}}/2\\cdot iω4​=eπi=−1,ω5​=e45π​i=−2​/2−2​/2⋅i ω6=e3π2i=−i,ω7=e7π4i=2/2−2/2⋅i\\Large{\\omega}_6=e^{\\frac{3\\pi}{2}i}=-i,\\quad {\\omega}_7=e^{\\frac{7\\pi}{4}i}={\\sqrt{2}}/2-{\\sqrt{2}}/2\\cdot iω6​=e23π​i=−i,ω7​=e47π​i=2​/2−2​/2⋅i 快速傅里叶变换FFT算法 设计思想 对x=1,ω1,ω2,...,ω2n−1x=1,{\\omega}_1,{\\omega}_2,...,{\\omega}_{2n-1}x=1,ω1​,ω2​,...,ω2n−1​，分别计算A(x),B(x)A(x),B(x)A(x),B(x)； 利用第1步中的结果堆每个x=1,ω1,ω2,...,ω2n−1x=1,{\\omega}_1,{\\omega}_2,...,{\\omega}_{2n-1}x=1,ω1​,ω2​,...,ω2n−1​，计算得到C(x)C(x)C(x)，得到C(1)=d0,C(ω1)=d1,...,C(ω2n−1=d2n−1C(1)=d_0,C({\\omega}_1)=d_1,...,C({\\omega}_{2n-1}=d_{2n-1}C(1)=d0​,C(ω1​)=d1​,...,C(ω2n−1​=d2n−1​； 构造多项式：D(x)=d0+dix+d2x2+...+d2n−1x2n−1D(x)=d_0+d_ix+d_2x^2+...+d_{2n-1}x^{2n-1}D(x)=d0​+di​x+d2​x2+...+d2n−1​x2n−1。 对x=1,ω1,ω2,...,ω2n−1x=1,{\\omega}_1,{\\omega}_2,...,{\\omega}_{2n-1}x=1,ω1​,ω2​,...,ω2n−1​，计算D(x),D(1),D(ω1),...,D(ω2n−1)D(x),D(1),D({\\omega}_1),...,D({\\omega}_{2n-1})D(x),D(1),D(ω1​),...,D(ω2n−1​) 可以证明： D(1)=2nc0D(ω1)=2nc2n−1...D(ω2n−1)=2nc1⇔c0=D(1)/2nc2n−1=D(ω1)/2n...c1=D(ω2n−1)/2n\\begin{gathered} D(1)=2nc_0 \\\\ D({\\omega}_1)=2n c_{2n-1} \\\\ ... \\\\ D({\\omega}_{2n-1})=2nc_1 \\end{gathered} \\quad \\Harr \\quad \\begin{gathered} c_0=D(1)/2n \\\\ c_{2n-1} = D({\\omega}_1) / 2n \\\\ ... \\\\ c_1 = D({\\omega}_{2n-1}) / 2n \\end{gathered} D(1)=2nc0​D(ω1​)=2nc2n−1​...D(ω2n−1​)=2nc1​​⇔c0​=D(1)/2nc2n−1​=D(ω1​)/2n...c1​=D(ω2n−1​)/2n​ 算法的关键： 令x=1,ω1,ω2,...,ω2n−1x=1,{\\omega}_1,{\\omega}_2,...,{\\omega}_{2n-1}x=1,ω1​,ω2​,...,ω2n−1​， 步1对2n2n2n个xxx值分别求多项式A(x),B(x)A(x),B(x)A(x),B(x) 步2做2n2n2n次乘法 步3对2n2n2n个xxx值求值多项式D(x)D(x)D(x) 关键：一个对所有的xxx快速多项式求值算法。 多项式求值算法 给定多项式： A(x)=a0+a1x+...+an−1xn−1\\quad A(x)=a_0+a_1x+...+a_{n-1}x^{n-1}A(x)=a0​+a1​x+...+an−1​xn−1 设xxx为111的2n2n2n次根，对所有的xxx计算A(x)A(x)A(x)的值。 算法1：对每个xxx做下述运算： 依次计算每个项aixi,i=1,...,n−1a_ix^i,i=1,...,n-1ai​xi,i=1,...,n−1对aixi(i=0,1,...,n−1)a_ix^i(i=0,1,...,n-1)ai​xi(i=0,1,...,n−1)求和。 蛮力算法的时间复杂度：T1(n)=O(n3)T_1(n)=O(n^3)T1​(n)=O(n3) 改进的算法2：对每个xxx做下述运算： A1(x)=an−1A_1(x)=a_{n-1}A1​(x)=an−1​ A2(x)=an−2+xA1(x)=an−2+an−1xA_2(x)=a_{n-2}+xA_1(x)=a_{n-2}+a_{n-1}xA2​(x)=an−2​+xA1​(x)=an−2​+an−1​x A3(x)=an−3+xA2(x)=an−3+an−2x+an−1x2A_3(x)=a_{n-3}+xA_2(x)=a_{n-3}+a_{n-2}x+a_{n-1}x^2A3​(x)=an−3​+xA2​(x)=an−3​+an−2​x+an−1​x2 ...\\quad ... \\quad... An(x)=a0+xAn−1(x)=A(x)A_n(x)=a_0+xA_{n-1}(x)=A(x)An​(x)=a0​+xAn−1​(x)=A(x) 带入已经计算的值，得到新的算法。 算法的时间复杂度：T2(n)=O(n2)T_2(n)=O(n^2)T2​(n)=O(n2) 平面点集的凸包 问题（平面点集的凸包） 给定大量离散点的集合QQQ，求一个最小的凸多边形，使得QQQ中的点在该多边形内或者边上。 应用背景： 图形处理中用于形状识别：字形识别、碰撞检测等。 分治算法 以连接点最大纵坐标点ymaxy_{max}ymax​和最小纵坐标点yminy_{min}ymin​的线段d={ymax,ymin}d=\\{y_{max},y_{min}\\}d={ymax​,ymin​}划分LLL为左点集Lleft和右点集L_{left}和右点集Lleft​和右点集L_{right}$。 Deal(Lleft=Deal(Lright)Deal(L_{left}=Deal(L_{right})Deal(Lleft​=Deal(Lright​) Deal(L_left) 考虑LleftL_{left}Lleft​：确定距d最远的点P 在三角形内的点，删除： a外的点与a构成LleftL_{left}Lleft​的子问题； b外的点与b构成LleftL_{left}Lleft​的子问题。","link":"/2021/09/01/divide_conquer_7/"},{"title":"情绪,请开门","text":"把握情绪，就能够把握生命的根本 所谓过的好不好，就是指当下所处的情绪状态。 我们所遇到的各种事情只是促使情绪反应的刺激物，而情绪本身才是值得品尝的生活味道。 外部的刺激促使人们产生了反应，他们忽略了反应系统本身。 情绪是支撑人们存活、发展、进化的必不可少的条件之一。 认识情绪 情绪：人们对外界刺激的反应。 感觉、感受、观念和情绪，这一完整的反映链就是情绪反应系统。 核心：观念和认知。 在不同的观念系统中，对情绪的看法因人而异，有好情绪、坏情绪，或者正能量、负能量，评判依据就是各人的感受。 我们对情绪的反应、对情绪的判断，都是被反应系统或核心观念系统创造出来的。 连接外界 只要你还有情绪，你的生命就还在与这个世界进行反应，就还在于世界相连。 注意力是意识系统的眼睛。 情绪与注意力之间有什么关系？ 情绪不但可以启动注意力，还可以锁定注意力。 无论舒适的情绪还是难受的情绪，都可以锁定注意力。 情绪的功能： 情绪是一种心理能力，可以调动自身各种各样的内外资源。情绪还可以触发行为，比如你会把手从冰水中拿出来，或者在盆中加点热水。 此外,情绪还有一个重要的功能，即帮助我们形成情感。情感与人们对外界的反应系统有关，相当于一套内在的价值观。 情感可以被理解为一种长期、稳定的情绪。 核心观念系统是纯主观性质的，而情绪界与心理和生理之间，受观念影响，同时又能连接身体。 感觉是纯生理的，依赖于感官，比如味觉细胞可以感知糖的甜味；而感受则更靠近身体，比如糖的甜味让我们觉得舒服、愉悦。核心观念系统将根据自身不断增加的经历形成各种情绪。种种情绪像一把雕刻刀，雕琢出情感，这种情感构成我们评价外部世界好坏对错的核心观念系统。 我们与这个世界互动机制始于外界刺激，情绪把我们和世界联系起来： 外界的刺激从感官通道进来让我们产生了情绪； 为了认识、理解这种情绪，我们逐渐形成了核心观念系统，这就相当于一个程序。 在碰到相似的外界刺激时，我们首先就会查阅以前是否类似的经验。如果有类似的经验，我们就会将之取出来，产生相应的情绪。 情绪与观念相辅相成 情绪构建核心观念系统的过程可以被理解为充电的过程，既有的观念触发情绪就是放电的过程。 情绪构建了观念。 即让我们对外界刺激产生反应的反应系统或者成为核心观念系统本身就是被一次次的情绪产生构建的。 观念触发情绪。 我们每天 碰到的各种事物到底会激活哪种情绪，取决于之前的经历、体验和情绪建立起来的核心观念系统。 核心观念系统一旦建立起来，就会比较稳定地存在。这种基于情绪的对世界持续进行的反应恰恰就是生命的特征，就是生命力的体现。有时候某件事情之所以会让人们产生难受的情绪，并不是因为事情本身，而是反应系统激活了不好的情绪。 了解情绪 阳性情绪：外显行为表达的情绪。(愤怒、恐惧) 阴性情绪：旁人难以观察到外显行为。(抑郁等) 焦虑：你的有效边界在哪里 特点： 指向未来 对不确定感的抗拒性反应 所指向的事情总是人们试图回避的 表现： 紧张，持续性的紧张 心烦意乱，心情比较烦躁 坐立不安 功能：转换成有效行为。即焦虑可以极大地调动内在能量和内外资源，触发一些有效行为，引导人们做很多事情以避免担心或害怕的事情的发生。甚至进一步推动了族群的延续、科技的发展、文明的进步…… 焦虑变成问题： 不能够确立有效的边界 不能够转化为有效行为 不能够觉察内在动机 当我们为某件事情焦虑的时候，可以问一下自己，自己的内在动机到底是什么。 觉察自己的内在动机后，你可能会发现其实你要的只是成功，进而你会想到其实有很多条道路可以让你取得成功，正所谓“条条大路通罗马”。这时候你的焦虑情绪也许就会有所缓解。 焦虑使人们保持对环境的敏感，适度的焦虑会让人们做出对自身发展有益且有效的行为 抑郁：人类特有的高级情绪 抑郁情绪不等于抑郁症：抑郁情绪，人皆有之，每个人都会在生命的某些情境下产生抑郁情绪；而抑郁症在主观感受的痛苦强度以及持续的时间上，与抑郁情绪有着明显的不同。二者在医学诊断上有严格界定。 沉浸在抑郁情绪中的人通常自我价值感比较低，并且这种低自我价值感并不是特定针对某件具体的事情。 抑郁就是情绪的流动性变差。 特点： 低能量，什么都不想做； 低自我价值感，全盘否定自己； 充满无望感，对改变现状不抱有任何希望。 形成的原因（可能） 有些人过于在意外在的功能，而忽略了自己的感受； 有些人无法调和自身的各种角色和所有角色之外的自己的需要。 意义 第一，抑郁可以触发人们对自己的观察、了解和反思。 第二，抑郁有可能让人们重新调整生命的目标，确立一种意义感。 人们的痛苦往往来自两个方面： 其一，病痛等原因让我们觉得很难受，这是一种纯粹的痛苦； 其二，更重要的是，我们觉得这种痛苦没有意义。 愤怒：修复受阻的连接 特点： 愤怒很容易转为外显行为； 容易识别，指的是情绪本身，如“气鼓鼓”。 总是在寻求释放，但这种释放往往会受阻； 总要指向外界的人或事； 具有强流动性。 强流动性是指这种愤怒的情绪比较容易行为化，比较容易通过行为表达出来。 内在机制 愤怒是失控感、失联感、无助感的一种阳性表达； 愤怒具有附着蔓延的特点。（弥散性） 附着是指愤怒一般有一个具体事件触发，这就是个导火索。之后会蔓延。这种蔓延中只能够看到行为的结果，不能够直接看到原因。 功能： 有效地寻求连接，即可以建立连接； 使心理能量流动。 表达愤怒实际上是在尝试修复受阻的连接，寻求内心与外界的一致。 不节制地表达愤怒，可能会造成一些无法挽回的后果。 悲伤：帮助我们回归内在 三个要素 指向过去或者既定事实。 既定事实与某种失去有关。 引起悲伤的失去或造成的结果往往是无法挽回的。 特点： 指向过去，往往和某个丧失或者某个法挽回的结果有关 能量比较低 属性： 人们对丧失感的反映； 容易让人们体验到一种复合型的情感； 悲伤这种情感不是单一的，在体验上它往往包括了沮丧、失望、气馁、孤独、内疚等。产生这种复合型情感的内在原因是已经发生的这件事情虽然定格了，人们在逻辑上、理智上也知道其实做什么都已经无法挽回了，但在心理层面，能量还在寻求一种流动、一种突破、一种表达。 弥散性较强。 它就像一张网，像水或沼泽，让人很容易陷进去，又难以走出来。 功能 表达情感； 很多时候，你不需要也不能消除悲伤，这也是人们对待悲伤应保持的态度。即使你强行把它消除，它也必然会通过另外一种表达方式呈现，这会使这种情感更扭曲。 使生命在心理层面连续和完整； 简单地说，人们失去了一段对自己而言非常重要的关系，或者失去了一个对人们来说重要的客体，就相当于生命缺失了一部分。于是，人们就需要以悲伤填补缺失的这一部分。 帮助人们回到内在。 这一回到内在的过程相当于在主观层面把这一段关系对于自己的意义进行了重新梳理和命名。当然，这种对自己进行深入了解和发现的过程可能会让人比较痛苦，但这对自身的心理成长和自我发展来说很重要。 恐惧：一切负面情绪的根源 恐”和“惧”的区别：“恐”指向未知事物，强调个人主观感受；“惧”指向的是外在确定的事物。 特点： 恐惧是一种对危险和失控的反应，并由此产生回避性行为； 恐惧往往会触发回避性的行为。要注意，恐惧可以触发行为，但触发的往往是回避性的行为。 恐惧在持续一段时间后会开始弥散； 所谓风声鹤唳、草木皆兵，就是恐惧的弥散性的体现。 恐惧往往会引发预测式的心理反应； 一位恐怖小说大师霍华德·菲利普·洛夫克拉夫特（Howard Philips Lovecraft）曾经说，人类最古老而强烈的情绪便是恐惧，而最强烈的恐惧就是对未知的恐惧。为了消除这种未知，人们会出现这种预测式的反应。 恐惧往往是其他让你难受的情绪的原发情绪。 它会像多米诺骨牌一样，引发其他的负面情绪。比如，在你有一个确定的害怕的对象时，恐惧就很容易引发焦虑。 功能 锚定注意力。 人们在感到害怕的时候往往非常专注。 触发回避、面对或木僵的行为。 恐惧引起的最常见的行为就是回避性反应，也就是逃跑；逃不掉，就只能去面对、去战斗；逃不掉又无力战斗，人们就可能进入一种木僵的状态，也就是通常意义上的“吓傻了”。其实这无非是在通过这种状态，缓解自身的恐惧。这就好像大脑中心的保险丝被烧断了，人们就不再继续恐惧了。 喜悦：生命存续的报偿系统 特点： 其带来的最普遍的反应是让人感到放松； 其往往会伴随着兴奋且协调的内在感受； 在处于喜悦情绪时，人们比较容易与外界环境、与他人建立更好的连接。 机制（通过有效途径获得喜悦） 第一种方法是尽力追求想要的东西； 也包括与更多的人建立一种良性的连接。 第二种方法是调整目标，使它容易实现。 调整自己的目标，让这个目标更容易达成，这样就会更容易获得喜悦的感受，也就是知足常乐。 功能 让人放松； 生命得以存续的报偿系统。 我们还可以从更广阔的角度来思考。喜悦这种报偿除了让人们感到愉快之外，更重要的是其指示作用。你产生的喜悦比较多，可以说明你这个人的内在系统，认知、思想、境界种种方面，都比较合乎自然规律。 喜悦本身又是一个检验系统，检验你对世界的认知是否正确。 如果你的内在价值体系、反应体系或所有内在观念，都符合自然规律，在生命中你感到喜悦的时间就会更长。相反，你如果有很多偏执的、错误的观念，可能在现实中就会处处碰壁，面对更多痛苦的情绪。","link":"/2021/08/16/emotion/"},{"title":"gpu.js","text":"gpu.js 使用记录 定义GPU 12345const mode = 'gpu';// gpu, cpuconst gpu = new GPU({ mode: mode });console.log(gpu.getMode());// gpu 输出 output： array： [width], [width, height], [width, height, depth] object: { x: width, y: height, z: depth} outputToTexture (Boolean) 值保存到texture中。 floatOutput floatTextures functions 输入 数字 一位数组 二维数组 三维数组 html image array of html image 使用thread 123456789const myFunc = gpu.createKernel(function(image) { const pixel = image[this.thread.y][this.thread.x]; this.color(pixel[0], pixel[1], pixel[2], pixel[3]);}) .setGraphical(true) .setOutput([100]);myFunc([1, 2, 3]);// Result: colorful image 输入[x, y, z] 使用流水线，即在GPU中保存值。 可以调用 outputToTexture: boolean 或者 kernel.setOutputToTexture(true) 12345678const importAsTexture = gpu.createKernel(function(value) { return value[this.thread.y][this.thread.x];}) .setOutput([512, 512]) .setOutputToTexture(true);const texture = importAsTexture([1, 2]);// console.log(texture); Gpu.js 处理图片 https://github.com/gpujs/gpu.js/issues/278 输出数组 1234const k = gpu.createKernel(function () { return this.thread.x % 2;}).setOutput([6, 2, 1]);console.log(k()); 添加额外的定制函数 addFunction 12345678910gpu.addFunction(function mySuperFunction(a, b) { return a - b;});function anotherFunction(value) { return value + 1;}gpu.addFunction(anotherFunction);const kernel = gpu.createKernel(function(a, b) { return anotherFunction(mySuperFunction(a[this.thread.x], b[this.thread.x]));}).setOutput([20]); 或者添加 setFunctions 12345678function mySuperFunction(a, b) { return a - b;}const kernel = gpu.createKernel(function(a, b) { return mySuperFunction(a[this.thread.x], b[this.thread.x]);}) .setOutput([20]) .setFunctions([mySuperFunction]); 传递常量 constants中定义常量。 12345678910const matMult = gpu.createKernel(function(a, b) { var sum = 0; for (var i = 0; i &lt; this.constants.size; i++) { sum += a[this.thread.y][i] * b[i][this.thread.x]; } return sum;}, { constants: { size: 512 }, output: [512, 512],}); GPU.Input 1234567891011121314151617import GPU, { input } from 'gpu.js';function run() { const gpu = new GPU({ mode: 'cpu' }); const opt = { output: [3, 3] }; const kernel = gpu.createKernel(function(values) { return values[this.thread.x] + values[this.thread.y]; }, opt); const gpuInput = input(new Float32Array([2, 4, 6, 1, 3, 5, 8, 10, 12]), [3, 3]); const output = kernel(gpuInput); console.log(output);}run(); in GPU mode: 123456(3) [Array(3), Array(3), Array(3)]0:(3) [4, 6, 8]1:(3) [6, 8, 10]2:(3) [8, 10, 12]length:3__proto__:Array(0) 此方法在cpu 模式中无法使用，主要原因是： Input 的实现中，主要使用了 glsl语言。 https://github.com/gpujs/gpu.js/blob/4173dd9610b9c04fa064e7e2e12b5f066d7eeac7/src/backend/web-gl/kernel.js#L627 That is correct, it just has not yet been implemented. The key difference on GPU over CPU is that at this time on GPU the Array’s are always flat, but there is some architecture in place to help flatten them, which is expensive, but isn’t worth making everyone have to pre-flatten their arrays. GPU.input skips this step, allowing for very fast computation without having to flatten, because the data is pre-flattened. I imagine the best means of which to implement this would be to use input, and then on the CPUFunctionBuilder we’d have an option (or detection?) to simply use them, altering the compiled kernel. So: input1[this.thread.z][this.thread.y][this.thread.x] would become something more like: input1[this.thread.hypotheticalndexOrSomething]. https://github.com/gpujs/gpu.js/issues/243 CPU 、GPU mode 123456789101112131415const gpu = new GPU({ mode: mode });console.log(gpu.getMode());var cpu = new GPU({mode:'cpu'});// var gpu = new GPU({mode:'gpu'});function testFunc(inp) { return inp[this.thread.y][this.thread.x];}const cpuKernel = cpu.createKernel(testFunc).setOutput([3, 3]);const gpuKernel = gpu.createKernel(testFunc).setOutput([3, 3]);console.log('cpu:', cpuKernel( [[0,1,2], [3,4,5], [6,7,8]] ) );console.log('gpu:', gpuKernel( [[0,1,2], [3,4,5], [6,7,8]] ) ); 如果参数不全，则在cpu中出现未定义，在GPU 中出现其他值。 123456789101112131415const gpu = new GPU({ mode: mode });console.log(gpu.getMode());var cpu = new GPU({mode:'cpu'});// var gpu = new GPU({mode:'gpu'});function testFunc(inp) { return inp[this.thread.y][this.thread.x];}const cpuKernel = cpu.createKernel(testFunc).setOutput([3, 3]);const gpuKernel = gpu.createKernel(testFunc).setOutput([3, 3]);console.log('cpu:', cpuKernel( [[0, 212], [1, 12], [2,21]] ) );console.log('gpu:', gpuKernel( [[0, 212], [1, 12], [2,21]] ) ); SSSP 算法 https://github.com/pan-long/SSSP-on-GPU/blob/master/bellman_ford_gpu.js 多GPU 支持，取决于运行环境（浏览器是否使用多GPU） https://github.com/gpujs/gpu.js/issues/190 webGL 支持检测： http://alteredqualia.com/tmp/webgl-maxparams-test/ createKernelMap 1234567891011var km = new GPU().createKernelMap([ function add(v1, v2) { return v1 + v2; }, function divide(v1, v2) { return v1 / v2; }], function (a, b, c) { return divide(add(a[this.thread.x], b[this.thread.x]), c[this.thread.x]);}, {output: [3], floatOutput: true});console.log(km([1], [1], [3])); 完整实例： 12345678910111213141516171819202122232425262728const mode = 'gpu';// gpu, cpuconst gpu = new GPU({ mode: mode });console.log(gpu.getMode());const size = 4; // keeping it small for testingconst a = new Float32Array(size);const b = new Float32Array(size);const c = new Float32Array(size);for (let i = 0; i &lt; size; ++i) { a[i] = 0; b[i] = i; c[i] = 2;}const megaKernel = gpu.createKernelMap([ function add(a, b) { return a + b; }, function multiply(a, b) { return a * b; }], function (a, b, c) { return multiply(add(a[this.thread.x], b[this.thread.x]), c[this.thread.x]);});megaKernel.setOutput([ size ]);console.log(megaKernel(a, b, c).result); 输出：float32Array(4) [0, 2, 4, 6]， https://github.com/gpujs/gpu.js/issues/258","link":"/2018/06/08/gpu.js/"},{"title":"【译】Linux系统中的 ELF 文件的理解与分析","text":"世界上一些真正的工匠精神，我们认为是理所当然的。其中之一就是 Linux 上常用的工具，比如ps和ls。尽管这些命令可能被认为是简单的，但当看清其本质时，却有更多的东西。这就是ELF或可执行和可链接格式的作用。一个用得很多的文件格式，但真正了解的人却寥寥无几。让我们通过这个介绍教程来了解一下吧! 通过阅读本指南，你将了解： 为什么要使用 ELF，以及使用在什么样的文件上？ 了解 ELF 的结构和格式的细节。 如何读取和分析 ELF 文件，如二进制文件。 哪些工具可以用于二进制分析。 什么是 ELF 文件？ ELF 是可执行和可链接格式（Executable and Linkable Format）的缩写，定义了二进制文件、库和核心文件的结构。正式的规范允许操作系统正确解释其底层机器指令。ELF 文件通常是编译器或链接器的输出，是一种二进制格式。通过合适的工具，可以对这类文件进行分析，更好地理解。 为什么要学习 ELF 的细节？ 在深入了解更多技术细节之前，不妨先解释一下为什么了解 ELF 格式是有用的。作为一个入门者，它有助于了解我们操作系统的内部运作。当出现问题时，我们可能会更好地理解发生了什么（或为什么）。然后是能够研究 ELF 文件的价值，特别是在安全漏洞或发现可疑文件后。最后但同样重要的是，为了在开发时更好地理解。即使你使用像Golang这样的高级语言编程，你仍然可能从了解幕后发生的事情中受益。 为什么学习 ELF？ 对操作系统工作原理的一般理解 软件的开发 数字取证和事件响应(DFIR) 恶意软件研究（二进制分析） 从源头到过程 所以无论我们运行的是什么操作系统，都需要将常用的函数翻译成 CPU 的语言，也就是机器代码。一个函数可能是一些基本的东西，比如在磁盘上打开一个文件或在屏幕上显示一些东西。我们不是直接与 CPU 对话，而是使用一种编程语言，使用内部函数。然后编译器将这些函数翻译成对象代码。然后，通过使用链接器工具，将这些对象代码链接成一个完整的程序。其结果是一个二进制文件，然后可以在特定的平台和 CPU 类型上执行。 在你开始之前 这篇博文将分享很多命令。不要在生产系统上运行它们。最好在测试机上做。如果你喜欢测试命令，可以复制一个现有的二进制文件，然后使用它。另外，我们还提供了一个小的 C 程序，你可以编译一下。毕竟，尝试是学习和比较结果的最好方法。 ELF文件的结构 一个常见的误解是，ELF 文件只是用于二进制文件或可执行文件。我们已经看到它们可以用于部分片段（对象代码）。另一个例子是共享库甚至核心转储（那些core或a.out文件）。ELF规范在Linux上也用于内核本身和Linux内核模块。 架构 由于 ELF 文件的可扩展设计，每个文件的结构不同。一个 ELF 文件由以下几个部分组成 ELF header 文件数据 通过readelf命令，我们可以查看一个文件的结构，它看起来是这样的。 ELF header 从这个截图中可以看到，ELF header 以一些魔术数字开始。这个 ELF header 的魔术数字提供了关于文件的信息。前4个十六进制部分定义了这是一个ELF文件(45=E,4c=L,46=F)，前缀为7f值。 这个 ELF header 是强制性的。它确保数据在链接或执行过程中被正确解释。为了更好地理解 ELF文件的内部工作，了解这个 header 信息的使用是很有用的。 Class 在ELF类型声明之后，定义了一个 Class 字段。这个值决定了文件的体系结构，可以是 32 位(=01)或64位(=02)的体系结构。它可以是32-bit（=01）或 64-bit（=02）的架构。魔法显示的是02，它被readelf命令翻译成ELF64文件。换句话说，是一个使用64位架构的 ELF 文件。这并不奇怪，因为这台特殊的机器包含一个现代 CPU。 Data 接下来的部分是数据字段。它知道两个选项。01代表LSB(Least_significant_bit), 也就是小字段. 然后是值02，代表MSB（Most Significant Bit，big-endian）。这个特殊的值有助于正确解释文件中的其余对象。这一点很重要，因为不同类型的处理器对输入的指令和数据结构的处理方式不同。在这种情况下，使用 LSB，这对于 AMD64 类型的处理器来说是很常见的。 当对二进制文件使用hexdump时，LSB 的效果就会显现出来。让我们展示一下/bin/ps的 ELF header 细节。 1234$ hexdump -n 16 /bin/ps0000000 457f 464c 0102 0001 0000 0000 0000 00000000010 我们可以看到，value pair 是不同的，这是由于字节顺序的正确解释造成的。 Version 接下来在魔法中又多了一个01。这就是版本号。目前，版本类型只有1个：当前，也就是值01。所以没什么有趣的东西可记。 OS/ABI 每个操作系统的共同功能都有很大的重叠。此外，他们每个人都有特定的，或者至少他们之间有小的差异。正确集的定义是通过应用二进制接口（ABI）来完成的。这样操作系统和应用程序都知道期望什么，功能也能正确转发。这两个字段描述了使用什么ABI和相关的版本。在这种情况下，值是00，这意味着没有使用特定的扩展。输出显示为System V。 Machine 我们还可以在头文件中找到预期的机器类型（AMD64）。 Type 类型字段告诉我们文件的目的是什么。有几种常见的文件类型。 CORE（值4) DYN(Shared object file)，用于 library (值3) EXEC(Executable file)，用于二进制文件(值2) REL(Relocatable file)，在链接到可执行文件之前(值1) See full header details 虽然有些字段已经可以通过readelf输出的魔术数字来显示，但还有更多。例如对于文件是什么特定的处理器类型。使用hexdump我们可以看到完整的 ELF header 及其值。 通过hexdump -C -n 64 /bin/ps创建的输出内容 12347f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 |.ELF............|02 00 3e 00 01 00 00 00 a8 2b 40 00 00 00 00 00 |..&gt;......+@.....|40 00 00 00 00 00 00 00 30 65 01 00 00 00 00 00 |@.......0e......|00 00 00 00 40 00 38 00 09 00 40 00 1c 00 1b 00 |....@.8...@.....| 第二行第三组是定义机器类型的。值3e是十进制的62，相当于AMD64。要了解所有机器类型，请看一下这个 ELF 头文件。 虽然你可以用十六进制转储做很多事情，但让工具为你做这些工作是有意义的。在这方面，dumpelf工具可以提供帮助。它显示的格式化输出与 ELF 头文件非常相似。很好地了解到使用了哪些字段以及它们的典型值。 明确了所有这些字段后，是时候看看真正的神奇发生在哪里，并进入下一个头文件了! File data 除了 ELF 头，ELF 文件还包括三个部分。 Program Headers or Segments (9) Section Headers or Sections (28) Data 在我们深入研究这些头文件之前，很高兴知道ELF有两个互补的 “视图（view）”。一个view 用于链接器允许执行（segment）。另一个用于对指令和数据进行分类（section）。因此，根据目标的不同，会使用相关的头类型。让我们从程序头开始，我们可以在ELF二进制文件上找到它。 程序头文件 一个 ELF 文件由0个或多个段组成，描述了如何为运行时执行创建一个进程/内存映像。当内核看到这些段时，它会使用它们来映射到虚拟地址空间，使用mmap(2)系统调用。换句话说，它将预定义的指令转换为内存映像。如果你的 ELF 文件是一个正常的二进制文件，它需要这些程序头。否则，它根本无法运行。它使用这些头文件和底层数据结构，形成一个进程。这个过程与共享库类似。 我们在这个例子中看到，有9个程序头文件。当第一次看的时候，很难理解这里发生了什么。所以我们来了解一些细节。 GNU_EH_FRAME* 这是 GNU C 编译器（gcc）使用的一个排序队列。它存储了异常处理程序。所以当出现问题时，它可以使用这个区域来正确处理。 GNU_STACK 这个头是用来存储栈信息的。栈是一个缓冲区，或者说是一个划痕的地方，在这里存储项目，就像本地变量一样。这将与 LIFO（Last In, First Out） 一起发生，类似于把盒子放在彼此的顶部。当一个进程函数启动时，会保留一个块。当函数完成后，它将再次被标记为空闲。现在有趣的部分是，堆栈不应该是可执行的，因为这可能会引入安全漏洞。通过对内存的操作，人们可以引用这个可执行的栈并运行预期的指令。 如果GNU_STACK段不可用，那么通常会使用可执行栈。scanelf和execstack工具是两个显示栈细节的例子。 123456# scanelf -e /bin/ps TYPE STK/REL/PTL FILE ET_EXEC RW- R-- RW- /bin/ps# execstack -q /bin/ps- /bin/ps 查看程序 header 文件的命令： dumpelf(pax-utils) elfls -S /bin/ps eu-readelf –program-headers /bin/ps ELF sections Section headers Section header 定义了文件中的所有章节。如前所述，这个 &quot;view&quot;是用来链接和重新定位的。 段可以在一个 ELF 二进制文件中找到，在 GNU C 编译器将 C 代码转化为汇编后，再由 GNU 汇编器将其创建对象。 如上图所示，一个段可以有0个或多个段。对于可执行文件来说，主要有四个部分：.text、.data、.rodata和.bss。每一个部分都加载了不同的访问权限，可以用readelf -S来查看。 .text 包含可执行代码。它将被打包到一个具有读取和执行访问权限的段中。它只被加载一次，因为内容不会改变。这可以通过objdump工具看到。 .data 初始化的数据，具有读/写访问权。 .rodata 初始化的数据，只有读取访问权（=A）。 .bss 未初始化的数据，具有读/写访问权(=WA) [24] .data PROGBITS 00000000006172e0 000172e0 0000000000000100 0000000000000000 WA 0 0 8 [25] .bss NOBITS 00000000006173e0 000173e0 0000000000021110 0000000000000000 WA 0 0 32 查看 section 和 header 的命令： dumpelf elfls -p /bin/ps eu-readelf -section-headers /bin/ps readelf -S /bin/ps objdump -h /bin/ps Section groups 有些部分可以分组，因为它们形成一个整体，或者换句话说是一个依赖关系。新的链接器支持这个功能。不过，这种情况还是不常见，不常发现。 123# readelf -g /bin/ps 在该文件下没有 section group。 虽然这看起来可能不是很有趣，但它显示了研究现有的 ELF 工具包的明显好处，以供分析。为此，本文末尾列入了对工具及其主要目标的概述。 静态和动态二进制文件 在处理 ELF 二进制文件时，最好知道有两种类型以及它们之间的联系。类型是静态或动态的，指的是使用的库。出于优化的目的，我们经常看到二进制文件是 &quot;动态 &quot;的，这意味着它需要外部组件才能正确运行。通常这些外部组件是普通的库，其中包含了一些常用的功能，比如打开文件或创建网络套接字。而静态二进制文件则包含了所有的库。这使得它们更大，但更容易移植（例如在另一个系统上使用它们）。 如果你想检查一个文件是静态还是动态编译的，使用file命令。如果它显示类似 12$ file /bin/ps/bin/ps: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.24, BuildID[sha1]=2053194ca4ee8754c695f5a7a7cff2fb8fdd297e, stripped 要确定正在使用哪些外部库，只需在同一二进制文件上使用ldd即可。 12345$ ldd /bin/pslinux-vdso.so.1 =&gt; (0x00007ffe5ef0d000)libprocps.so.3 =&gt; /lib/x86_64-linux-gnu/libprocps.so.3 (0x00007f8959711000)libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f895934c000)/lib64/ld-linux-x86-64.so.2 (0x00007f8959935000) 提示：要查看底层的依赖关系，最好使用 lddtree 工具。 二进制分析的工具 当你想分析 ELF 文件时，首先寻找可用的工具肯定是有用的。一些可用的软件包提供了逆向工程二进制文件或可执行代码的工具包。如果你是分析ELF恶意软件或固件的新手，可以考虑先学习静态分析（static analysis)。这意味着你检查文件而不实际执行它们。当您更好地了解它们的工作方式时，然后转向动态分析(dynamic analysi)。现在，您将运行文件样本，并查看它们作为实际处理器指令执行低级代码时的实际行为。无论你做什么类型的分析，都要确保在一个专用系统上进行，最好是有严格的网络规则。在处理未知样本或那些与恶意软件有关的样本时，尤其如此。 常用工具 Radare2 Radare2 工具包由 Sergi Alvarez 创建。版本中的2指的是与第一个版本相比，该工具的全面重写。现在很多逆向工程师都用它来学习二进制文件的工作原理。它可以用来剖析固件、恶意软件以及其他任何看起来是可执行格式的东西。 Software packages 大多数 Linux 系统已经安装了binutils包。其他的软件包可能会帮助显示更多的细节。拥有正确的工具包可能会简化你的工作，特别是在做分析或了解更多关于 ELF 文件的时候。因此，我们收集了一个软件包和其中的相关实用程序的列表。 elfutils /usr/bin/eu-addr2line /usr/bin/eu-ar – alternative to ar, to create, manipulate archive files /usr/bin/eu-elfcmp /usr/bin/eu-elflint – compliance check against gABI and psABI specifications /usr/bin/eu-findtextrel – find text relocations /usr/bin/eu-ld – combining object and archive files /usr/bin/eu-make-debug-archive /usr/bin/eu-nm – display symbols from object/executable files /usr/bin/eu-objdump – show information of object files /usr/bin/eu-ranlib – create index for archives for performance /usr/bin/eu-readelf – human-readable display of ELF files /usr/bin/eu-size – display size of each section (text, data, bss, etc) /usr/bin/eu-stack – show the stack of a running process, or coredump /usr/bin/eu-strings – display textual strings (similar to strings utility) /usr/bin/eu-strip – strip ELF file from symbol tables /usr/bin/eu-unstrip – add symbols and debug information to stripped binary 注：elfutils包是一个很好的开始，因为它包含了大多数执行分析的实用程序。 elfkickers /usr/bin/ebfc – compiler for Brainfuck programming language /usr/bin/elfls – shows program headers and section headers with flags /usr/bin/elftoc – converts a binary into a C program /usr/bin/infect – tool to inject a dropper, which creates setuid file in /tmp /usr/bin/objres – creates an object from ordinary or binary data /usr/bin/rebind – changes bindings/visibility of symbols in ELF file /usr/bin/sstrip – strips unneeded components from ELF file 注：ELFKickers包的作者专注于对ELF文件的操作，当你发现畸形的ELF二进制文件时，不妨多学习一下。 pax-utils /usr/bin/dumpelf – dump internal ELF structure /usr/bin/lddtree – like ldd, with levels to show dependencies /usr/bin/pspax – list ELF/PaX information about running processes /usr/bin/scanelf – wide range of information, including PaX details /usr/bin/scanmacho – shows details for Mach-O binaries (Mac OS X) /usr/bin/symtree – displays a leveled output for symbols 备注：本软件包中的几个实用程序可以在整个目录中递归扫描。非常适合对一个目录进行大规模分析。这些工具的重点是收集PaX的细节。除了支持ELF之外，还可以提取一些关于Mach-O二进制文件的细节。 输出示例 123scanelf -a /bin/ps TYPE PAX PERM ENDIAN STK/REL/PTL TEXTREL RPATH BIND FILE ET_EXEC PeMRxS 0755 LE RW- R-- RW- - - LAZY /bin/ps prelink /usr/bin/execstack – display or change if stack is executable /usr/bin/prelink – remaps/relocates calls in ELF files, to speed up the process Example 如果你想自己创建一个二进制程序，只需创建一个小的C程序，然后编译它。下面是一个例子，它打开/tmp/test.txt，将内容读入缓冲区并显示出来。确保创建相关的/tmp/test.txt文件。 1234567891011121314#include &lt;stdio.h&gt;int main(int argc, char **argv){ FILE *fp; char buff[255]; fp = fopen(&quot;/tmp/test.txt&quot;, &quot;r&quot;); fgets(buff, 255, fp); printf(&quot;%s\\n&quot;, buff); fclose(fp); return 0;} 这个程序通过gcc -o test test.c进行编译。 常见问题解答 什么是ABI？ ABI 是 Application Binary Interface 的缩写，指定了操作系统和一段可执行代码之间的低级接口。 什么是ELF？ ELF是可执行和可链接格式的简称。它是一种正式的规范，定义了如何在可执行代码中存储指令。 如何确定未知文件的文件类型？ 使用文件命令进行第一轮分析。该命令可能会根据头信息或魔术数字来显示细节。 结论 ELF 文件是用于执行或链接的。根据主要的目标，它包含了所需的段或节。段被内核查看并映射到内存中(使用mmap)，段被链接器查看以创建可执行代码或共享对象。段被链接器查看以创建可执行代码或共享对象。 ELF 文件类型非常灵活，支持多种CPU类型、机器架构和操作系统。它还具有很强的可扩展性：根据所需的部分，每个文件的构造不同。 头文件构成了文件的重要部分，准确描述了 ELF 文件的内容。通过使用正确的工具，你可以获得对文件目的的基本理解。从那里，你可以进一步检查二进制文件。这可以通过确定它使用的相关函数或文件中存储的字符串来完成。对于那些从事恶意软件研究的人来说，或者想更好地了解进程的行为（或不行为！），这是一个很好的开始。 更多资源 如果你想了解更多关于 ELF 和逆向工程的知识，你可能会喜欢我们在 Linux 安全专家所做的工作。作为培训计划的一部分，我们有一个带有实际实验室任务的逆向工程模块。 对于那些喜欢阅读的人来说，一个好的深度文档。ELF格式和由Brian Raiter（ELFkickers）撰写的文件。对于那些喜欢阅读实际源代码的人来说，可以看看苹果公司的一个文档化的ELF结构头文件。 小贴士：如果你喜欢在分析文件和样本方面有更好的表现，那就开始使用流行的二进制分析工具吧。 Magic data / Magic number: 缺乏解释或命名的独特数值。常常在程序中出现多次，并且可以（从规范上而言也应当）被有名字的常量取代。 用于识别一个文件格式或协议类型的一段常量或字符串，例如UNIX的特征签名。 不易于其他值混淆的值，例如 UUID。 魔术数字也会在文件中使用。在特定文件格式中加入固定数值和固定字符串，然后便可以通过检查文件是否包含这些数据来快速地识别文件格式。 例如：GIF 文件开头会包含GIF89a（47 49 46 38 39 61）或GIF87a（47 49 46 38 37 61）这两种字符串。 原为为The 101 of ELF files on Linux: Understanding and Analysis - Linux Audit (linux-audit.com)","link":"/2021/02/17/elf/"},{"title":"堆与栈","text":"进程内存布局 如下图所示，对于每个程序所分配的内存由很多部分组成，通常称之为“段”（segment）。 文本段（text）包括进程运行的程序机器语言指令。文本段具有只读属性，以防止进程通过错误指针意外修改自身指令。 初始化数据段（BSS）包括为未进行显式初始化的全局变量和静态变量。 对于初始化和未初始化数据段即用户初始化数据段（user-initialized data segment）和零初始化数据段（zero-initialized data segment）。 栈（stack）是一个动态增长和收缩的段，由栈帧（stack frames）组成。系统会为每个当前调用的函数分配一个栈帧。栈帧中存储了函数的局部变量（所谓自动变量）、实参和返回值。 堆（heap）是可在运行时（变量）动态进行内存分配的一块区域。堆顶端成为program break。 栈 栈是程序运行的基础。当每一个函数被调用时，操作系统会在栈顶分配一块连续的内存。这块内存被称为帧（frame）。 这里讨论的栈是用户栈（user stack），和内核栈区分开来。内核栈是每个进程保留在内核内存中的内存区域，在执行系统调用的过程中供（内核）内部函数调用使用。 栈是自顶向下增长的，一个程序的调用栈最底部，除去入口帧（entry frame），就是main()函数对应的帧。随着mian()函数一层一层调用，栈会一层一层地扩展；调用结束后，栈会一层一层地回溯，把内存释放回去。 每个栈帧包括如下信息： 函数实参和局部变量：这些变量都是在函数调用时自动创建的，被称为C语言中的自动变量。函数返回时将自动销毁这些变量（因为栈帧会被释放），这也是自动变量与静态变量（以及全局）变量主要的语义区别：后者与函数执行无关，且长期存在。 （函数）调用的链接信息：每个函数都会用到一些CPU寄存器，比如程序计数器，其值向下一条要执行的机器语言指令。当每个函数调用另外一个函数时，会在被调用函数的栈帧中保存这些寄存器的副本，以便函数返回时能够为函数调用者将寄存器恢复原状。 在调用的过程中，一个新的帧会分配足够的空间存储寄存器的上下文。在函数里使用到的通用寄存器会在栈保存一个副本，当这个函数调用结束，通过副本，可以恢复出原本的寄存器的上下文，就像什么都没有经历一样。此外，函数所需要使用到的局部变量，也都会在帧分配的时候被预留出来。 那么，一个函数运行时，是怎么确定需要多大的帧？ 这要归功于编译器。在编译、优化代码时，一个函数就是一个最小的编译单元。 在这个函数里，编译器得指导有哪些寄存器、栈上要放哪些局部变量，而这些都要在编译时确定。所以编译器就需要为每个局部变量明确大小，以便于预留空间。 在编译时，一切无法确定大小或者大小可以改变的数据，都无法安全地放在栈上，最好放在堆上。 存放在栈上的问题 栈上的内存分配是非常高效的。只需要改动栈指针（stack pointer），就可以预留相应的空间；把栈指针改动回来，预留的空间又会被释放掉。预留和释放只是动动寄存器，不涉及额外计算、不涉及系统调用，因而效率很高。 所以理论上说，只要可能，我们应该把变量分配到栈上，这样可以达到更好的运行速度。 那为什么在实际工作中，我们又要避免把大量的数据分配在栈上呢？ 这主要是考虑到调用栈的大小，避免栈溢出（stack overflow）。一旦当前程序的调用栈超出了系统允许的最大栈空间，无法创建新的帧，来运行下一个要执行的函数，就会发生栈溢出，这时程序会被系统终止，产生崩溃信息。过大的栈内存分配是导致栈溢出的原因之一，更广为人知的原因是递归函数没有妥善终止。一个递归函数会不断调用自己，每次调用都会形成一个新的帧，如果递归函数无法终止，最终就会导致栈溢出。 堆 当我们需要动态大小的内存时，只能使用堆，比如可变长度的数组、列表、哈希表、字典，它们都分配在堆上。进程可以通过增加堆的大小来分配内存，所谓堆就是一段长度可变的连续虚拟内存，始于进程的未初始化数据段末尾，随着内存的分配和释放而增减。通常将堆的当前内存边界成为program break。 除了动态大小的内存需要被分配到堆上外，动态生命周期的内存也需要分配到堆上。 上文中我们讲到，栈上的内存在函数调用结束之后，所使用的帧被回收，相关变量对应的内存也都被回收待用。所以栈上内存的生命周期是不受开发者控制的，并且局限在当前调用栈。 而堆上分配出来的每一块内存需要显式地释放，这就使堆上内存有更加灵活的生命周期，可以在不同的调用栈之间共享数据。 存放在堆上的问题 堆内存的这种灵活性也给内存管理带来很多挑战。 如果手工管理堆内存的话，堆上内存分配后忘记释放，就会造成内存泄漏。一旦有内存泄漏，程序运行得越久，就越吃内存，最终会因为占满内存而被操作系统终止运行。 如果堆上内存被多个线程的调用栈引用，该内存的改动要特别小心，需要加锁以独占访问，来避免潜在的问题。比如说，一个线程在遍历列表，而另一个线程在释放列表中的某一项，就可能访问野指针，导致堆越界（heap out of bounds）。而堆越界是第一大内存安全问题。 如果堆上内存被释放，但栈上指向堆上内存的相应指针没有被清空，就有可能发生**使用已释放内存（use after free）**的情况，程序轻则崩溃，重则隐含安全隐患。根据微软安全反应中心（MSRC）的研究，这是第二大内存安全问题。 GC、ARC 为了避免堆内存手动管理造成问题，Java等语言选择追踪式垃圾回收管理堆内存。Swift等语言选择自动引用计数。 追踪式垃圾回收 这种方式通过定期标记（mark）找出不再被引用的对象，然后将其清理（sweep）掉，来自动管理内存，减轻开发者的负担。 自动引用计数 在编译时，它为每个函数插入 retain/release 语句来自动维护堆上对象的引用计数，当引用计数为零的时候，release 语句就释放对象。 比较： 从效率上来说，GC 在内存分配和释放上无需额外操作，而 ARC 添加了大量的额外代码处理引用计数，所以 GC 效率更高，吞吐量（throughput）更大。 但是，GC 释放内存的时机是不确定的，释放时引发的 STW（Stop The World），也会导致代码执行的延迟（latency）不确定。所以一般携带 GC 的编程语言，不适于做嵌入式系统或者实时系统。当然，Erlang VM是个例外， 它把 GC 的粒度下放到每个 process，最大程度解决了 STW 的问题。 小结 对于存入栈上的值，它的大小在编译期就需要确定。栈上存储的变量生命周期在当前调用栈的作用域内，无法跨调用栈引用。堆可以存入大小未知或者动态伸缩的数据类型。 堆上存储的变量，其生命周期从分配后开始，一直到释放时才结束，因此堆上的变量允许在多个调用栈之间引用。但也导致堆变量的管理非常复杂，手工管理会引发很多内存安全性问题，而自动管理，无论是 GC 还是 ARC，都有性能损耗和其它问题。 栈上存放的数据是静态的，静态大小，静态生命周期；堆上存放的数据是动态的，动态大小，动态生命周期。 来源 内存：值放堆上还是放栈上，这是一个问题 Unix系统编程手册","link":"/2021/08/29/heap_stack/"},{"title":"冒号课堂笔记(1-4课)","text":"编程范式 范式译自英文的paradigm，也有译作典范、范型、范例的。所谓编程范式（programming paradigm），指的是计算机编程的基本风格或典范模式。借用哲学术语，如果说每个编程者都在创造虚拟世界，那么编程范式就是他们置身其中自觉不自觉采用德尔世界观与方法论。 库（lib）与框架（framework） 为保证软件开发快速有效，通常采取： 在宏观管理上选取框架以控制整体的结构与流程；在微观实现上利用库和工具包来解决细节问题。 框架的意义在于使设计者在特定领域的整体设计上不必重新发明轮子；库和工具包的意义在于使开发者摆脱底层编码，专注于特定问题和业务逻辑。 库和工具包是为给程序员带来自由的，框架是为程序员带来约束的。 库和工具包侧重代码重用，框架侧重设计重用。 框架是通过控制反转（IoC）机制控制全局，而库和工具包用callback知识局部的控制反转。程序员牺牲了对应用程序流程的主导权，换来的是更简洁的代码和更高的生产效率。 设计模式是软件的战术思想，架构师软件的战略决策。与框架、库和工具包不同，他们不是软件产品，是软件思想。 设计模式与惯用法都是针对常发问题的解决方法，但前者重设计，后者偏实现。 控制反转（Inversion of Control）是一种软件设计原则，与朝哪个用的用户代码调用可重用库（library）代码不同，IoC倒转控制流方向：由库代码调用用户代码。有人将此比作好莱坞原则：”不要打电话给我们，我们会打给你的”。 命令式编程时冯·诺依曼机运行机制的抽象。它把程序看作由若干行动指令组成的有序列表，并用变量来存储数据，用语句来执行指令。 过程式编程（procedural programming）是指引入了过程（procedure）、函数（function）或子程序（subroutine/subprogram）的命令式编程。 结构化编程时过程式编程的一种原则，其主要思想是：提倡在宏观上采用‘自顶向下’的设计，微观上采用顺序、选择和循环的逻辑结构，摒弃或限制goto语句，以保证程序结构清晰、易于调试和维护。 命令式编程模拟电脑运算，是行动导向（Action-Oriented）的，关键在于定义解法，即“怎么做”，因而算法是显性而目标是隐性的；声明式编程模拟人脑思维，目标驱动（Goal-Driven）的，关键在于描述问题，即“做什么”，因而目标是显性而算法是隐性的。 命令式 → 过程式 → 结构化过程式 声明式 → 函数式，数据流式；逻辑式，约束式；属性式；标记式、规范式等 函数式编程：通过数学函数的表达式变换和计算来求值。 逻辑式编程：通过一系列事实和规则，利用数理逻辑来推导或论证结论。 命令式编程的变量代表抽象化的内存，所存内容可能改变；声明式编程的变量代表抽象化的符号，所指对象一般不会改变。 声明式编程专注问题的分析与表达，而不是算法实现，不用指明执行顺序，一般没有或极少有副作用，也不存在内存管理问题。大大降低了编程的复杂度，也适合并发计算。 函数式语言和逻辑式语言擅长数理逻辑的应用； 命令式语言擅长业务逻辑的，尤其是交互式或事件驱动型应用。 编程是寻求一种机制，将指定的输入转化为指定的输出。 命令式：自动机机制，通过设计指令完成从初始态到最终态的转变； 函数式：数学变换机制，通过设计函数完成从自变量到因变量的计算； 逻辑式：逻辑证明机制，通过逻辑推理完成从题设到结论的证明。 OOP（Object-Oriented programming）是一种计算机编程模式，它将对象作为问题空间的基本元素，利用对象和对象间的相互作用来设计程序。 OOP大多是命令式，也有函数式和逻辑式的OO语言。 OOP的核心思想可以归纳为：以数据为中心组织逻辑，将系统视为相互作用的对象集合，并利用继承与多态来增强可维护性、可扩展性与可重用性。 过程式编程以过程为中心，自顶向下，逐步求精。 对象式编程以数据为中心，自底向上，逐步合并。 过程式程序的世界是君主制，OO程序的世界是民主制。 封装使得对象拥有个体身份，继承使对象拥有家庭身份，多态使得对象拥有社会身份。 并法式编程以进程为导向，以任务为中心，以资源共享与竞争为主线。 并法式编程有助于提高运行效率、充分利用资源、提高软件的响应能力、改善用户体验、保证公平竞争，同时以进程为单位将系统模块化，更加真实地模拟世界。 合理的并发式设计应该做到：软件易于重用、维护和测试；有效地利用资源、优化程序性能；保障进程安全和活性；减少性能损失和复杂度。 范式 体系 模块 模块关系 过程式 君主体系 过程 授命与听命 函数式 数学体系 函数 替换与合成 逻辑式 逻辑体系 断言 归纳与演绎 对象式 民主体系 对象 交流与服务 并发式 生产体系 进程 竞争与合作 STL有3要素：算法（algorithms）、容器（container）和迭代器（iterator） 算法是一系列切实有效的步骤； 容器是数据的集合，可以理解为抽象的数组； 迭代器是算法与容器之间的接口，可以理解为抽象的指针或游标。 算法串联数据，如脊贯肉；数据实体算法，如肉附脊。 泛型编程能够打破静态语言的数据类型之间的壁垒，在不牺牲效率并却类型安全的情况下，最大限度地提到算法的普适性。 泛型变成不仅能泛化算法中涉及的概念（数据类型），还能泛化行为（函数、方法和运算）。 泛型编程是以算法为导向的，以算法为中心，逐渐将其所涉及的概念内涵模糊化、外延扩大化，并将其所涉及的运算抽象化、一般化，从而提高算法的可重用性。 领域特定语言 DSL DSL 一般不会一步到位地编译成机器语言或汇编语言，而是通过现成的编译器生成器（compiler-compiler 或 compiler generator）首先转化为高级语言。这样不仅大大降低了难度，也方便程序的调试。 元编程 Meta-programming 元编程是编写、操纵程序的程序。在传统编程中，运算是动态的，但程序本身是静态的；在元编程中，二者都是动态的。 元编程能够减少手工编程，突破原语言的语法限制，提升语言的抽象级别与灵活性，从而提高程序员的生产效率。 许多开发工具、框架引擎之类的基础软件都有自动生成代码的功能，如许多IDE如Visual Studio、Delphi、Eclipse均能通过向导、拖放控件等方式自动生成源码；Servlet引擎将 JSP转换为Java代码。创造DSL以便高效地处理专门领域业务。自动生成重复代码，动态改变语句、函数、类等。 SoC 就是 Separation of Concerns，即关注点分离；DRY就是Don’t repeat yourself，即尽量减少重复代码。 不良代码通病：① 结构混乱或代码紊乱、松散；② 代码重复。解决此问题就是要做到——抽象与分离原则。 抽象与分解的原则：单一化、正交化。 每个模块职责明确专一，模块之间独立，即高内聚低耦合（high cohesion &amp; low coupling）。 AOP 切面 Aspect 描述的是横切关注点（cross-cutting concerns），是与程序纵向主流执行方向横向正交的关注焦点。 接入点是附加行为——建议（advice）的执行点，切入点（pointcut）是指切入点（join point）结合。这些接入点共享一段插入代码。切入点与建议组成切面（aspect），是模块化的横切关注点。 AOP的实现原理： AOP的实现关键是将advice的代码嵌入到主题程序中，术语称之为编织（weaving）。编织可以分为两种：一种是静态编织，通过修改源码或字节码（bytecode）在编译器（compile-time）、后编译器（post-compile）或加载器（load-time）嵌入代码（元编程、产生式编程实现）；另一种是动态编织，通过代理（proxy）等技术在运行时（run-time）实现嵌入。 AOP实施的3步：切面分解、切面实现和切面合成。 事件驱动 采用警觉式者主动去轮询（polling），行为取决于自身的观察判断，是流程驱动的，符合常规的流程驱动式编程（Flow-Driven Programming）的模式。 采用托付式者被动等通知（notification），行为取决于外来的突发事件，是事件驱动的，符合事件驱动式编程（Event-Driven Programming， aka EDP）的模式。 何为事件？ 事件是已经发生的某种令人关注的事情。在软件中，它一般表现为一个程序的某些信息状态上的变化。 事件分类： 内建事件（built-in event）： 底层事件（low-level event）或原生事件（native event） 在用户图形界面（GUI）系统中，这类事件由鼠标、键盘等硬件设备出发； 语义事件（semantic event） 一般代表用户的行为逻辑，是若干个底层事件的组合。比如鼠标的拖放（drag-and-drop）多表示移动被拖放的对象，由鼠标按下、移动和释放三个底层事件组成。 用户自定义事件（user-defined event）： 虚拟事件（virtual event） 原有内建事件基础上的包装。 此外，事件还有自然事件（natural event）和合成事件（synthetic event）。 事件驱动步骤： 实现事件处理器；注册事件处理器；实现事件循环。 事件驱动式的特征： 被动性与异步性。控制反转导致了事件驱动式编程的****被动性passivity**。此外，事件驱动式编程还具有异步性（asynchrony） 的特征，这是由于事件的不可预测性和随机性决定的。 回调函数（callback） Callback是指能作为参数传递的函数或代码，它允许底层模块调用高层模块，使调用者与被调者从代码上解耦。异步Callback在传入后并不会立即调用，使调用者与被调者从时间上解耦。 在C、CPP中函数指针可以实现callback。此外，抽象类（abstract class）、接口（interface）、CPP中的泛型函子（generic functor）和C#中的委托（delegate）都可以实现callback。 控制反转一般通过callback实现，其目的是降低模块之间的依赖性，从而降低模块的耦合度和复杂度。 依赖反转、控制反转和依赖注射是近义词，它们的主题是控制与依赖，目的是解耦，方法是反转，实现一切的关键是抽象接口。 依赖反转原则（Dependency-Inversion Principle，aka DIP）与控制反转相比更加具体——高层模块不依赖于低层模块，它们都应依赖抽象；抽象不应依赖于细节，细节应该依赖抽象。 依赖注射（Dependency Injection，aka DI）——动态地为一个软件组件提供外部依赖。 软件的可伸缩想（scalability）一般指从容应对工作量增长的能力，常与性能（performance）等指标一起考量。而控制反转的主要作用是降低模块之间的依赖性，从而降低模块的耦合度和复杂度，提高软件的可重用性、柔韧性和可扩展性。 独立是异步的前提，耗时是异步的理由。 观察者模式又称为发行/订阅模式，既是事件驱动式的简化，也是事件驱动式的核心思想。MVC架构是观察者模式在架构设计上的一个应用。 函数式编程中，函数是程序的核心，是头等公民，一般没有货很少有副作用，同时没有显示的内存管理。 函数式编程没有副作用（side affect）的好处： 没有副作用的函数易于重构、调试和单元测试。 代码有效性与函数顺序无关，方便并发处理和优化处理。 没有副作用的函数式是引用透明的（referential transparency），即一个表达式随时可以用它的值来替换，如数学中的函数一样，保证了数学思维的贯彻与运用。 惰性求值是需求驱动的，可以避免不必要的等待和计算。 相比于过程式和OOP，函数式思想过于数学化和抽象化，语言表现力和运行效率也不足。 代码的长度不是衡量软件复杂度的唯一标准。其中，逻辑结构越复杂、越微妙、受需求变化影响越大，软件越难控制和维护。 算法=逻辑+控制 。逻辑式编程将算法中的控制部分大都移交给编程语言，开发人员主要关注算法的核心逻辑。这样大大减轻了开发人员的负担，编码也更加简洁，更具有可维护性和可扩展性。 区别于过程式和函数式，逻辑式没有明显的输入和输出。 逻辑式编程不仅适用于人工智能方面的学术领域，还广泛适用于各种设计知识管理、决策分析等方面的应用领域。 相比于设计模式，编程范式针对问题领域更广泛，提出的思想和方法更为普遍适用、更抽象、更系统。此外， 设计模式重在设计，对语言和工具要求不高，而编程范式要求建立一套抽象机制和方法体系，离不开语言或工具的支持。 编程范式的核心价值在于：突破原有编程方式的某些限制，带来新思维和新方法，从而进一步解放程序员的劳动力。 闭包是一种能保存当初创建时环境变量的函数。它通常以匿名方式存在，多用于函数式编程中，能够让代码结构更加清晰简洁。Java中的匿名函数可以看做是OO化的闭包形式。 所谓迭代学习法，是指在具体知识和抽象理论之间进行增量式的循环学习。 // todo. 继续整理第五课 语言小谈","link":"/2020/05/17/maopao_1/"},{"title":"冒号课堂笔记(5-6课)","text":"编程语言 Duck类型的哲学：名义不重要，重要的是能力。 鸭子类型是动态类型的一种风格，允许非继承性多态，即一个对象的类型可以由其接口集合来去定，不需要通过显示继承，有利于代码重用。由于Duck类型的接口组合是隐性的，其使用者须要比普通的interface更小心，以免误用；其维护者也要小心，以免破坏客户端代码；另外，它也可能造成滥用。 数据类型包含两个要素： 允许取值的集合 允许参与的运算 如int类型在Java中既定义了介于−231-2^{31}−231和231−12^{31}-1231−1之间的整数集合，也定义了该集合上的整数所能进行的运算。 限定一个变量的数据类型，就意味着限制该变量的取值范围和所参与的运算，这从一定程度上保证了代码的安全性。 数据类型既有针对机器的物理意义，又有针对人的逻辑意义。前者进行底层的内存分配和数值运算等，后者用于表达高层的逻辑概念。既然类型如此重要，类型检查就必不可少。 所谓动态类型语言（dynamic typing language），正是指类型检查发生在运行期间（run-time）的语言。 优点：代码灵活简明、易于重用，适合泛型编程和快速原型开发。 静态类型语言（static typing language）是类型检查发生在运行之前（包括编译期间，compile-time）的语言。 优点：运行之前的类型检查增强了代码的可靠性，使编译器有可能进行优化处理而提高运行效率，节省了运行期的类型检查所占用的时间和空间，同时类型声明有辅助文档的功效。 动态类型的变量不需要显示声明，静态类型的变量需要通过显示声明或类型推断。 类型的动静与强弱完全是正交的两个概念。静态类型语言中，有强类型的Java，也有弱类型的C；动态类型语言中，有强类型的Smalltalk，也有弱类型的JavaScript。前者通过类型的绑定时间来划分，后者以类型的约束强度来划分。 通常弱类型语言（weakly-typed language）允许一种类型的值隐性转化为另一种类型。 类型按安全性来划分，可分为类型安全（type-safe language）和类型不安全语言（type-unsafe language）。 类型检查的目的就是为了避免类型错误（type error），即杜绝因类型问题而产生的错误或不良代码。 弱类型语言允许类型的隐性转化，被认为是类型不安全的；而强类型的语言则不允许这种转化，被认为是类型安全的。 静态类型检查实行“疑罪从有”的有罪推定制，动态类型检查实行“疑罪从无”的无罪推定制。取舍原则是：Static Typing Where Possible, Dynamic Typing When Needed。即尽可能守规则，必要时变通。 脚本语言一般是解释型语言，不需要通过“编译 - 链接 - 运行”的循环圈，便利快捷，加之简单宽松的语法、面向字符的特性，以及较强的文本处理能力，尤其适合作为年和语言，多用于系统管理和集成。 动态语言秉承的理念：优化人的时间而不是机器的时间。为提高人的生产效率，宁肯牺牲部分程序性能或者购买更高配置的硬件。 动态语言在程序运行期间改变数据结构、函数定义、对象行为或指令流程等，相比静态语言在结构和功能上的更就有动态性。 优点： 代码量少，从一定程度上减轻了维护难度； 提供字节码编译或JIT编译，弥补了运行效率上的不足； 一些模块的结构和功能上的变化不会导致相关模块的重新编译和链接； 具有灵活、适应力强和开发周期短的特点，能够快速响应客户端的需求变化，并且适合快速原型开发。 C++提倡使用RAII原则解决包括内存在内的资源管理问题。RRIF（Resource Release Is Finalization），即“资源释即终结化”，其思想是：将资源的取放与某一对象的生命周期绑定，初始化对象是获取资源，终结化对象时释放资源。用户代码不再直接管理资源，只需控制相应对象即可。这样代码得以简化，资源的有效性也得以保障，并且还是异常安全的（exception-safe）。","link":"/2020/06/10/maopao_2/"},{"title":"算法数学基础 - 1","text":"算法研究的主要内容 计算复杂性理论（Computational complexity theory） 常见问题： 货郎问题 （NP-hard 问题） 0-1背包问题 问题的解为0-1向量 &lt;X1,X2,...,Xn&gt;&lt;X_1,X_2,...,Xn_&gt;&lt;X1​,X2​,...,Xn&gt;​ 双机调度问题 NP-hard问题 问题有数千个，大量存在于各个领域； 至今未找到有效算法：现有算法的运行时间是输入规模的指数或更高阶函数；、 至今没有人能够证明对于这类问题存在多项式时间算法； 是否存在多项式时间算法等价于存在有效计算的边界 程序 = 算法 + 数据结构 好的算法： 提高求解问题的效率；节省存储空间 算法的研究目标： 问题 → 建模并寻找算法 （算法技术设计） 算法 → 算法的评价 （算法分析方法） 算法类 → 问题复杂度的估计 （问题复杂度分析） 问题类 → 能够求解的边界 （计算复杂性理论） NP完全理论 问题复杂度： 以排序算法（插入、冒泡、快排、堆排、归并） 哪个个排序算法效率高？ 是否可以找到更好的排序算法？ 排序问题的计算难度如何？ 其他问题的计算复杂度 问题计算复杂度估计方法 算法设计与分析（调度问题、背包问题和投资问题） 问题建模？对输入参数和解给出形式化或半形式化的描述。 设计算法：采用什么算法设计技术？ 正确性：这个方法是否对所有实例都得到最优解？如何证明？如果不是，能否找到反例？ 分析算法——效率 算法的相关概念 问题及实例 问题：需要回答的一般性提问，通常含有若干参数 问题描述： 定义问题参数（集合、变量、函数、序列等）； 说明每个参数的取值范围及参数间的关系； 定义问题的解； 说明解满足的条件（优化目标或约束条件） 问题实例 参数的每一组赋值可以得到问题的实例 什么是算法？ 算法即有限条指令的序列，这个指令序列确定了解决某个问题的一系列运算或操作。 算法A解问题P： 把问题P的任何实例作为算法A的输入 每步计算都是确定性的 能够在有限步停机 输出该实例的正确的解 算法的表示 （伪代码） 赋值语句： ← 分支语句：if ... then ... [else...] 循环语句：while, for, repeat until 转向语句：goto 输出语句：return 调用：直接写过程的名字 注释：//.. 算法时间复杂度定义？ 算法时间复杂度：针对指定的基本运算，计数算法所做的运算次数。 基本运算：比较、加法、乘法、置指针、交换…… 排序：元素之间的比较 检索：被检索元素与数组元素的比较 整数乘法：每位数字相乘（位乘）1次m位和n位整数相乘要做mn次位乘 矩阵相乘：每对元素乘1次 i×j 矩阵与j×k矩阵相乘要做ijk次乘法 图的遍历：置指针 …… 输入规模：输入串编码长度 通常用下述参数度量：数组元素多少，调度问题的任务个数，图的顶点数与边数等。 排序：数组元素个数n 检索：被检索数组的元素个数n 整数乘法：两个整数的位数 m，n 矩阵相乘：矩阵的行列数i,j,k 图的遍历：图的顶点数n，边数m …… 算法基本运算次数可表示为输入规模的函数 给定问题和基本运算决定了一个算法类。 时间复杂度函数的表示：函数渐近的界 对于相同输入规模的不同实例，算法的基本运算次数也不一样，可以定义为两种时间复杂度。 最坏情况下的时间复杂度 W(n)W(n)W(n) 平均情况下的时间复杂度A(n)A(n)A(n) 设SSS是规模为nnn的实例集，实例I∈SI \\in SI∈S的概率为PIP_IPI​，算法对实例III执行的基本运算次数为tIt_ItI​。 A(n)=∑I∈SPItIA(n) = \\sum_{I \\in S} P_It_I A(n)=I∈S∑​PI​tI​ 有关函数渐近的界的描述 大O符号 定义：设fff和ggg是定义域为自然数集NNN上的函数。若存在正数ccc和n0n_0n0​，使得对一切n≥n0n \\ge n_0n≥n0​有 0≤f(n)≤cg(n)0 \\le f(n) \\le c g(n)0≤f(n)≤cg(n) 成立，则称f(n)f(n)f(n)的渐近界上界是g(n)g(n)g(n)，记作f(n)=O(g(n))f(n)=O(g(n))f(n)=O(g(n))。 举例： 设f(n)=n2+nf(n)=n^2+nf(n)=n2+n，则 f(n)=O(n2)f(n)=O(n^2)f(n)=O(n2)，取c=2,n0=1c=2,n_0=1c=2,n0​=1即可；f(n)=O(n3)f(n)=O(n^3)f(n)=O(n3)，取c=1,n0=2c=1,n_0=2c=1,n0​=2即可。 注意： f(n)=O(g(n))f(n)=O(g(n))f(n)=O(g(n))，f(n)f(n)f(n)的阶不高于g(n)g(n)g(n)的阶； 可能存在多个正数ccc，只要指出一个即可； 对前面有限个值可以不满足不等式； 对于常函数可以写作O(1)O(1)O(1)。 大Ω符号 定义：设fff和ggg是定义域为自然数集NNN上的函数。若存在正数ccc和n0n_0n0​，使得对一切n≥n0n \\ge n_0n≥n0​ 有 0≤cg(n)≤f(n)0 \\le cg(n) \\le f(n)0≤cg(n)≤f(n) 成立，则称f(n)f(n)f(n)的渐近的下界是g(n)g(n)g(n)，记作 f(n)=Ω(g(n))f(n) = \\Omega(g(n))f(n)=Ω(g(n))。 举例： 设f(n)=n2+nf(n)=n^2+nf(n)=n2+n，则f(n)=Ω(n2)f(n)=\\Omega(n^2)f(n)=Ω(n2)，取c=1,n0=1c=1,n_0=1c=1,n0​=1即可；f(n)=Ω(100n)f(n)=\\Omega(100n)f(n)=Ω(100n)，取c=1/100,n0=1c=1/100,n_0=1c=1/100,n0​=1即可。 注意： f(n)=Ω(g(n))f(n)=\\Omega(g(n))f(n)=Ω(g(n))，f(n)f(n)f(n)的阶不低于g(n)g(n)g(n)的阶（下界）； 可能存在多个正数ccc，指出一个即可； 对前面有限个nnn值可以不满足上述不等式。 小o符号 定义：设fff和ggg是定义域为自然数集NNN上的函数。若对于任意正数ccc都存在n0n_0n0​，使得对一切n≥n0n \\ge n_0n≥n0​ 有0≤f(n)&lt;cg(n)0 \\le f(n) &lt; cg(n)0≤f(n)&lt;cg(n)成立，则记作 f(n)=o(g(n))f(n)=o(g(n))f(n)=o(g(n))。 举例： f(n)=n2+nf(n)=n^2+nf(n)=n2+n，则f(n)=o(n3)f(n)=o(n^3)f(n)=o(n3), 当 c≥1c\\ge1c≥1显然成立，因为n2+n&lt;cn3,(n0=2)n^2+n&lt;cn^3,(n_0=2)n2+n&lt;cn3,(n0​=2); 当1&gt;c&gt;01&gt;c&gt;01&gt;c&gt;0，取n0&gt;┌2/c┐n_0&gt;\\ulcorner2/c\\urcornern0​&gt;┌2/c┐即可。因为cn≥cn0≥2,(n≥n0)cn\\ge cn_0 \\ge 2, (n\\ge n_0)cn≥cn0​≥2,(n≥n0​)， n2+n&lt;2n2&lt;cn3n^2+n&lt;2n^2&lt;cn^3n2+n&lt;2n2&lt;cn3成立。 注意： f(n)=o(g(n))f(n)=o(g(n))f(n)=o(g(n))，f(n)f(n)f(n)的阶低于g(n)g(n)g(n)的阶； 对于不同的正数ccc，n0n_0n0​不一样，ccc越小n0n_0n0​越大； 对前面有限个nnn值可以不满足不等式。 小ω符号 定义：设fff和ggg是定义域为自然数集NNN上的函数。若对于任意正数ccc都存在n0n_0n0​，使得对一切n≥n0n \\ge n_0n≥n0​有 0≤cg(n)&lt;f(n)0 \\le cg(n) &lt; f(n)0≤cg(n)&lt;f(n) 成立，则记作 f(n)=ω(g(n))f(n) = \\omega(g(n))f(n)=ω(g(n))。 举例： 设f(n)=n2+nf(n)=n^2+nf(n)=n2+n，则f(n)=ω(n)f(n)=\\omega(n)f(n)=ω(n)。不能写f(n)=ω(n2)f(n)=\\omega(n^2)f(n)=ω(n2)，因为取c=2c=2c=2，不存在n0n_0n0​使得对一切n≥n0n\\ge n_0n≥n0​有下式成立 cn2=2n2&lt;n2+ncn^2=2n^2&lt;n^2+ncn2=2n2&lt;n2+n。 注意： f(n)=ω(g(n))f(n)=\\omega (g(n))f(n)=ω(g(n))，f(n)f(n)f(n)的阶高于g(n)g(n)g(n)的阶（下界)； 对于不同的正数ccc，n0n_0n0​不等，ccc越大n0n_0n0​越大； 对前面有限个nnn值可以不满足不等式。 θ符号 定义：若f(n)=O(g(n))f(n)=O(g(n))f(n)=O(g(n))且f(n)=Ω(g(n))f(n)=\\Omega(g(n))f(n)=Ω(g(n))，则记作f(n)=Θ(g(n))f(n)=\\Theta(g(n))f(n)=Θ(g(n))。 举例： f(n)=n2+n,g(n)=100n2f(n)=n^2+n, g(n)=100n^2f(n)=n2+n,g(n)=100n2，那么有f(n)=Θ(g(n))f(n)=\\Theta(g(n))f(n)=Θ(g(n))。 注意： f(n)f(n)f(n)的阶与g(n)g(n)g(n)的阶相等； 对前面有限个nnn值可以不满足条件。 Big-O标记 O(1) 常量，运行时间和元素个数无关； O(log(n)) 对数，运行时间随元素个数的增加呈对数增长； O(n) 线性，运行时间随元素个数的增加呈线性增长； O(nlog(n)) n-log-n，运行时间随元素个数的增加呈“线性与对数的乘积”的增长； O(n^2) 二次方，运行时间随元素个数的增加呈平方增长。 Big-O标记隐藏（忽略）了指数较小的因子。","link":"/2020/05/13/math_base_1/"},{"title":"图的存储与算法","text":"图论作为数学领域的重要分支已经有数百年的历史。图论应用的领域广泛，包括了地图、网页信息、电路、任务调度、商业交易、计算机网络和社交网络等。 图的类型 图是由一组顶点和一组能够将两个顶点相连的边组成的。 图有4种重要的模型：无向图（简单连接）、有向图（连接有方向性）、加权图（连接带有权值）和加权有向图（连接既有方向性又带有权值）。 特殊的图： 自环，即一条连接一个顶点和其自身的边 连接同一对顶点的两条边称为平行边。 术语 在图中，路径是由边顺序连接的一系列顶点。简单路径是一条没有重复顶点的路径。环是一条至少含有一条边且起点和终点相同的路径。简单环是一条（除了起点和终点必须相同之外）不含有重复顶点和边的环。路径或者环的长度为其所包含的边数。 如果从任意一个顶点都存在一条路径到达另一条任意顶点，我们称这幅图为连通图。一副非连通图的图由若干连通部分组成，他们都是其极大连通子图。 树是一副无环连通图。互不相连的树组成的集合叫做森林。连通图的生成树是它的一副子图，它含有图中所有的顶点且是一棵树。图的生成森林是它的所有连通子图的生成树的集合。 图的密度是指已经连接的顶点对占所有可能被连接的顶点对的比例。在稀疏图中，被连接的顶点对很少；而在稠密图中，只有少部分顶点之间没有边连接。 二分图是一种能够将所有结点分为两部分的图，其中图的每条边所连接的两个顶点都分别属于不同的部分。 图的存储 图存储的要求： 它必须为可能在应用中碰到的各种类型的图预留出足够的空间； Graph的实例方法的实现一定要快——它们是开发处理图的各种用例的基础。 图数据的存储方式有以下几种： 邻接矩阵 使用V×VV \\times VV×V的布尔矩阵，当顶点v 和顶点w之间有相连接的边时，定义v行w列元素值为true，否则为false。优点是实现简单，缺点是空间复杂度高，为V2V^2V2。 邻接表（链式存储） 以顶点为索引的列表数组，其中每个元素都对应一条链表，其中每个元素都是和该顶点相邻的顶点列表。 边集数组 使用Edge类，它含有两个int实例变量。这种表示方法简洁但不满足第二个条件，实现adj()需要检查所有的边。 前向星 链式前向星 性能复杂度 数据结构 所需空间 添加一条边v→w 检查w和v是否相邻 遍历v的所有相邻顶点 边的列表 EEE 111 EEE EEE 邻接矩阵 V2V^2V2 111 111 VVV 邻接表 E+VE+VE+V 111 degree(v)degree(v)degree(v) degree(v)degree(v)degree(v) 邻接集 E+VE+VE+V log⁡V\\log{V}logV log⁡V\\log{V}logV log⁡V+degree(v)\\log{V}+degree(v)logV+degree(v) 图的数据类型 相关API class Graph Graph(int V) 创建一个含有V个顶点但不含有边的图 Graph(In in) 从标准输入流in读入一幅图 int V() 顶点数 int E() 边数 void addEdge(int v, int w) 向图中添加一条边v→w Itereable&lt;Integer&gt; adj(v) 和v相邻的所有顶点 String toString() 对象的字符串表示 toString()方法和adj()方法用来允许用例遍历给定顶点的所有相邻顶点（遍历顺序不确定）。 伪代码 计算v的度数 12345int degree(Graph G, int v) { int degree = 0; for (int w: G.adj(v)) degree++; return degree;} 计算所有顶点的最大度数 123456789int maxDegree(Graph G) { int max = 0; for (auto v = 0; v &lt; G.V();v++) { if (degree(G, v) &gt; max) { max = degree(G, v); } } return max;} 计算所有顶点的平均度数 123double avgDegree(Graph G) { return 2 * G.E() / G.V();} 计算自环的个数 123456789int numberOfSelfLoops(Graph G) { int count = 0; for (auto v=0; v&lt;G.V(); v++) { for (const auto w: G.adj()) { int (v == w) count++; } } return count/2; // 每条边被记过两次} 图的邻接表的字符串表示（Graph的实例方法） 1234567891011std::string toString() { std::string s = V + &quot; vertices, &quot; + E + &quot; edges\\n&quot;; for (auto v=0; v&lt;V; v++) { s += v + &quot;: &quot;; for (const auto w: adj(v)) { s += w + &quot; &quot;; } s += &quot;\\n&quot;; } return s;} 图的相关算法 深度优先搜索 广度优先搜索 参考 https://zhuanlan.zhihu.com/p/215384586 《算法》","link":"/2020/10/26/graph_storage_algorithms/"},{"title":"算法数学基础 - 2","text":"函数渐近界的定理 定理1 设fff和 ggg是定义域为自然数集合的函数： （1）如果lim⁡n→∞f(n)/g(n)\\lim\\limits_{n\\rightarrow\\infty}f(n)/g(n)n→∞lim​f(n)/g(n)存在，并且等于某个常数c&gt;0c&gt;0c&gt;0，那么f(n)=Θ(g(n))f(n)=\\Theta(g(n))f(n)=Θ(g(n))。 （2）如果lim⁡n→∞f(n)/g(n)=0\\lim\\limits_{n\\rightarrow\\infty}f(n)/g(n)=0n→∞lim​f(n)/g(n)=0，那么f(n)=o(g(n))f(n)=o(g(n))f(n)=o(g(n))。 （3）如果lim⁡n→∞f(n)/g(n)=+∞\\lim\\limits_{n\\rightarrow\\infty}f(n)/g(n)=+\\inftyn→∞lim​f(n)/g(n)=+∞，那么f(n)=ω(g(n))f(n)=\\omega(g(n))f(n)=ω(g(n))。 推理1 → 多项式函数的阶低于指数函数的阶，nd=o(rn),r&gt;1,d&gt;0n^d=o(r^n),r&gt;1,d&gt;0nd=o(rn),r&gt;1,d&gt;0。 推理2 →对数函数的阶低于幂函数的阶，ln⁡n=o(nd),d&gt;0\\ln n=o(n^d),d&gt;0lnn=o(nd),d&gt;0。 定理2 设函数fff，ggg，hhh的定义域为自然数集合， （1）如果f=O(g)f=O(g)f=O(g)且g=O(h)g=O(h)g=O(h)，那么f=O(h)f=O(h)f=O(h)； （2）如果f=Ω(g)f=\\Omega(g)f=Ω(g)且g=Ω(h)g=\\Omega(h)g=Ω(h) ，那么f=Ω(h)f=\\Omega(h)f=Ω(h)； （3）如果f=Θ(g)f=\\Theta(g)f=Θ(g)且g=Θ(h)g=\\Theta(h)g=Θ(h)，那么f=Θ(h)f=\\Theta(h)f=Θ(h)。 函数的阶之间的关系具有传递性。 定理3 假设函数fff和ggg的定义域为自然数集，若对某个其他函数hhh，有f=O(h)f=O(h)f=O(h)和g=O(h)g=O(h)g=O(h)，那么f+g=O(h)f+g=O(h)f+g=O(h)。 该定理可以推广到有限个函数。即算法由有限步骤构成，若每一步的时间复杂度函数的上界都是h(n)h(n)h(n)，那么该算法的时间复杂度函数可以写作O(h(n))O(h(n))O(h(n))。在常数步的情况下取最高阶函数即可。 几种重要函数的性质 基本函数类 至少指数级：2n,3n,n! ,…2^n,3^n,n!~,\\dots2n,3n,n! ,… 多项式级：n,n2,nlog⁡n,n12,…n,n^2,n\\log n,n^{\\frac{1}{2}},\\dotsn,n2,nlogn,n21​,… 对数多项式级：log⁡n,log⁡2n,log⁡log⁡n,…\\log n, \\log^2n,\\log\\log n,\\dotslogn,log2n,loglogn,… 对数函数 符号： log⁡n=log⁡2n\\log n = \\log_2nlogn=log2​n log⁡kn=(log⁡n)k\\log^kn=(\\log n)^klogkn=(logn)k log⁡log⁡n=log⁡(log⁡n)\\log \\log n=\\log(\\log n)loglogn=log(logn) 性质： （1）log⁡2n=Θ(log⁡ln)\\log_2n=\\Theta(\\log_ln)log2​n=Θ(logl​n) （2）log⁡bn=o(nα),(α&gt;0)\\log_bn=o(n^\\alpha), (\\alpha&gt;0)logb​n=o(nα),(α&gt;0) （3）alog⁡bn=nlog⁡baa^{\\log_bn}=n^{\\log_ba}alogb​n=nlogb​a 指数函数与阶乘 Stirling公式 n!=2πn(ne)n(1+Θ(1n))n!=\\sqrt{2\\pi n}(\\frac{n}{e})^n(1+\\Theta(\\frac{1}{n}))n!=2πn​(en​)n(1+Θ(n1​)) n!=o(nn)n!=o(n^n)n!=o(nn) n!=ω(2n)n!=\\omega(2^n)n!=ω(2n) log⁡(n!)=Θ(nlog⁡n)\\log(n!)=\\Theta(n\\log n)log(n!)=Θ(nlogn) 取整函数 定义： ⌊x⌋\\lfloor x\\rfloor⌊x⌋：表示小于等于xxx的最大整数 ⌈x⌉\\lceil x\\rceil⌈x⌉：表示大于等于xxx的最小整数 举例： ⌊2.6⌋=2,⌈2.6⌉=3,⌊2⌋=⌈2⌉=2\\lfloor 2.6\\rfloor=2, \\lceil 2.6\\rceil=3,\\lfloor 2\\rfloor=\\lceil 2\\rceil=2⌊2.6⌋=2,⌈2.6⌉=3,⌊2⌋=⌈2⌉=2 应用：二分搜索 输入数组长度nnn，中位数位置：⌊n/2⌋\\lfloor n/2\\rfloor⌊n/2⌋，与中位数比较后子问题大小：⌊n/2⌋\\lfloor n/2\\rfloor⌊n/2⌋ 性质 （1）x−1&lt;⌊x⌋≤x≤⌈x⌉&lt;x+1x-1&lt;\\lfloor x\\rfloor \\le x \\le \\lceil x\\rceil &lt; x+1x−1&lt;⌊x⌋≤x≤⌈x⌉&lt;x+1 （2）⌊x+n⌋=⌊x⌋+n,⌈x+n⌉=⌈x⌉+n,n为整数\\lfloor x+n \\rfloor=\\lfloor x\\rfloor+n,\\lceil x+n\\rceil=\\lceil x\\rceil+n, n为整数⌊x+n⌋=⌊x⌋+n,⌈x+n⌉=⌈x⌉+n,n为整数 （3）⌈n2⌉+⌊n2⌋=n\\lceil \\frac{n}{2}\\rceil+\\lfloor \\frac{n}{2}\\rfloor=n⌈2n​⌉+⌊2n​⌋=n （4）⌈⌈na⌉b⌉=⌈nab⌉,⌊⌊na⌋b⌋=⌊nab⌋\\lceil \\frac{\\lceil\\frac{n}{a} \\rceil}{b}\\rceil=\\lceil\\frac{n}{ab} \\rceil, \\lfloor \\frac{\\lfloor \\frac{n}{a}\\rfloor}{b}\\rfloor =\\lfloor \\frac{n}{ab}\\rfloor⌈b⌈an​⌉​⌉=⌈abn​⌉,⌊b⌊an​⌋​⌋=⌊abn​⌋ 按照阶排序 22n,n!,n2n,(3/2)n,(log⁡n)log⁡n=nlog⁡log⁡n,n3,log⁡(n!)=Θ(nlog⁡n),n=2log⁡n,log⁡2n,log⁡n,log⁡n,log⁡log⁡n,n1/log⁡n=12^{2^n},\\quad n!,\\quad n2^n,\\quad (3/2)^n,\\quad (\\log n)^{\\log n} =n^{\\log\\log n}, \\\\ n^3,\\quad \\log(n!)=\\Theta(n\\log n),\\quad n=2^{\\log n}, \\\\ \\log^2n,\\quad \\log n,\\quad \\sqrt{\\log n}, \\quad \\log\\log n, \\\\ n^{1/\\log n}=1 22n,n!,n2n,(3/2)n,(logn)logn=nloglogn,n3,log(n!)=Θ(nlogn),n=2logn,log2n,logn,logn​,loglogn,n1/logn=1 来源： 北京大学-算法设计与分析","link":"/2020/05/13/math_base_2/"},{"title":"多线程编程","text":"进程与线程 进程是资源（CPU、内存等）分配的基本单位，具有一定独立功能的程序关于某个数据集合上的一次运行活动，进程是系统进行资源分配和调度的一个独立单位。 线程是进程的一个实体，是独立运行和独立调度的基本单位（CPU上真正运行的是线程）。线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈)，但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。 进程与线程的区别 进程是资源分配的基本单位；线程是程序执行的基本单位。 进程拥有自己的资源空间，没启动一个进程，系统就会为它分配地址空间； 线程与CPU资源分配无关，多个线程共享同一进程内的资源，使用相同的地址空间。 一个进程可以包含若干个线程。 线程与进程的优劣势： 线程之间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据，而进程之间的通信需要以通信的方式（Inter Process Communication，IPC)进行。不过如何处理好同步与互斥是编写多线程程序的难点。 线程的调度与切换比进程快很多，同时创建一个线程的开销也比进程要小很多。 但是多进程程序更健壮，多线程程序只要有一个线程死掉，整个进程也死掉了，而一个进程死掉并不会对另外一个进程造成影响，因为进程有自己独立的地址空间。 进程的本质：正在执行的一个程序，可以进程比作一个容器或者工厂 进程与进程之间相对独立 进程可以包括几个或者上百个线程在运行。 内存（逻辑内存）包括在进程里面，每个进程的内存都是互相独立的，但从一个更高的层次上看，不同的进程也共享着一个巨大的空间，这个空间就是整个计算机。 进程共有文件/网络句柄（handle），这样可以打开同一个文件，抢同一个网络端口。 线程的本质：真正运行的是一个一个的线程 栈（堆栈）：主线程的main函数、进行函数调用的参数和返回地址、局部变量等内容都会被压入栈内 PC（Program Couner）：程序计数器，PC的指针指向代码所在的内存地址。 TLS（Thread local storage）：分配内存，存放变量 进程/线程如何通信? 进程可以通过管道、套接字、信号交互、共享内存、消息队列等等进行通信；而线程本身就会共享内存，指针指向同一个内容，交互很容易。 123进程process：进程就是时间总和=执行环境切换时间+程序执行时间--&gt;CPU加载执行环境-&gt;CPU执行程序-&gt;CPU保存执行环境线程thread：线程也是时间总和=执行环境切换时间（共享进程的）+程序模块执行时间--&gt;CPU加载执行环境（共享进程的）-&gt;CPU执行程序摸块-&gt;CPU保存执行环境（共享进程的）进程和线程都是一个时间段的描述，是CPU工作时间段的描述。是运行中的程序指令的一种描述，这需要与程序中的代码区别开来，线程是更细小的时间段。 线程安全的方法 线程安全就是多线程访问时，采用了加锁机制，当一个线程访问该类的某个数据时，进行保护，其他线程不能进行访问直到该线程读取完，其他线程才可使用。不会出现数据不一致或者数据污染。 线程不安全就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据。 根据《Java Concurrency in Practice》的定义，一个线程安全的 class 应当满足以下三个条件： 多个线程同时访问时，其表现出正确的行为。 无论操作系统如何调度这些线程， 无论这些线程的执行顺序如何交织（interleaving）。 调用端代码无须额外的同步或其他协调动作。 另外一种定义，同一类型的多个对象能分别被各自所属的不同线程并发访问，就算是线程安全的。在这个定义下，C++ 标准库容器和基本类型都是“线程安全的”。为了与前一种定义区别，这个一般叫做 thread compatible。 如何理解互斥锁、条件锁、读写锁以及自旋锁？ https://www.zhihu.com/question/66733477/answer/1267625567 https://www.zhihu.com/question/66733477/answer/246535792 使用场景 https://zhuanlan.zhihu.com/p/246114725 无锁编程的场景 https://zhuanlan.zhihu.com/p/38664758 无锁的数据结构 为什么要无锁编程？ 异步比同步要好 非阻塞比阻塞要好，而锁会引起阻塞，线程一直在跑就是正常的cpu调度，阻塞唤醒一次则意味着两次cpu调度，且竞争比较激烈的时候，一次唤醒所有等待锁的线程又会带来阻塞。","link":"/2021/08/16/multiple-thread/"},{"title":"算法数学基础 - 3","text":"数列求和公式 等差、等比数列与调和级数 ∑k=1nak=n(a1+an)2∑k=0naqk=a(1−qn+1)1−q,∑k=0∞aqk=a1−q(q&lt;1)∑k=1n1k=ln⁡n+O(1)\\displaystyle\\sum_{k=1}^{n}a_k=\\frac{n(a_1+a_n)}{2} \\\\ \\sum_{k=0}^{n}aq^k=\\frac{a(1-q^{n+1})}{1-q}, \\sum_{k=0}^{\\infty}aq^k=\\frac{a}{1-q}(q&lt;1) \\\\ \\sum_{k=1}^{n}\\frac{1}{k}=\\ln n+O(1)\\\\ k=1∑n​ak​=2n(a1​+an​)​k=0∑n​aqk=1−qa(1−qn+1)​,k=0∑∞​aqk=1−qa​(q&lt;1)k=1∑n​k1​=lnn+O(1) 递推方程 设序列a0,a1,…,an,…a_0,a_1,\\dots,a_n,\\dotsa0​,a1​,…,an​,…简记为{an}\\{a_n\\}{an​}，一个把ana_nan​与某些个ai(i&lt;n)a_i(i&lt;n)ai​(i&lt;n)联系起来叫做关于序列{an}\\{a_n\\}{an​}的递推方程。 迭代法求解递推方程 迭代法： 不断用递推方程的右部替换左部 每次替换，随着nnn的降低在和式中多出一项 直到出现初值停止迭代 将初值并入对和式求和 可用数学归纳法验证解的正确性 换元迭代： 将对nnn的递推式换成对其他变元kkk的递推式 对kkk直接迭代 将解（关于kkk的函数）转换成为关于nnn的函数 差消法化简高阶递推方程 递归树 递归树： 递归树是迭代计算的模型； 递归树的生成过程与迭代过程一致； 递归树上所有恰好是迭代之后产生和式中的项； 对递归树上的项求和就是迭代后方程的解。 迭代在递归树中的表示 如果递归树某结点标记为W(m)W(m)W(m)， W(m)=W(m1)+⋯+W(mt)+f(m)+⋯+g(m),m1,…,mt&lt;mW(m)=W(m_1)+\\dots+W(m_t)\\\\ +f(m)+\\dots+g(m), m_1,\\dots,m_t&lt;mW(m)=W(m1​)+⋯+W(mt​)+f(m)+⋯+g(m),m1​,…,mt​&lt;m 其中，W(m1),…,W(mt)W(m_1),\\dots,W(m_t)W(m1​),…,W(mt​)称为函数项。 递归树的生成规则 初始，递归树只有根节点，其值为W(n)W(n)W(n) 不断继续下述过程： 将函数项叶节点的迭代式W(m)W(m)W(m)表示成二层子树 用该子树替换该叶节点 继续递归树的生成，直到树中无函数项（只有初值）为止。 主定理及其证明 主定理的应用背景 求解地推方程 T(n)=aT(n/b)+f(n)T(n)=aT(n/b)+f(n)T(n)=aT(n/b)+f(n) aaa ： 归约后的子问题个数 n/bn/bn/b：归约后子问题的规模 f(n)f(n)f(n)：归约过程及组合子问题的解的工作量 二分检索：T(n)=T(n/2)+1T(n)=T(n/2)+1T(n)=T(n/2)+1 二分归并排序：T(n)=2T(n/2)+n−1T(n)=2T(n/2)+n-1T(n)=2T(n/2)+n−1 主定理：设a≥1,b&gt;1a\\ge1,b&gt;1a≥1,b&gt;1为常数，f(n)f(n)f(n)为函数，T(n)T(n)T(n)为非负整数，且T(n=aT(n/b)+f(n)T(n=aT(n/b)+f(n)T(n=aT(n/b)+f(n)，则 若f(n)=O(nlog⁡ba−ϵ),ϵ&gt;0f(n)=O(n^{\\log_ba-\\epsilon}),\\epsilon&gt;0f(n)=O(nlogb​a−ϵ),ϵ&gt;0，那么T(n)=Θ(nlog⁡ba)T(n)=\\Theta(n^{\\log_ba})T(n)=Θ(nlogb​a) 若f(n)=Θ(nlog⁡ba)f(n)=\\Theta(n^{\\log_ba})f(n)=Θ(nlogb​a)，那么T(n)=Θ(nlog⁡balog⁡n)T(n)=\\Theta(n^{\\log_ba}\\log n)T(n)=Θ(nlogb​alogn) 若f(n)=Ω(nlog⁡ba+ϵ,ϵ&gt;0)f(n)=\\Omega(n^{\\log_ba+\\epsilon},\\epsilon&gt;0)f(n)=Ω(nlogb​a+ϵ,ϵ&gt;0)，且对于某个常数c&lt;1c&lt;1c&lt;1和充分大的nnn有af(n/b)≤cf(n)af(n/b)\\le cf(n)af(n/b)≤cf(n)，那么T(n)=Θ(f(n))T(n)=\\Theta(f(n))T(n)=Θ(f(n)) 主定理的应用 求解递推方程 求解递推方程T(n)=9T(n/3)+nT(n)=9T(n/3)+nT(n)=9T(n/3)+n 解 递推方程中的 a=9,b=3,f(n=n)a=9,\\quad b=3,\\quad f(n=n)a=9,b=3,f(n=n) nlog⁡39=n2,f(n)=O(nlog39−1)n^{\\log_39}=n^2,\\quad f(n)=O(n^{log_39-1})nlog3​9=n2,f(n)=O(nlog3​9−1) 相当于主定理case1，其中ϵ=1\\epsilon =1ϵ=1 根据定理得到 T(n)=Θ(n2)T(n)=\\Theta(n^2)T(n)=Θ(n2) 求解递推方程 T(n)=T(2n/3)+1T(n)=T(2n/3)+1T(n)=T(2n/3)+1 解 上述递推方程中 a=1,b=3/2,f(n)=1,nlog⁡3/21=n0=1a=1, b=3/2,f(n)=1,n^{\\log_{3/2}1}=n^0=1a=1,b=3/2,f(n)=1,nlog3/2​1=n0=1 相当于主定理的Case2， 根据定理得到T(n)=Θ(log⁡n)T(n)=\\Theta(\\log n)T(n)=Θ(logn) 求解递推方程 T(n)=3T(n/4)+nlog⁡nT(n)=3T(n/4)+n\\log nT(n)=3T(n/4)+nlogn 解 上述递推方程中的 a=3,b=4,f(n)=nlog⁡na=3,b=4,f(n)=n\\log na=3,b=4,f(n)=nlogn nlog⁡n=Ω(nlog⁡43+ϵ)=Ω(n0.793+ϵ)n\\log n=\\Omega(n^{\\log_43+\\epsilon})=\\Omega(n^{0.793+\\epsilon})nlogn=Ω(nlog4​3+ϵ)=Ω(n0.793+ϵ) 取ϵ=0.2\\epsilon=0.2ϵ=0.2即可。 条件验证： 要使af(n/b)≤cf(n)af(n/b)\\le cf(n)af(n/b)≤cf(n)成立，代入f(n)=nlog⁡nf(n)=n\\log nf(n)=nlogn，得到 3(n/4)log⁡(n/4)≤cnlog⁡n3(n/4)\\log(n/4)\\le cn\\log n3(n/4)log(n/4)≤cnlogn 只要c≥3/4c\\ge 3/4c≥3/4，上述不等式可以对所有充分大的nnn成立。相当于Case3。 因此有 T(n)=Θ(f(n))=Θ(nlog⁡n)T(n)=\\Theta(f(n))=\\Theta(n\\log n)T(n)=Θ(f(n))=Θ(nlogn) 递归算法分析： 二分搜索 W(n)=W(n/2)+1,W(1)=1a=1,b=2,nlog⁡21=1,f(n)=1W(n)=W(n/2)+1,W(1)=1\\quad a=1,b=2,n^{\\log_21}=1, f(n)=1W(n)=W(n/2)+1,W(1)=1a=1,b=2,nlog2​1=1,f(n)=1， 属于Case2，W(n)=Θ(log⁡n)W(n)=\\Theta(\\log n)W(n)=Θ(logn) 二分归并排序 W(n)=2W(n/2)+n−1,W(1)=0,a=2,b=2,nlog⁡22=n,f(n)=n−1W(n)=2W(n/2)+n-1, W(1)=0, \\quad a=2,b=2,n^{\\log_22}=n,f(n)=n-1W(n)=2W(n/2)+n−1,W(1)=0,a=2,b=2,nlog2​2=n,f(n)=n−1 属于Case2，W(n)=Θ(nlog⁡n)W(n)=\\Theta(n\\log n)W(n)=Θ(nlogn) 不能使用主定理的例子： 求解 T(n)=2T(n/2)+nlog⁡nT(n)=2T(n/2)+n\\log nT(n)=2T(n/2)+nlogn 解：a=b=2,nlog⁡ba=n,f(n)=nlog⁡na=b=2,n^{\\log_ba}=n,f(n)=n\\log na=b=2,nlogb​a=n,f(n)=nlogn 不存在ϵ&gt;0\\epsilon &gt;0ϵ&gt;0 使右式成立 nlog⁡n=Ω(n1+ϵ)n\\log n = \\Omega(n^{1+\\epsilon})nlogn=Ω(n1+ϵ)， 不存在c&lt;1c&lt;1c&lt;1使af(n/b)≤cf(n)af(n/b)\\le cf(n)af(n/b)≤cf(n)对所有充分大的nnn成立 2(n/2)log⁡(n/2)=n(log⁡n−1)≤cnlog⁡n2(n/2)\\log(n/2)=n(\\log n-1)\\le cn\\log n2(n/2)log(n/2)=n(logn−1)≤cnlogn 递归树求解： T(n)=nlog⁡n+n(log⁡n−1)+n(log⁡n−2)+⋯+n(log⁡n−k+1)=(nlog⁡n)log⁡n−n(1+2+⋯+k−1)=nlog⁡2n−nk(k−1)/2=O(nlog⁡2n)T(n) = n\\log n+ n(\\log n-1)+ n(\\log n-2) \\\\ + \\dots +n(\\log n-k+1) \\\\ = (n\\log n)\\log n - n(1+2+\\dots+k-1) \\\\ = n\\log^2n-nk(k-1)/2 = O(n\\log^2n) T(n)=nlogn+n(logn−1)+n(logn−2)+⋯+n(logn−k+1)=(nlogn)logn−n(1+2+⋯+k−1)=nlog2n−nk(k−1)/2=O(nlog2n) // todo: 继续阅读《具体数学》第一章递推式与第二章和式。","link":"/2020/05/15/math_base_3/"},{"title":"学习流行歌曲曲目","text":"难度逐级升高！ 如何学习演唱流行歌曲 首先找到准备好学唱歌曲的歌词，反复阅读 分析、了解歌词中表达的情感状态，并用对应的情感状态学唱 反复聆听原唱 5 ~ 10 遍 小声跟唱直到鞥能够大体跟得上歌曲节奏和旋律 不清晰的节奏或旋律，多听几遍 对旋律和节奏掌握不好的，对照曲谱跟唱 分析歌手演唱技巧，注意学习应用 旋律和节奏大体掌握后，跟伴奏练唱 跟伴奏练习的时候，如遇到不熟悉的地方反复聆听原唱 伴奏中的人声伴唱一般不是主旋律，是主旋律的和声 使用录歌软件录下来，对比聆听 不要带着耳机演唱（容易跑调，最多戴一只耳机） 男声一级 《一次就好 》杨宗纬 《中国人》刘德华 《爱我别走》张震岳 《心如刀割》张学友 《爱情转移》陈奕迅 《十年》陈奕迅 《爱一个人好难》苏永康 《眼泪》张学友 《风雨无阻》周华健 《把根留住》童安格 《东方之珠》 李克勤 《忘情水》刘德华 《夜半小夜曲》李克勤 《知足》五月天 《稻香》 周杰伦 《水星记》郭顶 《消愁》 毛不易 《别再闹了》毛不易 男声二级 《告白气球》 周杰伦 《一生有你》水木年华 《吻别》 张学友 《蓝莲花》许巍 《彩虹》周杰伦 《暗香》 沙宝亮 《愿得一人心》李行亮 《温柔》 五月天 《说谎》林宥嘉 《刚刚好》薛之谦 《末班车》萧煌奇 《在此》韩磊 《Take me to your heart》 迈克学摇滚 《等你下课》周杰伦 《青花瓷》周杰伦 《天后》 陈势安 男声三级 《我爱你中国》汪峰 《卓玛》 亚东 《你是我的眼》萧煌奇 《过火》张信哲 《单身情歌》林志炫 《精忠报国》屠洪刚 《悟空》戴荃 《同桌的你》老狼 《他说》林俊杰 《我们不一样》大壮 《父亲的草原母亲的河》 布仁巴雅尔 《You raise me up》 Westlife","link":"/2020/09/08/music/"},{"title":"pip 安装包指定头文件和静态库目录","text":"开发中遇到的问题 pip 指定include 和lib 目录 在指定目录时需要添加标识 build_ext，例如： sudo pip install --global-option=build_ext --global-option=&quot;-I/usr/local/include/&quot; --global-option=&quot;-L/usr/local/lib&quot; &lt;you package name&gt; 其中-L 指定 lib 文件， 123456789101112131415161718192021222324Options for 'build_ext' command: --build-lib (-b) directory for compiled extension modules --build-temp (-t) directory for temporary files (build by-products) --plat-name (-p) platform name to cross-compile for, if supported (default: linux-x86_64) --inplace (-i) ignore build-lib and put compiled extensions into the source directory alongside your pure Python modules --include-dirs (-I) list of directories to search for header files (separated by ':') --define (-D) C preprocessor macros to define --undef (-U) C preprocessor macros to undefine --libraries (-l) external C libraries to link with --library-dirs (-L) directories to search for external C libraries (separated by ':') --rpath (-R) directories to search for shared C libraries at runtime --link-objects (-O) extra explicit link objects to include in the link --debug (-g) compile/link with debugging information --force (-f) forcibly build everything (ignore file timestamps) --compiler (-c) specify the compiler type --swig-cpp make SWIG create C++ files (default is C) --swig-opts list of SWIG command line options --swig path to the SWIG executable --user add user include, library and rpath --help-compiler list available compilers https://stackoverflow.com/questions/18783390/python-pip-specify-a-library-directory-and-an-include-directory 基于Pycharm远程调试 https://blog.csdn.net/zhaihaifei/article/details/53691873 https://www.xncoding.com/2016/05/26/python/pycharm-remote.html ​","link":"/2018/04/24/pip/"},{"title":"pip源","text":"Pypi 即Python Package Index，是Python官方管理第三方软件库，目前共有96202个包。Python的软件管理工具包括pip等都是用PyPI作为默认软件源和以来。 Pypi的默认镜像地址是pypi.python.org 镜像地址 Mirror Location # of packages last update pypi.python.org San Francisco, California US 96201 2017-01-08 09:48:24 pypi.douban.com Beijing, Beijing CN 97126 2017-01-08 07:00:14 pypi.fcio.net Oberhausen, Nordrhein-Westfalen DE 97735 2017-01-08 09:45:01 pypi.tuna.tsinghua.edu.cn Beijing, Beijing CN Unavailable mirror.picosecond.org/pypi Fremont, California US Unavailable mirrors.aliyun.com/pypi Hangzhou, Zhejiang CN 97513 2017-01-07 19:01:37 pypi.pubyun.com Changzhou, Jiangsu CN 95514 2017-01-08 09:30:03 mirrors-uk.go-parts.com/python Reston, Virginia US Unavailable mirrors-ru.go-parts.com/python Reston, Virginia US Unavailable mirrors-au.go-parts.com/python Reston, Virginia US Unavailable pypi.mirrors.ustc.edu.cn Hefei, Anhui CN 76240 2017-01-08 04:48:06 2017-01-08 18:09:34 更新 数据来源：https://www.pypi-mirrors.org/ 使用方法 简单使用 pip install -i https://&lt;mirror&gt;/simple &lt;package&gt; or pip install -i http://&lt;mirror&gt;/simple &lt;package&gt; 全局设置 Linux 添加~/.pip/pip.conf文件，内容如下： 12345[global]index-url = https://&lt;mirror&gt;/simple[install]trusted-host=&lt;mirror&gt; Windows 在C:\\Users\\&lt;YourPCName&gt;下建立.pip文件夹，并添加pip.conf文件。 文件内容： 12345[global]index-url = https://&lt;mirror&gt;/simple[install]trusted-host=&lt;mirror&gt; http https任选 easy_install和pip使用方法类似。 参考 https://www.pypi-mirrors.org/ http://mirrors.aliyun.com/help/pypi https://en.wikipedia.org/wiki/Python_Package_Index https://pypi.python.org/pypi","link":"/2017/01/08/pip_pypi/"},{"title":"openldap搭建与使用","text":"Openldap的docker-compose.yml文件： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253version: '2'services: openldap: image: osixia/openldap:1.5.0 container_name: openldap environment: LDAP_LOG_LEVEL: &quot;256&quot; LDAP_ORGANISATION: &quot;Example&quot; LDAP_DOMAIN: &quot;example.com&quot; LDAP_BASE_DN: &quot;&quot; LDAP_ADMIN_PASSWORD: &quot;&quot; LDAP_CONFIG_PASSWORD: &quot;&quot; LDAP_READONLY_USER: &quot;false&quot; LDAP_READONLY_USER_USERNAME: &quot;readonly&quot; LDAP_READONLY_USER_PASSWORD: &quot;readonly&quot; LDAP_RFC2307BIS_SCHEMA: &quot;false&quot; LDAP_BACKEND: &quot;mdb&quot; LDAP_TLS: &quot;false&quot; # LDAP_TLS_CRT_FILENAME: &quot;ldap.crt&quot; # LDAP_TLS_KEY_FILENAME: &quot;ldap.key&quot; # LDAP_TLS_CA_CRT_FILENAME: &quot;ca.crt&quot; # LDAP_TLS_ENFORCE: &quot;false&quot; # LDAP_TLS_CIPHER_SUITE: &quot;SECURE256:-VERS-SSL3.0&quot; # LDAP_TLS_PROTOCOL_MIN: &quot;3.1&quot; # LDAP_TLS_VERIFY_CLIENT: &quot;demand&quot; LDAP_REPLICATION: &quot;false&quot; # LDAP_REPLICATION_CONFIG_SYNCPROV: &quot;binddn=&quot;cn=admin,cn=config&quot; bindmethod=simple credentials=$LDAP_CONFIG_PASSWORD searchbase=&quot;cn=config&quot; type=refreshAndPersist retry=&quot;60 +&quot; timeout=1 starttls=critical&quot; # LDAP_REPLICATION_DB_SYNCPROV: &quot;binddn=&quot;cn=admin,$LDAP_BASE_DN&quot; bindmethod=simple credentials=$LDAP_ADMIN_PASSWORD searchbase=&quot;$LDAP_BASE_DN&quot; type=refreshAndPersist interval=00:00:00:10 retry=&quot;60 +&quot; timeout=1 starttls=critical&quot; # docker-compose.ymlLDAP_REPLICATION_HOSTS: &quot;#PYTHON2BASH:['ldap://ldap.example.org','ldap://ldap2.example.org']&quot; KEEP_EXISTING_CONFIG: &quot;false&quot; LDAP_REMOVE_CONFIG_AFTER_SETUP: &quot;true&quot; LDAP_SSL_HELPER_PREFIX: &quot;ldap&quot; tty: true stdin_open: true volumes: - /var/lib/ldap - /etc/ldap/slapd.d - /container/service/slapd/assets/certs/ ports: - &quot;389:389&quot; - &quot;636:636&quot; domainname: &quot;&quot; # important: same as hostname hostname: &quot;&quot; phpldapadmin: image: osixia/phpldapadmin:latest container_name: phpldapadmin environment: PHPLDAPADMIN_LDAP_HOSTS: &quot;openldap&quot; PHPLDAPADMIN_HTTPS: &quot;false&quot; ports: - &quot;8080:80&quot; depends_on: - openldap 设置LDAP_DOMAIN、LDAP_ADMIN_PASSWORD、domainname和hostname等，就可以启动服务。 访问phpldapadmin，创建用户步骤。","link":"/2021/09/11/openldap_1/"},{"title":"Social Computing 3 —— 小世界实验及其惊奇","text":"小世界问题 The Small-World Program S. Milgram (1967) 实验 现象：俗语 “My it’s a small world.” 问题：两个互不相识得人，如果想认识，中间需要经过几个人 意义： a certain mathematical structure in society 假设 由于每个人都有熟人，熟人之间没有芥蒂，可以交往。故，不曾有连接的两个人之间，如果要建立连接，中间人的数量应该不多。 每个人的确都有熟人，不过，不同类型或阶层熟人之间，不会有交往。故，不曾有连接的两个人之间，不可能建立连接 设计 选择一个随机起点，观察需要经过多少个中间人，能够到达目标点 规则 参与这只能将信件转发给能够直呼其名的熟人，并请他继续转发；如果一个参与者不认识目标收信人，则他不能直接将信寄给他； 参与者需力争让信件尽早达到目的地 第一次：从Kansas的Wichita到哈佛大学神学院某学生的妻子 第二次：从Nebraska的Omaha到Boston的Shanron的股票经纪人Jeffrey Travers 结果 平均中间人数：5 小世界现象 小世界问题 在Milgram的研究之前，人们感觉世界很小，却没有证据 MIT的师生试图证明这一点，不过没有结果 来自Harvard的Milgram用信件进行传递，得到了一个平均数 小世界现象 —— Milgram的研究证明 世界是小的（六度分隔）；社会网络中包含丰富的短路径 “自动寻找”短路径；“有意识的转发”能“自动地“找到这些短路径 启发 为什么社会网络具有这样的性质？它们源于社会网络的哪些基本原理？ 能否依据社会网络的某些原理，构建出反映这种性质的网络模型？ 总结 一项试图证明“世界是小的”简单研究，提示了或许在人际关系之间，的确存在着某种数学结构 小世界现象的普遍性 后续研究 不少重复研究，包括Milgram（1970）自己 扩展 运用书信所做的研究具有重复性，电子邮件呢？ Dodds, Muhamad and Watts (2003) 60,000个电子邮件用户 通过给熟人转发电子邮件的方式，将邮件送达13个国家的18位收件人 发现 通过认识的人，不一定有多熟悉 中间路径：5-7步 网页之间的“社交” 全球互联网超过几百亿的网页，比人口总数多 问题 —— 网页之间，又怎样的关系，也有“小世界”现象吗？ Albert, Jeong, Barabási(1999); Barabási(2013) ——没有关系的两个网页之间的直径为18.59次点击 总结 通过熟人送文件（书信）在不断地检验小世界现象的存在 即使加上了“种族”的因素，小世界现象依然存在 在电子邮件时代，通过熟人转发电子邮件，依然有小世界 即使在网页之间的“社交”，也有短路径 关于小世界的 Watts-Strogatz 模型 人类社会的小世界现象 社会网络中两节点间包含丰富的短路径 —— 任意两节点间存在短路径的概率很高 短视搜索能够有效地找到这些短路径 —— 短视搜索：在达到目标节点过程中，每一步只能看到邻居节点 对于“十分稀疏”的社会网络来说，这并不是必然 从现象到问题 问题 为什么社会网络具有这样的性质？它们源于社会网络的那些性质？ 可以证明，完全随机的网络没有这样的性质 换句话说，能否依据社会网络的某些基本原理来证明这种性质的必然性呢？ 形成社会网络的两种力量 同质性 共同朋友，邻里关系，同学，同事，共同兴趣 对应社会网络中大量的“三角形”（圈子） 弱联系 偶然的原因，认识的“远程”朋友 对其所在的圈子并不一定熟悉 能否找到一种形式化网络，既能够体现这两种力量的作用，也便于我们分析其中是否具有小世界现象？ Watts-Strogatz 模型 定义一种图（网络），体现上述因素 有许多“三角形”和少数随机的“远程边” 每两点之间有一个“网格距离” 大量节点拍不成均匀的网格状 连接近邻：确定性，连接远程：随机性 模型中节点间有两个距离的概念：网格距离和网络距离 体现了同质连接和弱关系连接的概念，于是可以看成是现实社会网络的一个合理近似 可以证明：在这样的网络中，任意两节点之间存在短路径的概率很高 也可以证明，Watts-Strogatz模型不能很好滴体现第二个要求 短视搜索路径太长，尽管短路径存在 总结 对于重要的社会现象，如果可以使用一个数学模型来解释，尽管这个模型概括不了现象的所有细节，也是值得追求的 Watts-Strogatz模型，抽象地表达了社会网络成因的基本特征，从理论上说明了小世界现象（一个方面）的必然性 关于小世界的Watts-Strogatz-Kleinberg 模型 Watts-Strogatz模型的意义与局限性 证明了模型网络中任意两个节点之间存在短路径的概率很高，即“小世界” 但不能解释Milgram等人实验反映出的小世界现象的另一个层面：在短视搜索情况下能找到短路径 在模型上执行短视搜索，常常导致较长路径 短视搜索（分散搜索） 有目标；每一步只有局部知识；与目标进行对比 相对于我们已经熟悉的“广度优先索索”（无目标），这是一种有目标的基于局部信息的搜索，具有如下特点： 每个节点都有一个特征，任何两个节点间的特征可以谈差别（距离） → 不同于图论中定义的距离 每个节点都知道目标节点的特征，也知道自己和自己邻居节点的特征 搜索过程中可以看做是信息传递的过程，节点将信息传递给离目标节点距离较近（差别较小）的邻居节点 示例 节点：0, 1, …, 9, A, …, F 特征距离（差别）：由环上相对位置定义，例如节点0和A的距离为6 从0开始，以A为目标的短视搜索：0-C-B-A 而不是 0-F-A 短视搜索没走“最短路径”！ 一种一般的认识论方法 经常，在事物的宏观格局中存在某种性质，但若缺乏宏观视野，仅凭基于微观视野的追求，不一定能够发现那种特质 但如果事物的结构存在某种特征，使我们能够证明，基于微观视野的追求，就能揭示宏观性质，则是十分美妙的事情。 通过局部，了解全局；通过微观，理解宏观 在小世界问题上我们面对： 在人类社会网络上的大量实验结果表明：短视搜索是有效的，这说明现实社会网络结构支持这种做法 在WS社会网络模型上的理论分析表明，短视搜索效果不好，这说明该模型没能抓住现实网络的某个重要特点 因此，我们需要一种社会网络模型 既反映节点对之间短路径的存在性，也支持这种信件转发方式下短路径的可实现性 网络中需要什么样的结构特征来体现这样的要求呢？ 两个节点无论相距多远，都要有机会很快接近 两个节点的距离越近，存在直接连接的机会越大 Watts-Strogatz-Kleinberg模型 在WS模型基础上，让两个节点之间存在随机边的概率与它们网格距离的某个幂次（q）成反比 q值较小，随机边倾向于较远；q值较大，随机边倾向于较近 Watts-Strogatz模型对应于 q=0q = 0q=0 的情况 改模型的最佳工作参数（q） 理论结果：当 q=2q=2q=2 时 ，分散搜索达到最佳效果 仿真实验：由几亿个节点组成的网络中，考察不同的 q 值在分散搜索中的效果 总结 发现WS模型不能反映现实社会网络的一个重要特征，促成了WSK模型 WSK模型通过适当控制WS模型中的随机性，与试验结果更加吻合 改模型出现了一个优化参数（q），当取特定值时效果最好，这个参数在现实社会网络中如何体现的呢？ WSK模型中优化参数的大数据验证 Milgram的实验表明，现实社会网络中，分散搜索的路径很短。于是很值得好奇：难道人们成为朋友的概率真的岁空间距离递减，并且递减强度幂次 q 真的等于 2 吗？ 利用在线社会网络进行验证 真实大规模在线社会网络是否体现了这个（WSK）网络模型的优化性质？ 两人成为朋友的概率与其空间距离的平方成反比 如果是，则说明随即形成的社会网络可能具有某种本质参数！ 但，在线社会网络的节点如何谈空间距离？ 来自LiveJournal的实验数据 50万用户，含邮政编码 分布不均匀，不符合模型的假设，需要做一些适配性工作 社会网络中结合地理距离的节点相对排名 可以看成是节点在地理距离上均匀分布时区域范围概念的一种推广，“排名”与“距离”有对应关系 这就是我们能一般性地处理节点在地理上分布不均匀的问题 要验证的是： 在均匀地理分布情形，一个节点在任意距离上的朋友数量在同等距离节点总数中的占比随距离平方递减 1d2\\frac{1}{d^2}d21​ 此时等价于看 一个节点在任一排名上的朋友（即有连接）数量在同等排名节点总数的占比随排名递减 1r\\frac{1}{r}r1​ 这意味着，大量微观社交关系的建立总体上呈现出一种最优化特征，或者说大量人群的随机社会活动相当于一台计算机，完成了一种优化计算（实现了最优参数）—— 这可以看成是社会计算的一个实例，也是体现社会系统中微观与宏观关系的实例。 总结 前面的内容，讨论了人们围绕小世界现象所展开的一系列研究思路 看到了“实验 → 理论 → 完善 → 实验”研究范式的体现 （小世界）现象 → 抽象模型（解释现象） → 完善模型 （更好地解释） → 数据验证（得到对现实更深入的认识） 也看到了大数据分析在推进这类研究中的作用 核心—外围结构：一种社会网络观 核心-边缘结构模型 Borgatti 和 Everett (1999) 观察到，在社会网络中 地位较高的人，被连接在一个密集连接的核心 地位较低的人，都分散在网络外围 核心 - 边缘结构 不仅是在理论上 现实社会中，普遍存在 理论与现实 理论上 处在网络结构中的节点，不同的节点如果有相同的聚集系数，其被连接到的概率是一样的 现实中 Milgram(1967)的第一次试验就已经暗示：寻找地位较低得人（神学院学生的妻子）会更加困难 人们观察到，“媒体寻人”较之个体寻人有更高的成功率 回想“结构洞”，处于结构洞位置上的人，其被找到的概率，远远大于一般节点上的人 社会意义 如果处于更高的社会地位，且在结构洞的位置上呢？故 网络结构本身是重要的，尤其在可计算性上 同样重要的是，网络结构的社会属性 具有相同网络结构，却有着不同的社会属性的网络，在显示社会中，具有布偶听的“可连通性”（社会含义） 社会地位较高的人，具有更多的“关系资源”，更好的连通性 总结 网络结构会因为节点上的人的社会属性不同，而有不同 社会地位较高的人，倾向于有更多的、更广的关系（连接） 即，社会属性是影响网络结构及其连通性的重要因素","link":"/2020/03/06/social_computing_3/"},{"title":"Social computing 1 —— 网络与市场中的计算思维","text":"1. 网络与图论 图是网络结构信息的抽象，表达的是网络中各种事物之间的关系。 一个简单图是集合 X=(V,E)X = (V, E)X=(V,E)，其中 VVV 是定点， EEE 是边。一条边连接的两个顶点称为它的两端点。其实我们可以把一条边看作 VVV 的子集，其中有两个顶点。一个简单图就是一个无向图，它不会有圈或者重边。若 u≠vu \\not = vu​=v 是两个顶点， u,v{u, v}u,v 是一条边，那么两顶点相邻，记为 u,v{u, v}u,v。 同一个图，可能有多种不同的画法。也就是说，同一个图可能呈现出不同的图像形式。 同构图 在图论中，假设 G=(V,E)G=(V, E)G=(V,E) 和 G1=(V1,E1)G1 = (V1, E1)G1=(V1,E1)，如果存在一个双射 m:V→V1m: V → V1m:V→V1 ，使得对所有的 x,y∈Vx, y ∈ Vx,y∈V 均有 xy∈Exy ∈ Exy∈E 等价于 m(x)m(y)∈E1m(x)m(y)∈ E1m(x)m(y)∈E1，则称 GGG 和 G1G1G1 是同构的，这样的一个映射 mmm 称之为同构，如果 G=G1G = G1G=G1，则称他们为一个自同构。 路径（walk） 一个长度为 kkk 的路径是一个费控的顶点和边的交错序列 v0e0v1e1...ek−1vkv_0e_0v_1e_1...e_{k-1}v_kv0​e0​v1​e1​...ek−1​vk​ ，使得对于所有 i&lt;ki &lt; ki&lt;k 均有 ei=vivi+1e_i = v_iv_{i+1}ei​=vi​vi+1​ 。特别的，当 v0=vkv_0 = v_kv0​=vk​ 时，称这个路径为闭的（close）；当路径中的顶点互不相同，得到 GGG 的一条路。 连通图 在无向图GGG中，若从顶点viv_ivi​到顶点vjv_jvj​有路径（当然从vjv_jvj​到viv_ivi​也一定有路径），则称viv_ivi​和vjv_jvj​是连通的。 如果G是有向图，那么连接viv_ivi​和vjv_jvj​的路径中所有的边都必须同向。如果图中任意两点都是连通的，那么图被称作连通图。 连通分量 无向图G的一个极大连通子图称为G的一个连通分量（或连通分支）。连通图只有一个连通分量，即其自身；非连通的无向图有多个连通分量。 有向图G= (V,E)中，若对于V中任意两个不同的顶点 x和y，都存在从x到y以及从y到x的路径，则称G是强连通图（Strongly Connected Graph）。相应地有强连通分量的概念。强连通图只有一个强连通分量，即是其自身；非强连通的有向图有多个强连通分量。 二部图 二分图的顶点可以分成两个互斥的独立集U和 V的图，使得所有边都是连结一个 U 中的点和一个 V 中的点。顶点集 U、V 被称为是图的两个部分。等价的，二分图可以被定义成图中所有的环都有偶数个顶点。 许多社会现象或状态的结构，都呈现出二部图的形式 是否有长度为奇数的圈，是判断一个图是否是二部图的充分必要条件。 长度优先搜索（遍历），是考察一个图是否存在长度为奇数的圈的有效方法。 从任何节点开始，在广度优先搜索（遍历）过程中，一旦发现同一层节点之间有边，则图中一定存在长度为奇数的圈，则该图不是二部图。 三元闭包 不仅考虑一个时刻（“快照”）上的状态 还要研究随时间发生的变化（内部原因 vs 外部原因） 社会网络眼花的基本结构性原因（Anatole Rapoport, 1953） 三元闭包(triadic closure) 在一个社交圈内，若两个人有一个共同的朋友，则这两人在未来成为朋友的可能性会提高。 机会（opportunity） 信任（trust） 动机（incentive） 林南 一个特定的网络可以自然地形成 也可以有对一个特定的共同关注的焦点或关注一种资源利益的社会性建构 聚集系数 刻画某个节点的重要性 结构洞 聚集系数，就是在三元闭包中，对一个节点属性的测度，表示“凝聚力”的大小 节点A的聚集系数 = 与A相邻的任意两个朋友之间也是朋友的概率 = 与A相邻的朋友对的个数/总数 在上图a中，节点A的聚集系数1/61/61/6 （因为与A相邻的6个节点对B-C、B-D、B-E、C-D、C-E 和 D-E 中，仅有一个边 C-D ）。 三元闭包的大数据验证 电子邮件网络~~社会网络 可能性：共同朋友 -&gt; 成为朋友的概率 数据验证要求： 网络规模足够大 数据跨度时间足够长 关键： 将社会科学原理的定性描述，转化为便于定量分析的表述，形成数据指标（与共同朋友书对应的概率）。 选择合适的数据，以及从原始数据中提炼出指标数据的方法。 强关系与弱关系 Granovetter(1973)提出了刻画边的属性的一种测度：强 – 弱。 被动参与三元闭包原理实际上暗含了一个随时间推移的可能。 有的人会被动加入某些网络 Huberman et al. (2009) 对Twitter的研究表明，即使所有朋友的总数超过500，实际联系的总数也在10-20人之间；被动联系人的数量也不超过50人。 嵌入性（Embedness） Karl Polanyi (1944) 《大转变》 行动嵌入制度。 Granovetter (1985) 在与经济学家的论战中，提出了经济行为与社会结构之间的关系问题，拓展了嵌入性概念，指出，经济行为是嵌入在社会结构之中的，是社会行为的一种。 网络分析，恰恰是Granovetter从他老师Harrison White (1967) 那里得到的衣钵。 嵌入性：边的属性 嵌入性 = 一条边两端共同的邻里数 看 A - B 边，有共同的邻里 E 和 F，则 A-B 边的嵌入性为 2 嵌入性越强的边，相互之间的信任就越强；嵌入性越强的边，社会资源也就越多 嵌入性与社会资本是两个不同分析框架的概念。 结构洞（结构位置整体） 一个节点，移除该节点就会使网络变成多个连通分量的节点 节点B，移除它，就会变成3个连通分量 结构洞意义 了解三方面的信息 处于捷径的一端，对其 “长处” 有放大影响 对于其相邻的节点甚至具有“权力” 冗余（凝聚力冗余和结构等位冗余）越小的结构洞，社会资本就越多（Burt的结构洞） 强三元闭包 桥(Bridge)：如果一个图中，已知A和B相连，若去掉连接A和B的边导致A和B分属不同的连通分量，则该边称为桥。桥为A、B间唯一路径。 捷径(Local bridge)：若边A-B的端点A和B没有共同朋友，则称边A-B为捷径；删除A-B边将把A-B距离增加至2以上。 强联系：对应朋友(Friend)关系。弱联系：对应熟人(Acquaintance)关系；通过捷径找到工作；亲密团体内信息多数自己已经知道。 两人关系的强度与是否有共同朋友直接相关，捷径意味着没有共同朋友，强度为弱，共同朋友数越多，关系的强度越高。 强三元闭包原理：如果 A 和 B、C之间的关系分别为强关系；则 B 和 C 之间形成边的可能性应该很高。 若A有两个强关系邻居B和C，但B和C之间没有任何关系（s或w），则称节点A违背了强三元闭包远离 如果节点A没有违背强三元闭包原理，则称节点A符合强三元闭包原理 断言：若节点A符合强三元闭包，且至少有两个强关系邻居，则与A相连的任何捷径必定意味着是弱关系。 强三元闭包原理的精神： 没有共同朋友 -&gt; 捷径 -&gt; 弱关系 定量化表述：共同朋友越多，关系强度越 也就是社交网络中，我们预计看到人们关系的强度与共同朋友数正相关","link":"/2020/03/02/social_computing_1/"},{"title":"python tricks","text":"1. Python set操作 difference 和 symmetric_difference 的区别： 如果 a 和 b 是集合类型，a-b是指所有在a但不在b中的元素。 123456&gt;&gt;&gt; a = {1, 2, 3}&gt;&gt;&gt; b = {1, 4, 5}&gt;&gt;&gt; a - b{2, 3}&gt;&gt;&gt; b - a{4, 5} a.symmetric_difference(b) 或 a &amp; b 的结果是放在一个集合中，是 a-b 和 b-a的并集。 1234&gt;&gt;&gt; a.symmetric_difference(b){2, 3, 4, 5}&gt;&gt;&gt; (a - b).union(b - a){2, 3, 4, 5} 判断列表之间的差异： 12345678list1 = ['Scott', 'Eric', 'Kelly', 'Emma', 'Smith']list2 = ['Scott', 'Eric', 'Kelly']​list3 = list(set(list1) ^ set(list2))print(list3)​# output['Emma', 'Smith']","link":"/2021/01/30/python-tricks/"},{"title":"Social computing 2 —— 社会选择与社会影响","text":"同质性 同质性是古老议题： 柏拉图 相似性带来友谊 亚里士多德 人们喜欢与自己相似的人 俗语 夫妻相 Lazarsfeld 和 Merton（在 Simmel的基础上） Berger, et al. 1954. Freedom adn Control in Modern Society. 社会控制、群体与个体 国家与社会 Lazarsfeld and Merton （1954） 区分了 身份同质性：相同身份的人彼此相互联系 → 社会性机制 价值同质性：相同价值观的人会彼此相互联系 → 个体性机制 区分 同质性 Homophily 与同构性 Homogeny Miller McPherson, et al （2001） 用了 birds of a feather 作为篇名，提出同质性的机制 生态过程：场所的影响，同一个机构、社区，共同参加活动 关系过程：交叉关系的影响，一个人在不同的场所 网络过程：随时间的变化而变化的动态 James Moody (2001) 高中生之间的关系：年级、种族 社会交往 每个人的特质（2种） 固有特质：性别、种族、母语等，自然属性 可变特质：居住区、专长、偏好等，建构属性 同质性是社会网络结构形成的基本外部原因 血缘、地缘、业缘、趣缘等 社会学的一个基本问题 是因为“羽毛相似”才交往（selection）呢 还是因为“同林”后才变得“羽毛相似”（social incluence）呢 社交网络中同质性的测量 社交网络中的同质性现象 朋友~~相似 ”相似“的含义可因考虑的问题不同而不同 → 固定特征、可变特征 如何定量评估一个社交网络中同质性现象的程度？ 给定社交网（只考虑两种不同的特征：红，白） 我们能够得到的信息 节点数（n），边数（e） 不同颜色节点的占比：p，q=1-p 两端节点相同的边数（s） 计算： 节点数 n = 9 边数 e = 18 红色节点数占比 p = 13\\frac{1}{3}31​ 白色节点数占比 q = 23\\frac{2}{3}32​ 两端节点相同的边数 s = 13 se&gt;p2+q2\\frac{s}{e} &gt; p^2+q^2es​&gt;p2+q2 ? → se\\frac{s}{e}es​ = 1318\\frac{13}{18}1813​ p2+q2=132+232=1018p^2+q^2 = {\\frac{1}{3}}^2 + {\\frac{2}{3}}^2 = \\frac{10}{18}p2+q2=31​2+32​2=1810​ ∵ se&gt;p2+q2\\frac{s}{e} &gt; p^2+q^2es​&gt;p2+q2 ∴ 同质性现象在这个社交网络中有所表现 认识：两边节点的边越多（占比越高），同质性越明显se\\frac{s}{e}es​ 用“随机情况”作为基准：给定不同颜色的节点占比（红p和白q），随机情况下，一个节点是红色节点的概率为p，白色的概率就是q，那么任何一条边的两节点颜色相同的概率就是p2+q2p^2+q^2p2+q2，也就是两端节点相同边的占比。 物以类聚人以群分 经验观察 俗语 物以类聚，人以群分 亚里士多德 人们喜欢与自己相似的人 理论 Lazarsfeld 与 Merton (1954) 区分了选择机制 身份同质性：相同身份的人彼此相互联系 价值同质性：相同价值观得人会彼此相互联系 即人们通过自然属性或社会属性的相似性、或价值观的相似性进行选择 理解 为什么身份与价值观会影响社会网络同质性的动态 作为能动者的行动者（Giddens,1984; 1991），个体具有“加入”的主动性和自主性 （自然行为） Examples 你的朋友带来了一位对你而言是陌生人但却是你朋友的朋友来见你 同样，还具有退出的主动性和自主性 Examples 教会吸收新会员，学生社团吸收新成员 网络的同质性，实际上是一个动态过程，即使是主动选择的 从属网络 社会交往 社会网络的建构，无论是加入，还是退出，都可能是一个主动的过程 尽管被动参与（参见嵌入性）也是一种机制 形成网络同质性的机制之一，是个体（节点）的主动选择 近朱者赤近墨者黑 经验观察 传统故事 孟母三迁 俗语 近朱者赤，近墨者黑 婚姻 先结婚，后恋爱 理论 Miller McPherson, et al (2001) 同质性的机制 生态过程：场所的影响，同一个机构、社区，共同参加活动 关系过程：交叉关系的影响，一个人在不同的场所 网络过程：随时间的变化而变化的动态 强调生态性的重要性 由场所带来的影响，实际是同质性形成的另一个重要机制 从属关系与社会关系的相互总用（随时间发生的变化） 社会归属网：描述从属关系与社会关系 在现实社会中，选择与影响似乎很难明确区分，实际是交替甚至同时发生的现象，同质性是两种共同机制的结果 选择 → 社团闭包 影响 → 会员闭包 社会归属网：三类闭包 社团闭包的验证 社团闭包 由于参与一件事情，两个原本没联系的人之间，建立了联系 共同参与的事情越多，建立联系的可能性越高 会员闭包的验证 会员闭包 由于朋友参与某件事情中，原本不在这件事情的另一个人也加入了这件事 参与某件事的朋友越多，其被影响而参与的可能性就越大 社会影响与社会交往 个体的兴趣与能力，或许不限于既有，可能会被诱发 体育特长，自然的、本性的 拓展是可以选择的，更多或是受到影响的 Iphone一族；三星一族 形同同质性网络的机制之一，是个体之间的相互影响 ”朋友~~相似“现象溯源（大数据分析） 朋友间相似的原因？ 当两个关系不过的人在某些特质上相似 相似 → 朋友？ 朋友 → 相似？ 需要数据集 反应随时间变化的大规模社会归属网 大规模：人多，社交聚点多 随时间变化：人与人之间，人和人的社交聚点之间 wikipedia数据集 两人相似性的测量 相似性=两人都编辑过的文章数总共编辑过的文章数相似性 = \\frac{两人都编辑过的文章数}{总共编辑过的文章数}相似性=总共编辑过的文章数两人都编辑过的文章数​ 相似性、选择与社会影响 小结 利用“社会归属网”大数据剖析同质性现象的原因 从问题，到模型（社会归属网），再到数据（Wikipedia），最后到映射（数据与问题要素的关系） 谢林模型及其意义 从一个现象开始 芝加哥，黑人在居住区的比例变化图 同质性动态 现象 越来越多的黑人在某个区域聚集 理解 自然属性相同，选择相同 相互认识，相互影响，进而趋同 谢林模型示意 Schelling (1972, 1978) 隔离的动态模型（1972）：隔离不是个人刻意选择的后果 微观动机与宏观行为（1978，2005） 谢林模型的社会意义 以居住隔离为例，谢林模型模拟了同质性的动态变化。 如果同质性是一个自然现象，则促进或阻止不同社会情景下的同质性，将会对社会发展产生重要影响。","link":"/2020/03/05/social_computing_2/"},{"title":"Social Computing 4 —— 万维网结构、链接分析与网络搜索","text":"一、有向图 有向图是指一个有序(V(D),E(D),Ψ(D))(V(D), E(D), \\Psi(D))(V(D),E(D),Ψ(D))，其中Ψ(D)\\Psi(D)Ψ(D)是关联函数，它使得E(D)E(D)E(D)中的每一个元素（称之为有向边或弧）对应于V(D)V(D)V(D)中的一个有序元素（称为顶点或点）对。 出度与入度 设DDD是一个有向图，DDD中的顶点vvv的入度dD−(v)d_D^-(v)dD−​(v)是指以vvv为头的弧的数目，vvv的出度dD+(v)d_D^+(v)dD+​(v)是指以vvv为尾的弧的数目，vvv的度dD(v)d_D(v)dD​(v)则是出度和入度之和，我们用δ−(D)\\delta^-(D)δ−(D)和Δ−(D)\\Delta^-(D)Δ−(D)和δ+(D)\\delta^+(D)δ+(D)和Δ+(D)\\Delta^+(D)Δ+(D)分别表示DDD中顶点的最小和最大入度、最小和最大出度，并使用δ(D)\\delta(D)δ(D)和Δ(D)\\Delta(D)Δ(D)分别表示DDD中的顶点最小度和最大度，并用v(D)v(D)v(D)，ε(D)\\varepsilon(D)ε(D)来源表示DDD中的顶点数和弧数。 孤立点 VVV中不与EEE中任一条边关联的点成为DDD的孤立点。 简单图 不含平行边的图。 完备图 图中任何两个顶点UUU和uuu之间，恰有两条有向边(u,v)(u, v)(u,v)及(v,u)(v, u)(v,u)，则称该图为有向图DDD的完备图。 基本图 把有向图DDD的每条边出去定向就得到一个相应的无向图GGG，称GGG为DDD的基本图，称DDD为GGG的定向图。 强连通图 给定有向图G=(V,E)G=(V, E)G=(V,E)，并且给定向图GGG中的任意两个节点vvv和uuu，如果节点uuu和vvv相互可达，即至少存在一条路径可以由节点uuu开始，到节点vvv终止，同时存在至少一条路径可以由节点vvv开始，到节点uuu终止，那么就称该有向图GGG是强连通图。 弱连通图 若至少有一对节点不满足单向连通，但去掉边的方向后从无向图的观点看是连通图，则DDD称为弱连通图。 单向连通图 若每对节点至少有一个方向是连通的，则DDD称为单项连通图。 强连通分支 有向图GGG的极大强连通子图称为该有向图的强连通分支。 出度与入度： 如上图中右图，节点B的出度为2，入度为1。 有向路径： 从x到y有一条有向路径，不一定从y到x存在有向路径； 即使从x到y有，从y到x也有，但这两条路径经过的节点可能完全不同。 A → B ; B → D → E → F → A 有向图的强连通性 强连通分量 一个节点子集和它们之间的边，满足： 第一，如果它有两个或者更多的节点，那么其中任意两个节点之间的都存在两个方向上的有向路径； 第二，不被包含在一个更大得且满足第一个要求的节点集合之中。 尽可能大的双向连通节点子集 在一个有向图中，不可能存在一个节点属于两个不同的强连通分量。 总结： 有向图是描述具有方向性关系的工具。 与（无向）图的几个基本概念的对应关系： 节点 —— 节点 边 —— 有向边 路径（圈） —— 有向路径（有向圈） 连通 —— 强连通 连通分量 —— 强连通分量 二、将Web看成是一个有向图 领结：Web信息结构的一种概貌 Andrei Broder等发现万维网包含一个超大强连通分量SCC，加上其他部分，显示出一种形象的结构 链入，链出，卷须（管道），游离 SCC Furthermore, several studies have suggested that the directed graph connecting web pages has a bowtie shape: there are three major categories of web pages that are sometimes referred to as IN, OUT and SCC. A web surfer can pass from any page in IN to any page in SCC, by following hyperlinks. Likewise, a surfer can pass from page in SCC to any page in OUT. Finally, the surfer can surf from any page in SCC to any other page in SCC. However, it is not possible to pass from a page in SCC to any page in IN, or from a page in OUT to a page in SCC (or, consequently, IN). Notably, in several studies IN and OUT are roughly equal in size, whereas SCC is somewhat larger; most web pages fall into one of these three sets. The remaining pages form into tubes that are small sets of pages outside SCC that lead directly from IN to OUT, and tendrils that either lead nowhere from IN, or from nowhere to OUT. Figure 19.4 illustrates this structure of the Web. source： https://nlp.stanford.edu/IR-book/html/htmledition/the-web-graph-1.html 如何按照”领结“思路，获得一个有向图的几个组成部分？ 简化：只关心SCC，IN和OUT三个部分 假设我们知道某个节点一定在SCC中 给定有向图和其中的一个节点，如何得到包含该节点的强连通分量（SCC），以及相对于这个强连通分量的IN部分和OUT部分。 从某一节点上做广度优先搜索，从111节点进行搜索： FS={1,8,13,14,9,3,4,15,5,16,18,10}FS = \\{ 1, 8, 13, 14, 9, 3, 4, 15, 5, 16, 18, 10\\}FS={1,8,13,14,9,3,4,15,5,16,18,10} 然后，在依据反向图进行搜索： BS={1,4,9,14,13,15,8,12,18,3,7,6,11}BS=\\{1, 4, 9, 14, 13, 15, 8, 12, 18, 3, 7, 6, 11\\}BS={1,4,9,14,13,15,8,12,18,3,7,6,11} 所以，SCC=FS∩BS={1,3,4,8,9,13,14,15,18}SCC = FS \\cap BS = \\{1, 3, 4, 8, 9, 13, 14, 15, 18\\}SCC=FS∩BS={1,3,4,8,9,13,14,15,18} IN=BS−SCC={6,7,11,12}IN = BS - SCC = \\{6, 7, 11, 12\\}IN=BS−SCC={6,7,11,12} OUT=FS−SCC={5,10,16}OUT = FS - SCC = \\{5, 10, 16\\}OUT=FS−SCC={5,10,16} 有向图的“领结”表示 总结： 有向图是一种信息组织的有效形式 将Web看成是一个有向图，人们发现它宏观上像一个“领结”，多次数据实验验证了这个结论。（IN, OUT, SCC） 广度优先搜索，视具体得到“领结”的各个组成部分的基本手段。 三、中枢与权威 搜索引擎关心的基本问题 计算机显示屏只能够显示5-6个结果，典型搜索引擎掌握的网页超过60亿 对用户提交的一个查询，如何从这种海量网页集合中将最可能满足用户需求的少数几个结果找出来，展现在计算机显示屏上？ 传统信息检索（IR）技术要点 基于词语之间的相关性（relevance） 传统应用背景 文档集合：图书，规范的文献 查询：主题词，关键词 查询意图：获取与查询词有关的书籍和文章 用户：图书管理人员 ”查询目标包含查询词“ 是一个合理假设 在形成查询词的时候就有这样的意识 有效利用链接关系蕴含的信息，是搜索引擎超越传统信息检索系统、技术进步的重要标志。 Web page之间的链接有两层含义：关系、描述 反复改进原理 （principle of repeated improvement） 网页的“中枢”与“权威”性 万维网中一篇网页的两面属性。 观念： 被很多网页指向：权威性高，认可度高 被指向很多网页：中枢性强 HITS算法：计算网页的权威值（auth）和中枢值（hub） Hyperlink-Induced Topic Search auth(p)auth(p)auth(p) 和 hub(p)hub(p)hub(p) 的计算方法 输入： 一个有向图 初始化：对于每一个节点 p，auth(p)=1,hub(p)=1auth(p) = 1, hub(p) = 1auth(p)=1,hub(p)=1 利用中枢值更新权威值 对于每一个节点 p，让auth(p)auth(p)auth(p)等于指向 p 的所有节点 q 的hub(q)hub(q)hub(q)之和 利用权威值更新中枢值 对于每一个节点 p，让hub(p)hub(p)hub(p)等于 p 指向的所有节点 q 的auth(q)auth(q)auth(q)之和 重复上述步骤若干（k）次 在搜索引擎领域，auth值或hub值高的网页，分别称为“权威网页”和“中枢网页”。一篇网页可以兼具二者。 归一化与极限 数值随迭代次数递增 Auth 和 hub 值的意义在于相对大小 在每一轮结束后作归一化：值/总和值/总和值/总和 归一化结果随迭代次数趋向于一个极限 相继两次迭代的值不变 极限与初始值无关，即存在“均衡” 总结： 在一个由“引用”或者“推荐”关系构成的信息网络中，每个节点都有两种自然作用：“权威”与“枢纽”（中枢） 这样的作用可以用过“HITS算法”得到量化 HITS算法的基本精神是基于信息网络的结构，在两个量之间交叉进行“反复改进” 四、PageRank： 节点重要度的一种测度 基本要领：每一个节点将自己的值均分给出向邻居，每个节点将从入向邻居收到的值加起来。 PageRank算法基本描述： 输入： 一个有nnn个节点的网络（有向图），设所有节点的 pagerank 初始值为 1n\\frac{1}{n}n1​。 选择操作的步骤数kkk。 按照下列规则，同时对每个节点进行操作，做kkk次： 每个节点将自己当前的 pagerank 值通过出向链接均分传递给所指向的节点 若没有出向链接，则认为传递给自己（或者说保留给自己） 每个节点以从入向链接获得的（包括可能自传的）所有值之和更新它的 pagerank 总结： 在一个由“引用”或者“推荐”关系构成的信息网络中，每个节点的重要性可以认为取决于有多少人推荐，以及推荐人的重要性 这种重要性可通过“PageRank算法“得到量化 PageRank算法的基本精神是基于信息网络的结构，让每个节点不断把自己的重要性分给出向邻居，同时用从入向邻居收到的重要性之和来更新自己。 五、同比缩减与等量补偿 PageRank基本算法在某些结构上的“病态” 从上图去掉(G,A)(G, A)(G,A)和(F,A)(F, A)(F,A) 边，添加 (F,G)(F, G)(F,G) 和 G,A{G, A}G,A 两条边，得到： 此时，F 和 G两个节点显得很“自私”：不断吸收其他节点的价值，但不向外分享。 PageRank的同比缩减与统一补偿原则 同比缩减 在每次运行基本PageRank更新规则后，将每一个节点的PageRank值都乘以一个小于1的比例因子s(0&lt;s&lt;1)s (0&lt;s&lt;1)s(0&lt;s&lt;1)，经验值在0.8~0.9之间。 统一补偿 在每一个节点的PageRank值上统一加上1−sn\\frac{1-s}{n}n1−s​。 这样，既维持了∑PR=1\\sum PR = 1∑PR=1的性质，也防止了PR值过度集中到个别节点。 随机游走：PageRank的另一种等价理解 想象一个人从一篇随机选择的网页开始，然后随机选择其中的链接浏览到下一篇网页，并不断如此进行，称为“随机游走”。 考虑任意一篇网页X，问：经过k步随机游走到达X的概率是多少？ 可以证明：到达X的概率等于运行PageRank基本算法k步得到的值。 随机游走概念稍加修改也可以和同比缩减、统一补偿的PageRank等价。 总结： 信息一旦刻画成一种网络，其中的边经常自然地隐含着一种“推荐”或者“引用”关系，人们可以利用这种关系对信息的作用进行评估： 影响力、重要性、权威性、新颖性…… 先进的评估方法不仅考虑局部结构，而且会考虑全局结构带来的影响（节点特征性质在网络中的传播） HITS算法、PageRank算法 当理想遇到现实 —— 重要现实情况的处理 数据范围问题，退化网络结构问题","link":"/2020/03/12/social_computing_4/"},{"title":"Social computing 5 —— 博弈论","text":"博弈论的基本概念 博弈（game） 博弈三要素： 参与人（player，玩家） 策略集（strategy，战略） 回报（payoff，收益、支付） 次序（order） 均衡（equilibrium） 每个参与人都有一个策略集； 策略组：每个参与人出一个策略构成策略组合 对应每个策略组，每个参与人都有一个回报 田忌赛马 参与人：齐威王、田忌 策略集 上中下 上下中 中下上 中上下 下上中 下中下 回报 对于策略组（1，1），田忌（-3） 对于策略组（5，1），田忌（+1） …… 博弈不总是讲输赢 商场走失问题：两友人同逛一个大商场，走散了。已知商场有南北两个门，也知道朋友会在某个门等候，你会去哪个门？ —— 只有协调，才能共赢 收益矩阵（表达博弈的一种直观方式） 博弈论的关切（不同于博弈参与人的关切） 在”理性人“等基本假设下，博弈（作为一个整体）的结果、走向、发展趋势、哪些策略组（合） 会被人们采用。 博弈推理的假定（assumption） 自己的回报是每个参与人关心的唯一因素 参与人都是 “理性人” ，即只要可能，总是要选择有更好回报的策略 每个参与人都对博弈结构完全了解 个体理性与集体理性 个体理性 个人理性是指个人分析问题，决定自己行为取向时所表现的理性。 集体非理性 集体理性是指集体在决定和从事集体行动所表现出来的理性，而集体非理性则相反。 无论是个人理性、集体理性还是集体非理性，他们强调的是在选择和策略过程中表现的一种思维思考活动。 一个博弈的解，是“稳定的策略组”，要求是其中任何参与人不可能通过单方面改变策略而获得更好的回报。 ”稳定的“ → 在博弈推理假设下不可能再变化 不是所有的博弈都有解 这里解的概念，实际上就是博弈均衡的概念。 策略L 策略R 策略U 90,90 86,92 策略D 92,86 88,88 严格占优策略：对一个参与人来说，若存在一个策略，无论另一个参与人选择何种策略，该策略都是严格最佳的选择，则这个策略就被称为是前者的严格占优策略。 按照博弈推理假设，参与人将选择严格占优策略。 严格与不严格的区别 L R U 3，3 4，3 D 2，0 3，4 横向为参与人1，纵向为参与人2 U是参与人1的严格占优策略；R是参与人2的占优策略，但不是严格的 L是U的最佳应对，但不是最严格的；R是D的严格最佳应对 简单博弈的行为推理 如果两个人都有严格占优策略，可以预计他们均会采用严格占优策略。 如果只有一个人有严格占优策略，则这个人会采取严格占优策略，而另一方会采取此策略的最佳应对（一定会有）。 占优策略 → 占优策略 ； 占优策略 → 最佳应对 互为最佳应对策略组 → 纳什均衡 具有多个纳什均衡的博弈 如果两个人均没有严格占优策略呢？ 如何讨论博弈的走向？ A B C A 4,4 0,2 0,2 B 0,0 1,1 0,2 C 0,0 0,2 1,1 三客户博弈的解，横向为公司1，纵向为公司2 策略组（A，A）中的两个策略为最佳应对 纳什均衡：互为最佳应对的策略组。 协调博弈 北门 南门 北门 1，1 0，0 南门 0，0 1，1 横向为你，纵向为你的拍档。 有两个纳什均衡（北门，北门）与（南门，南门） 如何预测协调博弈中参与人的行为？ 引入外部条件 鹰鸽博弈的推理 两个均衡，不能推断出哪个均衡会出现 一般来说，纳什均衡的概念能够有助于缩小预测的范围，但它并不一定能够给出唯一的预测 如果不存在纳什均衡，怎么办？ 零和博弈（zero sum game） → 猜测他人的策略，不让他人预测你的策略 混合策略的引入 引入随机性，考虑参与人将以一定的概率在不同策略间进行选择，一个概率对应一个“策略”（称为混合策略）。此时，选择策略就是选择策略，而博弈矩阵中给出的选项称为寸策略。 一般地，混合策略是一个概率分布，双策略情形等价为一个概率。 通常地，在有两个纯策略H和T的情形，我们说： 你的策略概率是ppp，是指你以概率ppp执行 H； 以概率1−p1-p1−p执行T。 他的策略概率是qqq，是指他以概率qqq执行H；以概率1−q1-q1−q执行T。 针对混合策略的博弈，三要素齐全了吗？ 参与人 √ 策略（概率） √ 回报 ？ 此时的策略是两种（纯）策略上选择的概率，每一组纯策略是对应有固有收益的。因而，从概率意义出发，此时的收益应该体现一种在两种纯策略上的“平均”（期望）。 但是，在研究一个混合策略博弈的时候，我们一般并不关心在每个策略下的具体回报情况，而是关心是否能够达到均衡？在什么混合策略组下达到均衡？哪两个概率是互为最佳应对？ 最佳应对：改变策略后，不会得到更好的回报。 博弈均衡有两种：纯策略均衡、混合策略均衡； 任何博弈都存在均衡： 可能有一个，也可能有多个 可能是某一个，也可能两种都有 社会最优 均衡是博弈的解（走向、结果），参与人都实现个体最优，但不一定是社会最优。 帕累托最优（Pareto Optimality） 帕累托最优是指资源分配的一种理想状态。 假定固有的一群人和可分配的资源，从一种分配状态到另一种状态的变化中，再没有使任何人境况变坏的前提下，使得至少一个人变得更好。 帕累托最优的状态就是不可能再有更多的帕累托改进的余地；换句话说，帕累托改进是达到帕累托最优的路径和方法。帕累托最优是公平与效率的“理想王国”。 一组策略选择是社会福利最大化（或社会最优），若它使参与者的回报之和最大。 社会最优和纳什均衡有可能一致。 从社会应用的意义讲，均衡与社会最优一致的系统是理想系统。 相关概念 纳什均衡（Nash Equilibrium） 在一策略组合中，所有的参与者面临这样的情况：当其他人不改变策略时，他此时的策略师最好的。也就是说，此时如果他改变策略他的回报（payoff）将会降低。 在纳什均衡点上，每一个理性的参与者都不会有单独改变策略的冲动。 纳什的奠基性贡献：证明了具有有限参与者和有限纯策略集的博弈一定存在纳什均衡（包含混合策略均衡）。 零和博弈（Zero-sum Game） 零和博弈是一种非合作博弈，指的是参与博弈的各方，在严格竞争下，一方的收益必然意味着另一方的损失，博弈各方的收益和损失之和永远为“零”。双方不存在合作的可能。 零和博弈的结果是一方吃掉一方，一方的所得正是另一方的所失，整个社会的利益不会因此增加一分。 非零和博弈（Non-zero-sum Game） 非零和博弈是一种非合作下的博弈，博弈中各方的收益或损失的总和不是零值，它区别于零和博弈。在经济学研究中很有用。 在非零和博弈中，对局各方不是完全对立的，一个局中人所得并不一定意味着其他局中人要遭到同样数量的损失。也就是说，博弈参与者之间不存在“你之得即我之失”这样一种简单的关系。 参与者之间可能存在着某种共同的利益，博弈参与者可能实现“双赢”或者“多赢”。 囚徒困境（Prisoner’s dilemma） 两个嫌疑犯（A和B）作案后被警察抓住，隔离审讯。警方的政策是“坦白从宽，抗拒从严”，如果两个人都坦白则各判8年；如果一个人坦白，另外一个人不坦白，则坦白的放出去，不坦白的判刑十年；如果都不坦白，则因为证据不足各判1年。 囚徒困境最早由美国普林斯顿大学数学家阿尔伯特·塔克（Albnert Tucker）在1950年提出来，他当时编了一个故事向斯坦福大学的一群心理学家们解释什么是博弈论，这个故事后来成为博弈论中最著名的案例。 → 此时，都坦白是二者的严格最优策略。","link":"/2020/04/02/social_computing_5/"},{"title":"Social computing 6 —— 网络流量的博弈","text":"网络流量的博弈 网络结构上的博弈 公路交通网 网络中的博弈 假设有4000辆车，都要从A走到B 参与人： 4000位司机 策略选择：ACB 或 ADB 回报：行驶时间（越小越好），显然也取决于他人的策略 “均衡” = 没人通过改变选择可以得到更好的回报 均衡：上下路各有2000辆车；对于每辆车而言，对应回报为65。 此时，若某人要改变，则他的行驶时间为 2001/100+45&gt;652001 / 100 + 45 &gt; 652001/100+45&gt;65，因此无人改变 假设，C→D之间修一条快速路，则 若大家都走：A → C →D→B，则每个人的行驶时间为4000/100+0+4000/100=804000/100+0+4000/100=804000/100+0+4000/100=80 注意，在没修这条路之前，均衡中每个人行驶时间为65 如果某人打算改变为A→D→B，则他的行驶时间将变为45+4000/100&gt;8045+4000/100&gt;8045+4000/100&gt;80，于是他不会改变！ → 布雷斯悖论 为什么大家不能像从前那样？ 你会很合理地想走A→C→D→B，也就是说，从前那样的交通模式是不均衡的。 你会这么想，其他人呢？ 小结 通过一种简单的交通网络模型，我们看到“在网络上的博弈”的一种范式，特别是结构对均衡的影响。 我们看到了“布雷斯悖论”的出现，它其实可以看成是我们现实生活中有时看到“投入资源反而使情况更糟糕”情形的一种简单化、但有效的解释。 这个例子也告诉我们，在现实生活中，参与一个博弈，可能是无形中的。 布雷斯悖论的一般性 布雷斯悖论（Braess’s paradox）指的是一个交通网络上增加一条路反而是网络上的旅行时间增加。 例子： 高速公路免费带来的影响 2012年中秋开始，政府颁布一项惠民政策，即： 在法定节假日，高速公路免费通行。 每年中国高速公路公司将因此减收200亿人民币，与此同时免费政策也引发各方争议： 免费带动了消费额，远远大于高速公路公司的减收。 免费也带来了高速公路的拥堵，旅游景点的人流饱和等。 高速公路免费带来影响的理论化 与布雷斯悖论不同的地方在于，除了结构与流量关系之外，这个例子涉及多个行动者： 高速公路公司、车主及其家庭、政府 简化模型 免费政策 = 多修了一条公路 通行时间 = 交通总成本，包括时间和费用 布雷斯悖论的一般化 如此，我们是不是看到了另一种形态的布雷斯悖论 虽然也是交通网络，却是另一种形态 探讨 通行时间 - 流量 - 成本 - 社会成本 布雷斯悖论的含义是，通过网络结构的变动，意在改善交通行动，结果是导致了更加糟糕的交通。 中国高速公路免费所产生的效应，看起来类似 那么我们是否可以把布雷斯悖论做进一步抽象？譬如说 “好心办坏事”，意在增加社会福利的行动，反而增加了社会成本 例如： 意在改善儿童教育机会的制度变动，其结果是对学校需求的更加不平衡，有些学校无人问津，有些学校则挤破脑袋 同样，改善就医便利程度和降低个人就医负担的制度变动，其结果不仅是就医总费用急剧增加，对医院的需求更加不平衡，高等级医院挤破脑袋，社区医院门可罗雀。 小结 布雷斯悖论是社会政策、公共服务中可以意会到的现象 意会与科学论证，是两回事，对布雷斯悖论的推广，应该还是一个可探索的领域。 拍卖的意义及其形式 拍卖的普遍性 拍卖（auction）是很典型的节点之间的互动，例 佳士得、苏富比拍卖艺术品 政府拍卖土地、车牌 毕业摆摊，买旧物 竞标（bidding）也是一种拍卖 卖家将合同机会进行拍卖 拍卖的意义 拍卖是普遍存在的经济互动形态 模式简单，互动却复杂 也是博弈论应用的典型场景 参与者：参加拍卖的人，买卖双方，相当于两方博弈 策略：出价 收益：对物品的估值（支付价格）或为零，即不成交；对卖家而言，就是其得到的支付价格，或为零。 均衡：即在该状态下所有参与者的策略互为最佳应对，任何个人都没有理性的冬季来改变自己的策略，在拍卖中如何体现？ 拍卖的形式 在拍卖中，均衡是拍卖规则下的均衡，因此拍卖规则或拍卖形式，对均衡的达成有直接影响。 最简单的，单品拍卖。 英式拍卖 （古董艺术品的拍卖） 也称为“出价逐升式拍卖”，是目前最流行的网上拍卖方式。拍卖中，竞买人出价由低开始，此后出价一个比前一个要高，直到没有更高的出价为止，出价最高即最后一个竞买人将以其所出的价格获得该商品。 既然获胜的竞买人的出价只需比前一个最高价高一点，那么每个竞买人都不愿马上按照其预告价出价。当然，竞买人也要冒风险，他可能会被令人兴奋的竞价过程吸引，出价超出了预估价，这种心理现象被称为赢者诅咒（Winner’s Curse）。 荷兰式拍卖（农产品） 是英式拍卖的逆行，也称为“出价逐降式拍卖”。它是先由拍卖人给出一个潜在的最高价，然后价格不断下降，直到有人接受价格。该方式的缺点是拍卖速度太快，而且需求所有竞买人在某一时候竞买。 密封拍卖（Sealed Auction） （适合招标、互联网广告） 是指竞买人通过加密的E-mail将出价发送给拍卖人，再由拍卖人统一开标后，比较各方递价，最后确定中标人。 密封拍卖可分为一级密封拍卖和二级密封拍卖。一级密封拍卖也称为密封递价最高价拍卖，即在密封递价过程中，出价最高的竞买人中标。如果拍卖的是多件相同物品，出价低于前一个的竞买人购得剩余的拍卖品。二级密封拍卖也称为密封递价次高价拍卖，其递价过程与一及密封拍卖类似，只是出价最高的竞买人是按照出价第二高的竞买人所出的价格都按其预告价出价，降低了竞买人串通的可能性，获胜者不必按照最高价付款，从而使所有的竞买人都想以比其一级密封拍卖中高一些的价格出价。威廉.维克瑞（William Vickrey）因对此拍卖的研究而荣获1996年诺贝尔经济学奖，因此，二级密封拍卖也称为维氏拍卖。 双重拍卖(double auction) Open-outcry double auctions（开放出价双重拍卖） Sealed-bid double auctions（密封递价双重拍卖） 次价支付 假设有一件物品 不同人对其价值有不同的看法，v1, v2, v3, … , vk 每个人都有一个竞价：b1, b2, b3, … , bk 则 vi−biv_i - b_ivi​−bi​ 就是 i 可能得到的收益 次价拍卖规则 出价最高者得到购买权，但只需支付（b中的）次高价 出价策略 如果大家都按照自己真实的估值出价 则没有人能通过改变，获得更大的回报；这种情况下，大家互为最佳应对，均衡；尽管改变出价可能得到同样的回报 如果某个人不按照自己真实的估值出价 其他人按照估值出价，则他的回报要么没变化，要么变少，总之不可能获得更好的回报 因此“次价出价”是鼓励买家按照自己的真实估值出价 真的吗？ bi&gt;vib_i &gt; v_ibi​&gt;vi​ 提高报价，只是当超越其他人报价才有差别，但在这种情况下，就要支付比估值多的钱 —— 亏了 bi=vib_i = v_ ibi​=vi​ 真实报价 bi&lt;vib_i &lt; v_ibi​&lt;vi​ 降低报价。只是当低于其他人的报价才有差别，但这种情况下，就得不到交易权，因此没意义了。 拍卖规则要点 成交规则，谁获得拍品？ 通常是报价最高者或最低者。 支付价格，首价或次价 次价规则的引入，对于竞拍者的出价策略是有影响的。 是否知道他人出价 密封拍卖是不知道的，需要竞价者做出独立判断，且是否竞得，只有一次机会 非密封拍卖，知道他人竞价，且会受到他人出价的影响 小结 日常生活中，拍卖是随时发生的现象，对于我们理解博弈论的应用是一个难得的典型情景。 拍卖的形式多种多样，简单的、复杂的拍卖，从出价方式来看，有增价、降价、密封，三种形式；从支付方式看，有首价、次价两种方式。 拍卖中的博弈与占优策略 密封报价拍卖的两种形式 首价密封拍卖（FPA） 最高报价者得到交易权，支付最高报价。 次价密封拍卖（SPA） 最高报价者得到交易权，支付次高报价。 次价密封拍卖问题 一件物品 估值，不同的人对它的价值有不同的认识（即底价，最多愿意花的钱），v1，v2，… ，vk 每个人提出一个竞拍价， b1 &gt; b2 &gt; … &gt; bk 次价拍卖规则：出价最高者得购买权，但只需支付（b中）第二高的出价，即 v1−b2v_1-b_2v1​−b2​是出价最高者参与人得到的收益，其他人为0。 什么策略最优？ 博弈论视角（占优策略）：不可能通过改变其他策略得到更大的回报，无论别人出价策略如何。 回报： 估值 - 付出 结论：按照自己的估值出价最优！（非严格占优策略） 论证 假设在一次拍卖活动中，你认为拍品的估值最多为100元，你也考虑出价100元，现在考虑你能否通过不同的出价获得较大的回报 第一，你获得交易权。此时，你有正回报 提高报价也不会改善回报 降低报价，若不低于第二个人的，也不会改善回报，若低于第二个人的，则失去交易权，回报变成0（变少了） 第二，你没有获得交易权（有人出价x &gt; 100），此时，你的回报为0。 降低报价不会改变回报。 提高报价，若不高于第一个人的报价，也不会改善回报。若高于第一个人的，你赢得了交易权，但要支付原来第一个人的报价（高于你的估值），于是回报为负（减少了） 小结 采用次价密封拍卖的规则，拍卖一件物品，对参拍人来说，按照估值报价是占优策略 现实中，参拍人自觉应用这个结论的困难自安于每个人其实很难知道自己对一件物品的“估值”到底是多少 “估值” ≠ “我愿意出的钱数” “估值” = “我绝不接受高于这个钱数” 首次密封拍卖没有这个性质 匹配问题 2012年度诺贝尔经济学奖得主是劳埃德·夏普利和艾文·罗斯，两人研究市场制度下参与者之间如何达成配对的理论和实践问题，其中“GS算法”有重要地位。 学生必须合适的学校匹配，需要移植器官的患者必须与器官捐赠者匹配。这样的匹配如何才能尽可能高效的完成？什么样的方式对哪一方更有利？劳埃德•夏普利采用所谓的“合作博弈”理论去研究和比较不同的匹配方法。“求解”的难点在于确保匹配的结果是稳定的这一突出贡献，也就是说，两个代理人无法找到对方在当前情况下条件优于自己地方。而且，夏普利和他的同事创造了具体的方法即——Gale-Shapley algorithm来确保匹配是稳定的。这些方法也限制了代理人操纵匹配过程的动机。 艾文•罗斯认识到，Shapley值的理论结果可以解释在实践中重要市场的功能。通过一系列的实证研究，罗斯和他的同事证明，稳定是特定的市场机构成功的关键。罗斯后来在系统实验室中的实验都证实这一结论。他还帮助重新设计现有的医院和医生，学校和学生，器官捐献者与患者进行稳定匹配的机制。这些改革都基于Gale-Shapley算法，且考虑到具体情况和道德限制，如排除了侧面支付等问题，使得这一机制更有可操作性。 匹配是人类社会中常见的基本问题之一，会出现在各种不同的背景下。 匹配市场问题框架 卖方，买方，估值矩阵 简单匹配问题 二部图是表达这种供需关系的工具 问：是否存在一种安排（配置）使得每个人都满意？ 二部图中完美匹配：一组边，覆盖了所有的节点，没有节点冲突 这两个图体现的要求能否被满足？ 不能满足 = 存在受限组；S, N(S) 能被满足 = 存在完美匹配 基于估值的匹配问题 人们表达偏好不一定就是”要“与”不要“，对于不同的物品，可以有多样性的估价值判断 同一个物品，不同的人，估值可能不同 同一个人，不同的物品，估值可能不同 如何在”人“和”物品“之间配置（匹配）？ 如何评估一种安排的好坏？ 在经济学中，社会福利 = 参与人收益综合 社会最优：收益综合最大 小结 匹配问题描述的基本框架，参考上面的图 通过简单匹配问题，引入供需关系之间的二部图表达方式 不同供需配置方案的优劣比较指数 —— 社会福利，以及对“社会最优”性质的认识 匹配问题的解 利用收益矩阵计算 偏好卖家图（市场经济原则，涨价） 匹配问题的解 “计划经济”： top-down，从宏观结果到具体安排 市场经济思路 引入价格机制，让需求方选择（博弈），看最后能否达到宏观最优的结果。 清仓价格：每个需求方都能无冲突地得到最大的收益（差价） ？ 清仓价格同时也导致社会福利最大？ 清仓价格 → 最大的 ∑ 估值 ∑ 收益（差价） = ∑估值-∑价格 考虑清仓价格，以及偏好卖家图中的完美匹配对应的配置（M） 每一个收益都是最大 → “∑收益”最大 → “∑估值”最大 小结 以匹配问题为背景，比较“计划经济”与“市场经济”思路 简单模型，体现要点 “市场无形之手”含义与优势的一种解释 参考 # 拍卖形式有哪几种 # 匹配问题 孙立坚:2012年诺奖的理论贡献对政策设计的影响","link":"/2020/04/02/social_computing_6/"},{"title":"软件定义一切","text":"什么是软件定义？ 软件定义的真正落地，还是在云计算平台里面的应用。2011年前后，OpenFlow被用于云计算平台中进行网络管理，并被广泛接受。在15年的时候，Gartner战略报告首次出现SDN（软件定义），SDN重新“定义”了传统的网络架构甚至通信产业。 软件定义网络的技术原理是通过一组API对网络设备进行任意的编程从而实现新型的网络协议、拓扑架构而不需改动网络设备本身。 计算机的操作系统是什么，是管理硬件资源、控制程序运行、改善人机界面和为应用软件提供支持的一种系统软件，即向上提供公共服务，向下管理资源。如果从操作系统视角来看软件定义，操作系统是软件定义的“计算机”，从软件研究者的视角，操作系统体现了“软件定义”之集大成。 **软件定义的技术本质：**硬件资源虚拟化，管理功能可编程。硬件资源抽象为虚拟资源，然后用系统软件对虚拟资源管理和调度。就是在硬件资源虚拟化的基础上，用户可编写应用程序，满足访问资源的多样性的需求。大家现在可以看到软件定义出现了各种各样的延伸，软件定义的存储，软件定义的计算，软件定义的环境，软件定义的数据中心等等。但所有架构都跳不出操作系统的三层架构，就是说软件平台的三层架构，这些SDX均符合“硬件资源虚拟化”与“管理任务可编程”的技术原理。 我们可以看到的机遇就是软件定义一切。定义一切，人-机-物互联是我们追求的目标。我们是不是最终能做到万物皆可互联，一切均可编程呢？这就是软件定义给未来世界达成的目标，也就是我们的机遇所在。我们看到软件定义的本身进一步泛化和延伸，我们要软件定义我们的物理世界，再进入我们的城市、我们的行业、我们的校园，从单一的资源管控到人、机、物融合环境下对各种资源全方位的互联互通。这是我们今后努力的方向。 人工智能是当今的热潮，但我个人的观点还是认为处于数据驱动的算法智能阶段，软件平台如何提供“通用”的智能应用支撑，并允许按需深度定制？是否会出现面对AI的操作系统？我想这个也是可以通过平台的方式去实现。软件技术在新一轮革命技术中毫无疑问是核心竞争力之一，新一轮制造革命需要实现“硬件”、知识和工艺流程的软件化，进而实现软件的平台化，本质上即“软件定义”。 随着人、机、物的融合，软件定义的挑战可以分为这几个方面：体系结构设计决策，系统质量，系统安全，更轻量的虚拟化，从原有系统到软件定义系统平滑过渡，高度自适应智能软件平台。 体系结构设计决策，包括比如如何确定受管元素的合理“粒度”和“层次”？如何界定软、硬件的功能划分并组装、配置相应元素？等。 系统的质量，需要解决的问题有如何合理平衡管理灵活性和“虚拟化”后的性能损耗（与直接访问原系统相比）？如何降低“软件实现”的复杂性和故障率，有效定位故障以保障可靠性？等等。 系统安全，对硬件资源管理可编程带来开放性、灵活性的同时，也可能会带来更多的安全隐患。对于工业控制等安全攸关领域来说，可能会带来难以难以估量的损失。 更轻量的虚拟化。大量的新设备产生，虚拟化实现了对硬件资源的软化，是软件定义的基础技术，现有以虚拟机为单位的技术过于重载，难以满足性能和实时性要求。 原有系统到软件定义系统平滑过渡。如何将原有系统平滑过渡到软件定义系统？通过对已有的资源进行大幅度的改造，我们需要安装新的硬件，需要做新的软件管理系统，以及面临的人力，时间，经济，风控等因素。这个平滑过渡也需要合理的方案，否则很难做成这样的事情。 高度自适应软件平台。从软件人追求的目标来看，我们想追求一种更为高度自适应的智能软件平台。现在平台方式是以硬件资源为中心的，如果基础设施层发生变化，软件平台就要发生改变，改完之后，上面的应用也可能发生改变。我们追求的理想方式是，软件平台具有预测和管理未来硬件资源变化的能力。 来源：梅宏院士：软件定义的未来——万物皆可互联，一切均可编程 | CNCC 2017","link":"/2021/02/03/software_everything/"},{"title":"线程","text":"与进程近似，线程是允许应用程序并发执行多个任务的一种机制。如下图所示，一个进程可以包含多个线程。同一个程序的所有线程均会独立地执行相同的程序，且会共享统一份全局内存区域，包括初始化数据段(initialized data)、未初始化数据段（uninitialized data）以及堆内存段（heap segment）。 注意： 传统意义上的UNIX进程是多线程程序的一个特例，该进程值包括一个线程。 下图作了简化。特别是，线程栈(thread stack)的位置可能会与共享库、共享内存区域混在一起，这取决于创建线程、加载共享库，以及映射共享内存的具体顺序。而且，对于不同的Linux发行版，线程地址也会有所不同。 进程的问题 进程间信息难以共享。只能通过进程间通信（IPC）的方式在进程间进行信息交换。 调用fork()来创建进行的代价较高。即使利用写时复制（copy-on-write）技术，仍然需要复制内存页表（page table）和文件描述符（file descriptor table）等多种进程属性。 线程解决了上述的痛点： 线程之间可以快速共享信息。 创建线程效率比创建进程快10倍以上。（创建线程是clone()实现的）。 线程之间共享的数据 全局性： 全局内存 进程ID、父进程ID 进程组ID、会话ID 控制终端 打开的文件描述符 进程凭证 fcntl()创建的记录锁（record clock） 信号（signal）处置 文件系统相关信息 间隔定时器、POSIX定时器 系统V信号量撤销值 资源限制 CPU时间消耗 资源消耗 nice值 独有属性： 线程ID 信号掩码 线程特有数据 备选信号栈 errno变量 浮点型环境 实时调度策略（real-time scheduleing policy）和优先级 CPU亲和力（affinity） 能力（capablity） 栈、本地变量和函数的调用链接信息 线程ID 进程内部每一个线程都有一个唯一标识，成为线程ID。线程ID会返回pthread_create()的调用者，一个线程可以通过pthread_self()来获取线程ID。 POSIX线程ID和Linux专有的系统调用gettid()返回的线程ID 并不相同。POSIX线程ID由线程库实现来负责分配和维护。gettid()返回的线程ID是由内核(Kernel)分配的数字，类似于进程ID（process ID)。虽然在LINUX NPTL线程实现中，每个POSIX线程都对应于唯一的线程内核线程ID，但应用程序一般无需了解内核ID。 线程特有数据 线程特有数据使函数得以为每个调用线程分别维护一份变量的副本。线程特有数据是长期存在的。在同一线程对相同通过的函数历次调用期间，每个线程的变量会持续存在，函数可以向每个调用线程返回各自的结果缓存区。 实时调度策略和优先级 在Linux中，调度进程使用的CPU默认模型是循环时间共享。在这种模型中，每个进程轮流使用CPU一段时间，这段时间称之为时间片或者量子。循环时间共享满足了交互式多任务的两个重度需求： 公平性：每个进程都有机会用到CPU。 响应度：一个进程在使用CPU之前无需等待太常的时间。 进程的nice值允许进程间接地影响内核的调度算法，每个进程都有一个nice值，其中取值范围是-20（高优先级）～19（低优先级），默认值是0。 CPU亲和力（affinity） LINUX提供非标准系统调用来修改进程的硬CPU亲和力：sched_setaffinity()和sched_getaffinity()。 CPU亲和力是线程级特性，可以调整线程组中的每一个线程。 123456789#define _GNU_SOURCE#include &lt;sched.h&gt;void CPU_ZEOR(cpu_set_t *set); // 设置为0void CPU_SET(int cpu, cpu_set_t *set); // 设置cpu性质void CPU_CLR(int cpu, cpu_set_t *set); // 清除设置int CPU_ISSET(int cpu, cpu_set_t *set); // 检测cpu是否在set中。// 返回值=1,cpu被设置了；否则，返回0。 Pthreads 线程数据类型（Pthreads data type） 数据类型 描述 pthread_t 线程ID pthread_mutex_t 互斥对象（Mutex） pthread_mutexattr_t 互斥属性对象 pthread_cond_t 条件变量（condition ariable） pthread_condattr_t 条件变量的属性对象 pthread_key_t 线程特有数据的键 pthead_once_t 一次性初始化控制上下文（control context） pthead_attr_t 线程的属性对象","link":"/2021/09/07/thread/"},{"title":"贪心算法基础","text":"本文开始记录贪心算法的学习。 贪心算法的例子——活动选择问题 输入：S={1,2,...,n}S=\\{1,2,...,n\\}S={1,2,...,n}为nnn项活动的集合，sis_isi​、fif_ifi​分别为活动iii的开始和结束时间。 活动iii 与jjj相容 ⟺ si≥fj\\iff s_i \\ge f_j⟺si​≥fj​ 或 sj≥fis_j \\ge f_isj​≥fi​ 求：最大的两两相容的活动集AAA 输入实例： iii 1 2 3 4 5 6 7 8 9 10 sis_isi​ 1 3 2 5 4 5 6 8 8 2 fif_ifi​ 4 5 6 7 9 9 10 11 12 13 解：{1,4,8}\\{1,4,8\\}{1,4,8} 贪心算法 贪心算法（greedy algorithm）的挑选过程是多步判断，每步依据某种“短视”的策略进行选择，选择时注意满足条件相容性条件。 策略1：开始时间早的优先排序使s1≤s2≤...≤sns_1\\le s_2 \\le ... \\le s_ns1​≤s2​≤...≤sn​，从前向后挑选； 策略2：占用时间少的优先排序使得f1−s1≤f2−s2≤...≤fn−snf_1-s_1 \\le f_2 - s_2 \\le ... \\le f_n - s_nf1​−s1​≤f2​−s2​≤...≤fn​−sn​，从前向后挑选。 策略3：结束早的优先排序使得f1≤f2≤...≤fnf_1 \\le f_2 \\le ... \\le f_nf1​≤f2​≤...≤fn​，从前向后挑选。 策略1的反例 策略1：开始早的优先 反例：S={1,2,3}S=\\{1,2,3\\}S={1,2,3} s1=0,f1=20,s2=2,f2=5,s3=8,f3=15s_1=0,f_1=20,s_2=2,f_2=5,s_3=8,f_3=15s1​=0,f1​=20,s2​=2,f2​=5,s3​=8,f3​=15 策略2的反例 策略2：占时少的优先 反例：S={1,2,3}S=\\{1,2,3\\}S={1,2,3} s1=0,f1=8,s2=7,f2=9,s3=8,f3=15s_1=0,f_1=8,s_2=7,f_2=9,s_3=8,f_3=15s1​=0,f1​=8,s2​=7,f2​=9,s3​=8,f3​=15 策略3伪码 算法：Greedy Select 输入：活动集S,si,fi,i=1,2,...,n,f1≤...≤fnS, s_i, f_i, i=1,2,...,n, f_1 \\le ... \\le f_nS,si​,fi​,i=1,2,...,n,f1​≤...≤fn​ 输出：A⊆SA \\subseteq SA⊆S，选中的活动子集 n←length[S]n \\gets length[S]n←length[S] A←{1}A \\gets \\{1\\}A←{1} j←1j \\gets 1j←1 for i←2i \\gets 2i←2 to nnn do ifsi≥fj\\quad \\quad if \\quad s_i \\ge f_jifsi​≥fj​ thenA←A∪{i}\\quad \\quad then \\quad A \\gets A \\cup \\{i\\}thenA←A∪{i} j←i\\quad \\quad \\quad \\quad \\quad j \\gets ij←i return A 完成事件 t=max⁡{fk:k∈A}t=\\max \\{f_k: k \\in A\\}t=max{fk​:k∈A} 运行实例 输入：S={1,2,...,10}S=\\{1,2,...,10\\}S={1,2,...,10} iii 1 2 3 4 5 6 7 8 9 10 sis_isi​ 1\\fcolorbox{red}{aqua}{1}1​ 3 0 5\\fcolorbox{red}{aqua}{5}5​ 3 5 6 8\\fcolorbox{red}{aqua}{8}8​ 8 2 fif_ifi​ 4\\fcolorbox{red}{aqua}{4}4​ 5 6 7\\fcolorbox{red}{aqua}{7}7​ 8 9 10 11\\fcolorbox{red}{aqua}{11}11​ 12 13 解：A={1,4,8},t=11A=\\{1,4,8\\},\\quad t=11A={1,4,8},t=11 时间复杂度：O(nlog⁡n)+O(n)=O(nlog⁡n)O(n \\log n) + O(n)=O(n\\log n)O(nlogn)+O(n)=O(nlogn) 贪心算法的特点 设计要素： 贪心算法适用于组合优化问题； 求解过程是多步判断过程，最终的判断序列对应于问题的最优解； 依据某种“短视”的贪心选择性质判断，性质好坏决定算法的成败； 贪心法必须进行正确性证明； 证明贪心法不正确的技巧：举反例。 贪心算法的正确性证明 一个数学归纳法的例子 例：证明对于任何自然数nnn，1+2+...+n=n(n+1)/21+2+...+n=n(n+1)/21+2+...+n=n(n+1)/2 证 n=1n=1n=1，左边=1=1=1，右边=1×(1+1)/2=1=1 \\times (1+1)/2=1=1×(1+1)/2=1 假设对任意自然数nnn等式成立，则 1+2+...+(n+1)=(1+2+...+n)+(n+1)=n(n+1)/2+(n+1)=(n+1)(n/2+1)=(n+1)(n+2)/2\\large 1+2+...+(n+1) \\\\ =(1+2+...+n)+(n+1) \\\\ =n(n+1)/2 + (n+1) \\\\ =(n+1)(n/2+1) \\\\ =(n+1)(n+2)/21+2+...+(n+1)=(1+2+...+n)+(n+1)=n(n+1)/2+(n+1)=(n+1)(n/2+1)=(n+1)(n+2)/2 第一数学归纳法 适合证明涉及自然数的命题P(n)P(n)P(n) 归纳基础：证明P(1)P(1)P(1)为真（或者P(0)P(0)P(0)为真） 归纳步骤：若对所有nnn有P(n)P(n)P(n)为真，证明P(n+1)P(n+1)P(n+1)为真 ∀n,P(n)→P(n+1)P(1)n=1,P(1) ⟹ P(2)n=2,P(2) ⟹ P(3)...\\forall n, P(n) \\to P(n+1) \\\\ \\quad \\quad \\quad P(1) \\\\ n=1,\\quad P(1) \\implies P(2) \\\\ n=2,\\quad P(2) \\implies P(3) \\\\ \\quad \\quad \\quad ... ∀n,P(n)→P(n+1)P(1)n=1,P(1)⟹P(2)n=2,P(2)⟹P(3)... 第二数学归纳法 适合证明涉及自然数的命题P(n)P(n)P(n) 归纳基础：证明P(1)P(1)P(1)为真（或P(0)P(0)P(0)为真） 归纳步骤：若对所有小于nnn的kkk有P(k)P(k)P(k)真，证明P(n)P(n)P(n)为真 ∀k(k&lt;n∧P(k))→P(n)P(1)n=2,P(1) ⟹ P(2)n=3,P(1)∧P(2) ⟹ P(3)...\\forall k(k&lt;n \\land P(k)) \\to P(n) \\\\ \\quad \\quad \\quad P(1) \\\\ n=2, P(1) \\implies P(2) \\\\ n=3, P(1) \\land P(2) \\implies P(3) \\\\ \\quad \\quad \\quad ... ∀k(k&lt;n∧P(k))→P(n)P(1)n=2,P(1)⟹P(2)n=3,P(1)∧P(2)⟹P(3)... 两种归纳法的区别 归纳基础一样：P(1)P(1)P(1)为真 归纳步骤不同： 证明逻辑 算法正确性归纳证明 证明步骤： 叙述一个有关自然数nnn的命题，该命题断定该贪心策略的执行最终将导致最优解。其中自然数nnn可以代表算法步数或问题规模。 证明命题对所有的自然数为真。 归纳基础（从最小实例规模开始） 归纳步骤（第一或第二数学归纳法） 活动选择算法的命题 命题： 算法Select执行到第kkk步，选择kkk项活动 i1=1,i2,...,ik\\quad \\quad i_1=1,i_2,...,i_ki1​=1,i2​,...,ik​ 则存在最优解AAA包含活动i1=1,i2,...,iki_1=1,i_2,...,i_ki1​=1,i2​,...,ik​。 根据上述命题：对于任何kkk，算法前kkk步的选择都将导致最优解，至多到第nnn步将得到问题实例的最优解。 归纳证明：归纳基础 令S={1,2,...,n}S=\\{1,2,...,n\\}S={1,2,...,n}是活动集，且fi≤...≤fnf_i\\le ...\\le f_nfi​≤...≤fn​。 归纳基础：k=1k=1k=1，证明存在最优解包含活动111 证： 任取最优解A，A中的活动按截止时间递增排列。如果AAA的第一个活动为j,j1̸j,j \\not 1j,j​1，用111替换AAA的活动j得到解A′A'A′，即 A′=(A−{j})∪{1}\\quad \\quad \\quad A' = (A-\\{j\\}) \\cup \\{1\\}A′=(A−{j})∪{1}， 由于f1≤fjf_1 \\le f_jf1​≤fj​，A′A'A′也是最优解，且含有1。 归纳步骤 假设命题对kkk为真，证明对k+1k+1k+1也为真 证明：算法执行到第k步，选择了活动i1=1,i2,...,iki_1=1,i_2,...,i_ki1​=1,i2​,...,ik​，根据归纳假设存在最优解A包含i1=1,i2,...,iki_1=1,i_2,...,i_ki1​=1,i2​,...,ik​，AAA中剩下活动选自集合S′S'S′ S′={i∣i∈S,si≥fk}A={i1,i2,...,ik}∪BS'=\\{i|i \\in S, s_i \\ge f_k\\} \\\\ A=\\{i_1,i_2,...,i_k\\} \\cup B S′={i∣i∈S,si​≥fk​}A={i1​,i2​,...,ik​}∪B BBB是S′S'S′的最优解。（若不然，S′S'S′的最优解为B∗B^*B∗，B∗B^*B∗的活动比B多，那么 B∗∪{1,i2,...,ik}\\quad \\quad \\quad B^* \\cup \\{1,i_2,...,i_k\\}B∗∪{1,i2​,...,ik​} 是SSS的最优解，且比AAA的活动多，与AAA的最优性矛盾。） 将S′S'S′看成子问题，根据归纳基础， 存在S′S'S′的最优解B′B'B′有S′S'S′中的第一个活动ik+1i_{k+1}ik+1​，且∣B′∣=∣B∣|B'|=|B|∣B′∣=∣B∣，于是 {i1,i2,...,ik}∪B′={i1,i2,...,ik,ik+1}∪(B′−{ik+1})\\{i_1,i_2,...,i_k\\} \\cup B' \\\\ =\\{i_1,i_2,...,i_k,i_{k+1}\\} \\cup (B'-\\{i_{k+1}\\}){i1​,i2​,...,ik​}∪B′={i1​,i2​,...,ik​,ik+1​}∪(B′−{ik+1​}) 也是原问题的最优解。 最优装载问题 问题：nnn个集装箱1,2,...,n1,2,...,n1,2,...,n装上轮船，集装箱iii的重量wiw_iwi​，轮船装载限制为CCC，无体积限制。问如何装使得上船的集装箱最多？不妨设每个箱子的重量wi≤Cw_i\\le Cwi​≤C。 算法设计 贪心策略：轻者优先 算法设计： 将集装箱排序，使得 w1≤w2≤...≤wnw_1 \\le w_2 \\le ... \\le w_nw1​≤w2​≤...≤wn​ 按照标号从小到大装箱，直到装入下一个箱子使得集装箱总重量超过轮船装载重量限制，则停止。 正确性证明思路 命题：对装载问题任何规模为nnn的输入实例，算法得到最优解。 设集装箱从轻到重记为1,2,...,n1,2,...,n1,2,...,n。 归纳基础 证明对任何只含1个箱子的输入实例，贪心法得到最优解，显示正确。 归纳步骤 证明：假设对于任何n个箱子的输入实例贪心法都能得到最优解，那么对于n+1n+1n+1个箱子的输入实例也能得到最优解。 归纳步骤证明思路 N={1,2,...,n+1},w1≤w2≤...≤wn+1N=\\{1,2,...,n+1\\},w_1\\le w_2 \\le ... \\le w_{n+1}N={1,2,...,n+1},w1​≤w2​≤...≤wn+1​ ⟹ \\implies⟹ 去掉箱子111，令C′=C−w1C'=C-w_1C′=C−w1​，得到规模为nnn的输入N′={2,3,...,n+1}N'=\\{2,3,...,n+1\\}N′={2,3,...,n+1} ⟹ \\implies⟹ 关于输入N′N'N′和C′C'C′的最优解I′I'I′ ⟹ \\implies⟹ 在I′I'I′加入箱子111，得到III ⟹ \\implies⟹ 证明III是关于输入NNN的最优解 正确性证明 假设对于nnn个集装箱的输入，贪心法都可以得到最优解，考虑输入 N={1,2,...,n+1}N=\\{1,2,...,n+1\\}N={1,2,...,n+1}，其中w1≤w2≤...≤wn+1w_1\\le w_2 \\le ... \\le w_{n+1}w1​≤w2​≤...≤wn+1​ 由归纳假设，对于 N′={2,3,...,n+1},C′=C−w1N'=\\{2,3,...,n+1\\}, \\quad C'=C-w_1N′={2,3,...,n+1},C′=C−w1​， 贪心法得到最优解I′I'I′。令 I=I′∪{1}I=I'\\cup \\{1\\}I=I′∪{1} III(算法解)是关于NNN的最优解。 若不然，存在包含1的关于N的最优解I∗I*I∗（如果I∗I*I∗） 若不然，存在包含1的关于N的最优解I∗I*I∗（如果I∗I*I∗中没有1，用1替换中的第一个元素得到的解也是最优解），且∣I∗∣&gt;∣I∣|I*|&gt;|I|∣I∗∣&gt;∣I∣；那么I∗−{1}I*-\\{1\\}I∗−{1}是N′N'N′和C′C'C′的解且 ∣I∗−{1}∣&gt;∣I−{1}∣=∣I′∣|I*-\\{1\\}|&gt;|I-\\{1\\}|=|I'|∣I∗−{1}∣&gt;∣I−{1}∣=∣I′∣ 与I′I'I′是关于N′N'N′和C′C'C′的最优解矛盾。 小结 装载问题是0-1背包的子问题（每件物品的重量为1），NP难的问题存在多项式时间可解的子问题。 贪心算法证明：对规模归纳 最小延迟调度 客户集合AAA，∀i∈A\\forall i \\in A∀i∈A，tit_iti​为服务时间，did_idi​为客户要求完成时间，ti,dit_i, d_iti​,di​为正整数，一个调度f:A→Nf:A\\to Nf:A→N，f(i)f(i)f(i)为客户iii的开始时间。求最大延迟达到最小的调度，即求fff使得 min⁡f{max⁡i∈A{f(i)+ti−di}}∀i,j∈A,i≠j,f(i)+ti≤f(j)orf(j)+tj≤f(i)\\min_f\\{\\max_{i \\in A}\\{f(i)+t_i-d_i\\}\\} \\\\ \\forall i,j \\in A, i \\neq j,f(i)+t_i \\le f(j) \\\\ or \\quad f(j)+t_j\\le f(i) fmin​{i∈Amax​{f(i)+ti​−di​}}∀i,j∈A,i​=j,f(i)+ti​≤f(j)orf(j)+tj​≤f(i) 实例：调度1 A={1,2,3,4,5},T={5,8,4,10,3},D=&lt;10,12,15,11,20&gt;A=\\{1,2,3,4,5\\},T=\\{5,8,4,10,3\\},D=&lt;10,12,15,11,20&gt;A={1,2,3,4,5},T={5,8,4,10,3},D=&lt;10,12,15,11,20&gt;。 调度1：顺序安排 f1(1)=0,f1(2)=5,f1(3)=13,f1(4)=17,f1(5)=27f_1(1)=0,f_1(2)=5,f_1(3)=13,f_1(4)=17,f_1(5)=27f1​(1)=0,f1​(2)=5,f1​(3)=13,f1​(4)=17,f1​(5)=27 各任务延迟：0，1，2，16，10； 最大延迟：16。 优化的调度2 A={1,2,3,4,5},T={5,8,4,10,3},D=&lt;10,12,15,11,20&gt;A=\\{1,2,3,4,5\\},T=\\{5,8,4,10,3\\},D=&lt;10,12,15,11,20&gt;A={1,2,3,4,5},T={5,8,4,10,3},D=&lt;10,12,15,11,20&gt;。 调度2：按截至时间从前到后安排： f2(1)=0,f2(2)=5,f2(3)=13,f2(4)=17,f2(5)=27f_2(1)=0,f_2(2)=5,f_2(3)=13,f_2(4)=17,f_2(5)=27f2​(1)=0,f2​(2)=5,f2​(3)=13,f2​(4)=17,f2​(5)=27 各个任务延迟：0，11，12，4，10； 最大延迟：12。 贪心策略 贪心策略1：按照tit_iti​从小到大安排 贪心策略2：按照di−tid_i-t_idi​−ti​从小到大安排 贪心策略3：按照did_idi​从小到大安排 策略1对某些实例得不到最优解。 反例：t1=1,d1=100,t2=10,d2=10t_1=1,d_1=100,t_2=10,d_2=10t1​=1,d1​=100,t2​=10,d2​=10 策略2对某些实例得不到最优解。 反例：t1=1,d1=2,t2=10,d2=10t_1=1,d_1=2,t_2=10,d_2=10t1​=1,d1​=2,t2​=10,d2​=10 策略3 伪代码 算法 Schedule 输入：A，T，D 输出：f 排序A使得d1≤d2≤...≤dnd_1\\le d_2 \\le ... \\le d_nd1​≤d2​≤...≤dn​ f(1)←0f(1)\\gets 0f(1)←0 // 从0时刻起 i←2i \\gets 2i←2 whilei≤ndowhile \\quad i \\le n \\quad dowhilei≤ndo f(i)←f(i−1)+ti−1\\quad \\quad \\quad f(i) \\gets f(i-1)+t_{i-1}f(i)←f(i−1)+ti−1​ i←i+1\\quad \\quad \\quad i\\gets i+1i←i+1 排序思想：按照完成时间从早到晚安排任务，没有空闲。 交换论证：正确性证明 证明思路： 分析一般最优解与算法解的区别（成分，排列顺序不同）； 设计一种转换操作（替换成份或者交换次序），可以在有限步将任意一个普通最优解逐步替换成算法的解； 上述每部转换都不降低解的最优性质。 贪心算法的解的性质：没有空闲时间，没有逆序 逆序(i,j):f(i)&lt;f(j)且di&gt;dj(i,j): f(i)&lt;f(j)且d_i&gt;d_j(i,j):f(i)&lt;f(j)且di​&gt;dj​ 引理 引理1：所有没有逆序、没有空闲时间的调度具有相同的最大延迟。 证：设fff没有逆序，在fff中具有相同的完成时间ddd的客户i1,i2,...,iki_1,i_2,...,i_ki1​,i2​,...,ik​连续安排，其安排时刻为t0t_0t0​，完成这些任务的时刻是ttt，最大延迟为最后任务延迟t−dt-dt−d，与i1,i2,...,iki_1,i_2,...,i_ki1​,i2​,...,ik​的排列次序无关。 t=t0+(ti1+ti2)+...+tikt=t_0+(t_{i_1}+t_{i_2})+...+t_{i_{k}}t=t0​+(ti1​​+ti2​​)+...+tik​​ 证明要点 从一个没有空闲的最优解出发，逐步转变成没有逆序的解。根据引理1，这个解和算法解具有相同的最大延迟。 如果一个最优调度存在逆序，那么存在i&lt;ni&lt;ni&lt;n使得(i,i+1)(i,i+1)(i,i+1)构成一个逆序，称为相邻的逆序。 交换相邻逆序iii和jjj，得到的解仍旧最优。 每次交换后逆序数减111，至多经过n(n−1)/2n(n-1)/2n(n−1)/2次交换得到一个没有逆序的最优调度——等价于算法的解。 交换相邻逆序仍旧最优 设f1f_1f1​是一个任意最优解，存在相邻逆序(i,j)(i,j)(i,j)。交换iii和jjj的顺序，得到解f2f_2f2​。那么f2f_2f2​的最大延迟不超过f1f_1f1​的最大延迟。 理由： 交换iii、jjj与其他客户延迟时间无关。 交换后不增加jjj的延迟，但可能增加iii的延迟。 iii在f2f_2f2​的延迟小于jjj在f1f_1f1​的延迟。因此小于f1f_1f1​的最大延迟fff。 iii在f2f_2f2​的延迟不超过jjj在f1f_1f1​的延迟 delay(f2,i)=s+tj+ti−didelay(f_2,i)=s+t_j+t_i-d_idelay(f2​,i)=s+tj​+ti​−di​ delay(f1,j)=s+ti+tj−djdelay(f_1,j)=s+t_i+t_j-d_jdelay(f1​,j)=s+ti​+tj​−dj​ dj&lt;did_j&lt;d_idj​&lt;di​ delay(f2,i)&lt;delay(f1,j)≤rdelay(f_2,i)&lt;delay(f_1,j)\\le rdelay(f2​,i)&lt;delay(f1​,j)≤r 小结 贪心法的正确性证明方法：交换论证 分析算法解与一般最优解的区别，找到把一般解改造成算法解的一系列操作（替换成份、交换次序）。 证明操作步数有限。 证明每步操作后的得到解仍旧保持最优。 得不到最优解的处理方法 输入参数分析 考虑输入参数在什么取值范围内使用贪心法可以得到最优解。 误差分析 估计贪心法——近似算法所得到的解与最优解的误差（对所有的输入实例在最坏的情况下误差的上界）。 找零钱问题 问题：设由nnn种零钱，重量分别为w1,w2,...,wnw_1,w_2,...,w_nw1​,w2​,...,wn​，价值分别为v1=1,v2,...,vnv_1=1,v_2,...,v_nv1​=1,v2​,...,vn​。需要付的总钱数是yyy。不妨设币值和钱数都为正整数。问：如何付钱使得所付钱的总重量最轻？ 实例：v1=1,v2=5,v3=14,v4=18,wi=1,i=1,2,3,4.y=28v_1=1,v_2=5,v_3=14,v_4=18,w_i=1,i=1,2,3,4. \\\\ y=28v1​=1,v2​=5,v3​=14,v4​=18,wi​=1,i=1,2,3,4.y=28 最优解：x3=2,x1=x2=x4=0x_3=2,\\quad x_1=x_2=x_4=0x3​=2,x1​=x2​=x4​=0，总重为222。 建模 令选用第iii种硬币的数目是xi,i=1,2,3,...,nx_i,\\quad i=1,2,3,...,nxi​,i=1,2,3,...,n min⁡{∑i=1nwixi}∑i=1nvixi=y,xi∈N,i=1,2,...,n\\min \\{\\sum\\limits_{i=1}^{n}w_ix_i\\} \\\\ \\sum\\limits_{i=1}^{n}v_ix_i=y, \\quad x_i \\in N, \\quad i=1,2,...,nmin{i=1∑n​wi​xi​}i=1∑n​vi​xi​=y,xi​∈N,i=1,2,...,n 动态规划算法 设Fk(y)F_k(y)Fk​(y)表示用前kkk种零钱，总钱数为yyy的最小重量 Fk(y)=min⁡0≤xk≤⌊yvk⌋{Fk−1(y−vkxk)+wkxk}F_k(y)=\\min\\limits_{0\\le x_k \\le \\lfloor \\frac{y}{v_k}\\rfloor}\\{F_{k-1}(y-v_kx_k)+w_kx_k\\}Fk​(y)=0≤xk​≤⌊vk​y​⌋min​{Fk−1​(y−vk​xk​)+wk​xk​} F1(y)=w1⌊yv1⌋=w1yF_1(y)=w_1\\lfloor \\frac{y}{v_1}\\rfloor = w_1yF1​(y)=w1​⌊v1​y​⌋=w1​y 贪心法 单位价值重量轻的货币优先，设 w1v1≥w2v2≥...≥wnvn\\frac{w_1}{v_1} \\ge \\frac{w_2}{v_2} \\ge ... \\ge \\frac{w_n}{v_n}v1​w1​​≥v2​w2​​≥...≥vn​wn​​ 使用前kkk种零钱，总钱数为yyy，贪心法的总重量为Gk(y)G_k(y)Gk​(y)。 Gk(y)=wk⌊yvk⌋+Gk−1(ymod vk),k&gt;1G_k(y)=w_k\\lfloor \\frac{y}{v_{k}}\\rfloor +G_{k-1}(y \\mod v_k),\\quad k&gt;1Gk​(y)=wk​⌊vk​y​⌋+Gk−1​(ymodvk​),k&gt;1 G1(y)=w1⌊yv1⌋=w1yG_1(y)=w_1\\lfloor \\frac{y}{v_{1}}\\rfloor =w_1yG1​(y)=w1​⌊v1​y​⌋=w1​y n=1，2贪心法是最优解 n=1n=1n=1，只有一种零钱，F1(y)=G1(y)F_1(y)=G_1(y)F1​(y)=G1​(y) n=2n=2n=2，x2x_2x2​越大，得到的解越好。 F2(y)=min⁡0≤x2≤⌊y/v2⌋{F1(y−v2x2)+w2x2}[F1(y−v2(x2+δ))+w2(x2+δ)]−[F1(y−v2x2)+w2x2]=[w1(y−v2x2−v2δ)+w2x2+w2δ]−[w1(y−v2x2)+w2x2]=−w1v2δ+w2δ=δ(−w1v2+w2)≤0\\large F_2(y)=\\min\\limits_{0\\le x_2 \\le \\lfloor y/v_2\\rfloor} \\{F_1(y-v_2x_2)+w_2x_2\\} \\quad \\\\ [F_1(y-v_2(x_2+\\delta))+w_2(x_2+\\delta)] \\\\ \\quad - [F_1(y-v_2x_2)+w_2x_2] \\\\ = [w_1(y-v_2x_2-v_2\\delta)+w_2x_2+w_2\\delta] \\\\ \\quad - [w_1(y-v_2x_2)+w_2x_2] \\\\ = -w_1v_2\\delta+w_2\\delta \\\\ = \\delta(-w_1v_2+w_2)\\le 0 F2​(y)=0≤x2​≤⌊y/v2​⌋min​{F1​(y−v2​x2​)+w2​x2​}[F1​(y−v2​(x2​+δ))+w2​(x2​+δ)]−[F1​(y−v2​x2​)+w2​x2​]=[w1​(y−v2​x2​−v2​δ)+w2​x2​+w2​δ]−[w1​(y−v2​x2​)+w2​x2​]=−w1​v2​δ+w2​δ=δ(−w1​v2​+w2​)≤0 判别条件 定理：对每个正整数kkk，假设对所有非负数yyy有Gk(y)=Fk(y)G_k(y)=F_k(y)Gk​(y)=Fk​(y)，且存在ppp和δ\\deltaδ满足 vk+1=pvk−δv_{k+1}=pv_k-\\deltavk+1​=pvk​−δ， 其中0≤δ&lt;vk,vk≤vk+10\\le \\delta &lt; v_k, v_k \\le v_{k+1}0≤δ&lt;vk​,vk​≤vk+1​，ppp为正整数， 则下面的命题等价： Gk+1(y)=Fk+1(y)G_{k+1}(y)=F_{k+1}(y)\\quadGk+1​(y)=Fk+1​(y)对一切正整数yyy； Gk+1(pvk)=Fk+1(pvk)G_{k+1}(pv_k)=F_{k+1}(pv_k)Gk+1​(pvk​)=Fk+1​(pvk​)； wk+1+Gk(δ)≤pwkw_{k+1}+G_k(\\delta)\\le pw_kwk+1​+Gk​(δ)≤pwk​。 几点说明 根据条件1和3的等价性，可以对k=3,4,...,nk=3,4,...,nk=3,4,...,n，依次利用条件3对贪心法是否得到最优解做出判别。 条件3验证1次需要O(k)O(k)O(k)时间，k=O(n)k=O(n)k=O(n)，整个验证时间O(n2)O(n^2)O(n2)。 条件2是条件1在y=pvky=pv_ky=pvk​时的特殊情况。若条件1成立，显然有条件2成立。反之，若条件2不成立，则条件1不成立，钱数y=pvky=pv_ky=pvk​恰好提供了一个贪心法不正确的反例。 验证实例 例1：v1=1,v2=5,v3=14,v4=18,wi=1,i=1,2,3,4v_1=1,v_2=5,v_3=14,v_4=18,w_i=1,i=1,2,3,4v1​=1,v2​=5,v3​=14,v4​=18,wi​=1,i=1,2,3,4。对一切yyy有 G1(y)=F1(y),G2(y)=F2(y)G_1(y)=F_1(y),G_2(y)=F_2(y)G1​(y)=F1​(y),G2​(y)=F2​(y). 验证G3(y)=F3(y)G_3(y)=F_3(y)G3​(y)=F3​(y) v3=pv2−δ ⟹ p=3,δ=1.w3+G2(δ)=1+1=2pw2=3×1=3w3+G2(δ)≤pw2v_3=pv_2-\\delta \\implies p=3,\\delta =1. \\\\ w_3+G_2(\\delta)=1+1=2 \\\\ pw_2=3 \\times 1 =3 \\\\ w_3 + G_2(\\delta) \\le pw_2 v3​=pv2​−δ⟹p=3,δ=1.w3​+G2​(δ)=1+1=2pw2​=3×1=3w3​+G2​(δ)≤pw2​ 贪心法对n=3n=3n=3的实例得到最优解 例2 v1=1,v2=5,v3=14,v4=18,wi=1,i=1,2,3,4v_1=1,v_2=5,v_3=14,v_4=18,w_i=1,i=1,2,3,4v1​=1,v2​=5,v3​=14,v4​=18,wi​=1,i=1,2,3,4.对一切yyy有 G1(y)=F1(y),G2(y)=F2(y),G3(y)=F3(y)G_1(y)=F_1(y),G_2(y)=F_2(y),G_3(y)=F_3(y)G1​(y)=F1​(y),G2​(y)=F2​(y),G3​(y)=F3​(y), 验证G4(y)=F4(y)G_4(y)=F_4(y)G4​(y)=F4​(y), v4=pv3−δ ⟹ p=2,δ=10w4+G3(δ)=1+2=3pw3=2×1=2w4+G3(δ)&gt;pw3v_4=pv_3-\\delta \\implies p=2,\\delta = 10 \\\\ w_4 +G_3(\\delta)=1+2=3 \\\\ pw_3=2 \\times 1=2 \\\\ w_4+G_3(\\delta) &gt; pw_3 v4​=pv3​−δ⟹p=2,δ=10w4​+G3​(δ)=1+2=3pw3​=2×1=2w4​+G3​(δ)&gt;pw3​ n=4,y=pv3=28n=4,y=pv_3=28n=4,y=pv3​=28， 最优解：x3=2x_3=2x3​=2，贪心法：x4=1,x2=2x_4=1,x_2=2x4​=1,x2​=2。 小结 贪心策略不一定得到最优解，在这种情况下有两种解决方法： 参数化分析：分析参数取什么值可以得到最优解。 估计贪心法得到的解在最坏情况下与最优解的误差。 一个参数化分析的例子：找零钱问题。","link":"/2021/09/18/greedy-1/"}],"tags":[{"name":"DSL","slug":"DSL","link":"/tags/DSL/"},{"name":"image processing","slug":"image-processing","link":"/tags/image-processing/"},{"name":"图像处理","slug":"图像处理","link":"/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"Huge Page","slug":"Huge-Page","link":"/tags/Huge-Page/"},{"name":"Pin","slug":"Pin","link":"/tags/Pin/"},{"name":"SystemTap","slug":"SystemTap","link":"/tags/SystemTap/"},{"name":"lru","slug":"lru","link":"/tags/lru/"},{"name":"functools","slug":"functools","link":"/tags/functools/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"算法与数据结构","slug":"算法与数据结构","link":"/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"algorithms","slug":"algorithms","link":"/tags/algorithms/"},{"name":"data structure","slug":"data-structure","link":"/tags/data-structure/"},{"name":"分治策略","slug":"分治策略","link":"/tags/%E5%88%86%E6%B2%BB%E7%AD%96%E7%95%A5/"},{"name":"并发","slug":"并发","link":"/tags/%E5%B9%B6%E5%8F%91/"},{"name":"concurrency","slug":"concurrency","link":"/tags/concurrency/"},{"name":"决策论","slug":"决策论","link":"/tags/%E5%86%B3%E7%AD%96%E8%AE%BA/"},{"name":"运筹学","slug":"运筹学","link":"/tags/%E8%BF%90%E7%AD%B9%E5%AD%A6/"},{"name":"快速排序","slug":"快速排序","link":"/tags/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"name":"幂乘问题","slug":"幂乘问题","link":"/tags/%E5%B9%82%E4%B9%98%E9%97%AE%E9%A2%98/"},{"name":"斐波那契","slug":"斐波那契","link":"/tags/%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91/"},{"name":"情绪","slug":"情绪","link":"/tags/%E6%83%85%E7%BB%AA/"},{"name":"javascript","slug":"javascript","link":"/tags/javascript/"},{"name":"GPU","slug":"GPU","link":"/tags/GPU/"},{"name":"elf","slug":"elf","link":"/tags/elf/"},{"name":"OS","slug":"OS","link":"/tags/OS/"},{"name":"内存","slug":"内存","link":"/tags/%E5%86%85%E5%AD%98/"},{"name":"编程范式","slug":"编程范式","link":"/tags/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F/"},{"name":"图","slug":"图","link":"/tags/%E5%9B%BE/"},{"name":"多线程","slug":"多线程","link":"/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"流行歌曲","slug":"流行歌曲","link":"/tags/%E6%B5%81%E8%A1%8C%E6%AD%8C%E6%9B%B2/"},{"name":"演唱","slug":"演唱","link":"/tags/%E6%BC%94%E5%94%B1/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"pip","slug":"pip","link":"/tags/pip/"},{"name":"pypi","slug":"pypi","link":"/tags/pypi/"},{"name":"openldap","slug":"openldap","link":"/tags/openldap/"},{"name":"社会计算","slug":"社会计算","link":"/tags/%E7%A4%BE%E4%BC%9A%E8%AE%A1%E7%AE%97/"},{"name":"小世界问题","slug":"小世界问题","link":"/tags/%E5%B0%8F%E4%B8%96%E7%95%8C%E9%97%AE%E9%A2%98/"},{"name":"计算思维","slug":"计算思维","link":"/tags/%E8%AE%A1%E7%AE%97%E6%80%9D%E7%BB%B4/"},{"name":"tricks","slug":"tricks","link":"/tags/tricks/"},{"name":"有向图","slug":"有向图","link":"/tags/%E6%9C%89%E5%90%91%E5%9B%BE/"},{"name":"网页排序","slug":"网页排序","link":"/tags/%E7%BD%91%E9%A1%B5%E6%8E%92%E5%BA%8F/"},{"name":"博弈论","slug":"博弈论","link":"/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA/"},{"name":"software","slug":"software","link":"/tags/software/"},{"name":"线程","slug":"线程","link":"/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"贪心算法","slug":"贪心算法","link":"/tags/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/"}],"categories":[{"name":"编程","slug":"编程","link":"/categories/%E7%BC%96%E7%A8%8B/"},{"name":"图象处理","slug":"图象处理","link":"/categories/%E5%9B%BE%E8%B1%A1%E5%A4%84%E7%90%86/"},{"name":"OS","slug":"OS","link":"/categories/OS/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"},{"name":"Linux","slug":"OS/Linux","link":"/categories/OS/Linux/"},{"name":"运筹学","slug":"运筹学","link":"/categories/%E8%BF%90%E7%AD%B9%E5%AD%A6/"},{"name":"计算机性能","slug":"OS/计算机性能","link":"/categories/OS/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%80%A7%E8%83%BD/"},{"name":"functools","slug":"Python/functools","link":"/categories/Python/functools/"},{"name":"读书笔记","slug":"读书笔记","link":"/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"Javascript","slug":"Javascript","link":"/categories/Javascript/"},{"name":"生活","slug":"生活","link":"/categories/%E7%94%9F%E6%B4%BB/"},{"name":"openldap","slug":"openldap","link":"/categories/openldap/"},{"name":"社会计算","slug":"社会计算","link":"/categories/%E7%A4%BE%E4%BC%9A%E8%AE%A1%E7%AE%97/"},{"name":"WebGPU","slug":"Javascript/WebGPU","link":"/categories/Javascript/WebGPU/"}]}